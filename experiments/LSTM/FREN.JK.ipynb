{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbecac10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513dd6dc",
   "metadata": {},
   "source": [
    "# LSTM Multivariate\n",
    "Using lookback = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db62f90",
   "metadata": {},
   "source": [
    "## Load and prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bdfb975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>7 DAYS MA</th>\n",
       "      <th>14 DAYS MA</th>\n",
       "      <th>21 DAYS MA</th>\n",
       "      <th>7 DAYS STD DEV</th>\n",
       "      <th>RSI 7</th>\n",
       "      <th>RSI 14</th>\n",
       "      <th>RSI 21</th>\n",
       "      <th>MFI 7</th>\n",
       "      <th>MFI 14</th>\n",
       "      <th>MFI 21</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>quarter</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>dayofyear</th>\n",
       "      <th>dayofmonth</th>\n",
       "      <th>weekofyear</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-10-17</th>\n",
       "      <td>-0.077792</td>\n",
       "      <td>-0.039585</td>\n",
       "      <td>-0.041007</td>\n",
       "      <td>-0.484714</td>\n",
       "      <td>2.223844</td>\n",
       "      <td>2.575815</td>\n",
       "      <td>2.574613</td>\n",
       "      <td>1.633924</td>\n",
       "      <td>1.679844</td>\n",
       "      <td>1.552717</td>\n",
       "      <td>0.008923</td>\n",
       "      <td>1.34241</td>\n",
       "      <td>1.016593</td>\n",
       "      <td>-1.845348</td>\n",
       "      <td>1.033444</td>\n",
       "      <td>0.147246</td>\n",
       "      <td>1.030312</td>\n",
       "      <td>0.440118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-18</th>\n",
       "      <td>-0.003835</td>\n",
       "      <td>-0.007674</td>\n",
       "      <td>-0.010651</td>\n",
       "      <td>1.422315</td>\n",
       "      <td>0.937519</td>\n",
       "      <td>1.283190</td>\n",
       "      <td>1.404574</td>\n",
       "      <td>1.679668</td>\n",
       "      <td>1.748685</td>\n",
       "      <td>1.672304</td>\n",
       "      <td>0.716706</td>\n",
       "      <td>1.34241</td>\n",
       "      <td>1.016593</td>\n",
       "      <td>-1.845348</td>\n",
       "      <td>1.042927</td>\n",
       "      <td>0.261864</td>\n",
       "      <td>1.030312</td>\n",
       "      <td>0.201081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-19</th>\n",
       "      <td>0.038425</td>\n",
       "      <td>0.004293</td>\n",
       "      <td>0.002741</td>\n",
       "      <td>1.517442</td>\n",
       "      <td>1.158441</td>\n",
       "      <td>1.511092</td>\n",
       "      <td>1.626116</td>\n",
       "      <td>0.908951</td>\n",
       "      <td>0.920132</td>\n",
       "      <td>0.908441</td>\n",
       "      <td>1.424489</td>\n",
       "      <td>1.34241</td>\n",
       "      <td>1.016593</td>\n",
       "      <td>-1.845348</td>\n",
       "      <td>1.052410</td>\n",
       "      <td>0.376483</td>\n",
       "      <td>1.030312</td>\n",
       "      <td>0.293018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-22</th>\n",
       "      <td>0.093893</td>\n",
       "      <td>0.025567</td>\n",
       "      <td>0.019705</td>\n",
       "      <td>1.628038</td>\n",
       "      <td>1.070196</td>\n",
       "      <td>1.424646</td>\n",
       "      <td>1.546813</td>\n",
       "      <td>0.634583</td>\n",
       "      <td>0.627739</td>\n",
       "      <td>0.526947</td>\n",
       "      <td>-1.406643</td>\n",
       "      <td>1.34241</td>\n",
       "      <td>1.016593</td>\n",
       "      <td>-1.845348</td>\n",
       "      <td>1.080859</td>\n",
       "      <td>0.720337</td>\n",
       "      <td>1.096678</td>\n",
       "      <td>0.274631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-10-23</th>\n",
       "      <td>0.141436</td>\n",
       "      <td>0.046841</td>\n",
       "      <td>0.028634</td>\n",
       "      <td>1.606590</td>\n",
       "      <td>0.794613</td>\n",
       "      <td>1.164224</td>\n",
       "      <td>1.310060</td>\n",
       "      <td>0.566140</td>\n",
       "      <td>0.561087</td>\n",
       "      <td>0.541269</td>\n",
       "      <td>-0.698860</td>\n",
       "      <td>1.34241</td>\n",
       "      <td>1.016593</td>\n",
       "      <td>-1.845348</td>\n",
       "      <td>1.090342</td>\n",
       "      <td>0.834955</td>\n",
       "      <td>1.096678</td>\n",
       "      <td>0.219468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            7 DAYS MA  14 DAYS MA  21 DAYS MA  7 DAYS STD DEV     RSI 7  \\\n",
       "Date                                                                      \n",
       "2012-10-17  -0.077792   -0.039585   -0.041007       -0.484714  2.223844   \n",
       "2012-10-18  -0.003835   -0.007674   -0.010651        1.422315  0.937519   \n",
       "2012-10-19   0.038425    0.004293    0.002741        1.517442  1.158441   \n",
       "2012-10-22   0.093893    0.025567    0.019705        1.628038  1.070196   \n",
       "2012-10-23   0.141436    0.046841    0.028634        1.606590  0.794613   \n",
       "\n",
       "              RSI 14    RSI 21     MFI 7    MFI 14    MFI 21  dayofweek  \\\n",
       "Date                                                                      \n",
       "2012-10-17  2.575815  2.574613  1.633924  1.679844  1.552717   0.008923   \n",
       "2012-10-18  1.283190  1.404574  1.679668  1.748685  1.672304   0.716706   \n",
       "2012-10-19  1.511092  1.626116  0.908951  0.920132  0.908441   1.424489   \n",
       "2012-10-22  1.424646  1.546813  0.634583  0.627739  0.526947  -1.406643   \n",
       "2012-10-23  1.164224  1.310060  0.566140  0.561087  0.541269  -0.698860   \n",
       "\n",
       "            quarter     month      year  dayofyear  dayofmonth  weekofyear  \\\n",
       "Date                                                                         \n",
       "2012-10-17  1.34241  1.016593 -1.845348   1.033444    0.147246    1.030312   \n",
       "2012-10-18  1.34241  1.016593 -1.845348   1.042927    0.261864    1.030312   \n",
       "2012-10-19  1.34241  1.016593 -1.845348   1.052410    0.376483    1.030312   \n",
       "2012-10-22  1.34241  1.016593 -1.845348   1.080859    0.720337    1.096678   \n",
       "2012-10-23  1.34241  1.016593 -1.845348   1.090342    0.834955    1.096678   \n",
       "\n",
       "               Close  \n",
       "Date                  \n",
       "2012-10-17  0.440118  \n",
       "2012-10-18  0.201081  \n",
       "2012-10-19  0.293018  \n",
       "2012-10-22  0.274631  \n",
       "2012-10-23  0.219468  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../cleaned_data/FREN.csv', index_col='Date', parse_dates=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e7372b",
   "metadata": {},
   "source": [
    "### Split the dataset into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef269da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = int(len(df)*.8)\n",
    "train_dataset = df[:train_len]\n",
    "test_dataset = df[train_len:len(df)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b67742b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train_dataset[['Close']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662e7ee5",
   "metadata": {},
   "source": [
    "### Create the train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04cdbb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hops = 1\n",
    "train_len = len(train_dataset)\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "for i in range(hops, train_len):\n",
    "    X_train.append(train_dataset[i-hops:i])\n",
    "    y_train.append(train_y.iloc[i][0])\n",
    "    \n",
    "X_train, y_train = np.array(X_train), np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6cc5ef19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1966, 1, 18)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0e4995c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1966,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2de81a2",
   "metadata": {},
   "source": [
    "**Reshape the X_train into 3d**\n",
    "Required for LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cdad742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1966, 1, 18)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_reshaped = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], X_train.shape[2]))\n",
    "X_train_reshaped.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0eb3b0",
   "metadata": {},
   "source": [
    "### Create the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad3b7455",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_last_hops = train_dataset.iloc[-1*hops:]\n",
    "test_dataset_full = test_dataset.copy()\n",
    "test_dataset_full = pd.concat((train_dataset_last_hops, test_dataset_full), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6e4d9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_full_y = test_dataset_full[['Close']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50b02a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_len = test_dataset_full.shape[0]\n",
    "\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "for i in range(hops, test_len):\n",
    "    X_test.append(test_dataset_full[i-hops:i])\n",
    "    y_test.append(test_dataset_full_y.iloc[i][0])\n",
    "    \n",
    "X_test, y_test = np.array(X_test), np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e79e3044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(492, 1, 18)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6854979a",
   "metadata": {},
   "source": [
    "## Modeling with LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c443cffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "550326d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(lstm_unit1, lstm_unit2, hops):\n",
    "    \"\"\"\n",
    "    Function to build LSTM model architecture\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=lstm_unit1, return_sequences=True, input_shape=(hops,18)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(units=lstm_unit2))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    print(model.summary())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69d2b774",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(model, X_train, y_train, epochs, batch_size):\n",
    "    \"\"\"\n",
    "    Function to fit the model with specified epochs and batch size\n",
    "    \"\"\"\n",
    "    history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c40202c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, X_test):\n",
    "    predictions = model.predict(X_test)\n",
    "    actual_close = df[['Close']]\n",
    "    actual_close = pd.DataFrame(actual_close.iloc[train_len:, 0])\n",
    "    predictions = pd.DataFrame(predictions)\n",
    "    predictions.reset_index(drop=True, inplace=True)\n",
    "    predictions.index = test_dataset.index\n",
    "    predictions['Actual'] = actual_close['Close']\n",
    "    predictions.rename(columns={0:'Pred'}, inplace=True)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3ba465a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pred_act(predictions_df):\n",
    "    \"\"\"\n",
    "    Function to plot and compare y_true and y_pred\n",
    "    \"\"\"\n",
    "    plt.title('True vs Predicted')\n",
    "    predictions_df['Actual'].plot(figsize=(20,8), legend=True, color='blue')\n",
    "    predictions_df['Pred'].plot(legend=True, color='red', figsize=(20,8))\n",
    "    plt.legend(loc='best')\n",
    "    plt.xlabel('Standardized Close Price')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "17ee1ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "\n",
    "close_scaler = load('../feature_engineering/fren_close_scaler.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "63a3933f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_pred_act(predictions_df):\n",
    "    \"\"\"\n",
    "    Function to inverse standardized Close value\n",
    "    \"\"\"\n",
    "    inversed_pred = close_scaler.inverse_transform(np.array(predictions_df['Pred']).reshape(-1,1))\n",
    "    inversed_act = close_scaler.inverse_transform(np.array(predictions_df['Actual']).reshape(-1,1))\n",
    "    inversed = pd.DataFrame(inversed_pred)\n",
    "    inversed['Actual'] = inversed_act\n",
    "    inversed.rename({0:'Pred'}, axis=1, inplace=True)\n",
    "    inversed.index = test_dataset.index\n",
    "    return inversed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "44c1ad8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotErrorHist(inversed_df):\n",
    "    \"\"\"\n",
    "    Function to plot error histogram\n",
    "    \"\"\"\n",
    "    error = inversed_df['Pred'] - inversed_df['Actual']\n",
    "    # plt.hist(error, bins=25)\n",
    "    plt.figure(figsize=(12,12))\n",
    "    sns.displot(error)\n",
    "    plt.xlabel('Prediction Error [Close]')\n",
    "    _ = plt.ylabel('Count')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "88c98fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Evaluation metrics\n",
    "\"\"\"\n",
    "from statsmodels.tools.eval_measures import rmse\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def mape(actual, pred): \n",
    "    actual, pred = np.array(actual), np.array(pred)\n",
    "    return np.mean(np.abs((actual - pred) / actual)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9dbd1e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(inversed_df):\n",
    "    \"\"\"\n",
    "    Function to evaluate predictions\n",
    "    \"\"\"\n",
    "    rmse_ = rmse(inversed_df['Actual'], inversed_df['Pred'])\n",
    "    mape_ = mape(inversed_df['Actual'], inversed_df['Pred'])\n",
    "    r2 = r2_score(inversed_df['Actual'], inversed_df['Pred'])\n",
    "    return rmse_, mape_, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "beadb98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_candidates = [100,150,200]\n",
    "batch_size_candidates = [16,32,64]\n",
    "lstm_unit1_candidates = [50, 100]\n",
    "lstm_unit2_candidates = [50, 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4d7a98db",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "predictions_dfs = {}\n",
    "inversed_dfs = {}\n",
    "performances = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "63cc4b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 1, 50)             13800     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1, 50)             0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 50)                20200     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 50)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34,051\n",
      "Trainable params: 34,051\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "123/123 [==============================] - 14s 9ms/step - loss: 0.4784\n",
      "Epoch 2/100\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0370\n",
      "Epoch 3/100\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0353\n",
      "Epoch 4/100\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.0334\n",
      "Epoch 5/100\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.0325\n",
      "Epoch 6/100\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.0302\n",
      "Epoch 7/100\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.0278\n",
      "Epoch 8/100\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0254\n",
      "Epoch 9/100\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0248\n",
      "Epoch 10/100\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0266\n",
      "Epoch 11/100\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0249\n",
      "Epoch 12/100\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0287\n",
      "Epoch 13/100\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0285\n",
      "Epoch 14/100\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0255\n",
      "Epoch 15/100\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0264\n",
      "Epoch 16/100\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0243\n",
      "Epoch 17/100\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0253\n",
      "Epoch 18/100\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0207\n",
      "Epoch 19/100\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0228\n",
      "Epoch 20/100\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0251\n",
      "Epoch 21/100\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0231\n",
      "Epoch 22/100\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0224\n",
      "Epoch 23/100\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0232\n",
      "Epoch 24/100\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0232\n",
      "Epoch 25/100\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0233\n",
      "Epoch 26/100\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0256\n",
      "Epoch 27/100\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0252\n",
      "Epoch 28/100\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0208\n",
      "Epoch 29/100\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0227\n",
      "Epoch 30/100\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0257\n",
      "Epoch 31/100\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0213\n",
      "Epoch 32/100\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0244\n",
      "Epoch 33/100\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0214\n",
      "Epoch 34/100\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0211\n",
      "Epoch 35/100\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0225\n",
      "Epoch 36/100\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0245\n",
      "Epoch 37/100\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0205\n",
      "Epoch 38/100\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0246\n",
      "Epoch 39/100\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0209\n",
      "Epoch 40/100\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0203\n",
      "Epoch 41/100\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0205\n",
      "Epoch 42/100\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0214\n",
      "Epoch 43/100\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0237\n",
      "Epoch 44/100\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0214\n",
      "Epoch 45/100\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0220\n",
      "Epoch 46/100\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0199\n",
      "Epoch 47/100\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0201\n",
      "Epoch 48/100\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0199\n",
      "Epoch 49/100\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0212\n",
      "Epoch 50/100\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0178\n",
      "Epoch 51/100\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0192\n",
      "Epoch 52/100\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0202\n",
      "Epoch 53/100\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0199\n",
      "Epoch 54/100\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0212\n",
      "Epoch 55/100\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0223\n",
      "Epoch 56/100\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0241\n",
      "Epoch 57/100\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0196\n",
      "Epoch 58/100\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0193\n",
      "Epoch 59/100\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0219\n",
      "Epoch 60/100\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0223\n",
      "Epoch 61/100\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0221\n",
      "Epoch 62/100\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0189\n",
      "Epoch 63/100\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0226\n",
      "Epoch 64/100\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0202\n",
      "Epoch 65/100\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0189\n",
      "Epoch 66/100\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0198\n",
      "Epoch 67/100\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0184\n",
      "Epoch 68/100\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0212\n",
      "Epoch 69/100\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0185\n",
      "Epoch 70/100\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0218\n",
      "Epoch 71/100\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.0212\n",
      "Epoch 72/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0225\n",
      "Epoch 73/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0202\n",
      "Epoch 74/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0204\n",
      "Epoch 75/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0189\n",
      "Epoch 76/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0189\n",
      "Epoch 77/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0201\n",
      "Epoch 78/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0191\n",
      "Epoch 79/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0209\n",
      "Epoch 80/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0201\n",
      "Epoch 81/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0185\n",
      "Epoch 82/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0201\n",
      "Epoch 83/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0217\n",
      "Epoch 84/100\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0224\n",
      "Epoch 85/100\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0181\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0206\n",
      "Epoch 87/100\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0214\n",
      "Epoch 88/100\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0197\n",
      "Epoch 89/100\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.0193\n",
      "Epoch 90/100\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.0180\n",
      "Epoch 91/100\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.0206\n",
      "Epoch 92/100\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.0173\n",
      "Epoch 93/100\n",
      "123/123 [==============================] - 0s 2ms/step - loss: 0.0214\n",
      "Epoch 94/100\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0190\n",
      "Epoch 95/100\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.0204\n",
      "Epoch 96/100\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0191\n",
      "Epoch 97/100\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0193\n",
      "Epoch 98/100\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0191\n",
      "Epoch 99/100\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0184\n",
      "Epoch 100/100\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0211\n",
      "16/16 [==============================] - 1s 2ms/step\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_2 (LSTM)               (None, 1, 50)             13800     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 1, 50)             0         \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 100)               60400     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 74,301\n",
      "Trainable params: 74,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "123/123 [==============================] - 5s 3ms/step - loss: 0.3346\n",
      "Epoch 2/100\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0318\n",
      "Epoch 3/100\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0279\n",
      "Epoch 4/100\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.0282\n",
      "Epoch 5/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0266\n",
      "Epoch 6/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0278\n",
      "Epoch 7/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0278\n",
      "Epoch 8/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0251\n",
      "Epoch 9/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0241\n",
      "Epoch 10/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0228\n",
      "Epoch 11/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0248\n",
      "Epoch 12/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0213\n",
      "Epoch 13/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0202\n",
      "Epoch 14/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0230\n",
      "Epoch 15/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0205\n",
      "Epoch 16/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0216\n",
      "Epoch 17/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0215\n",
      "Epoch 18/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0214\n",
      "Epoch 19/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0209\n",
      "Epoch 20/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0215\n",
      "Epoch 21/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0221\n",
      "Epoch 22/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0192\n",
      "Epoch 23/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0206\n",
      "Epoch 24/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0226\n",
      "Epoch 25/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0203\n",
      "Epoch 26/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0227\n",
      "Epoch 27/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0191\n",
      "Epoch 28/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0205\n",
      "Epoch 29/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0190\n",
      "Epoch 30/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0185\n",
      "Epoch 31/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0170\n",
      "Epoch 32/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0177\n",
      "Epoch 33/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0173\n",
      "Epoch 34/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0190\n",
      "Epoch 35/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0204\n",
      "Epoch 36/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0202\n",
      "Epoch 37/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0205\n",
      "Epoch 38/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0158\n",
      "Epoch 39/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0193\n",
      "Epoch 40/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0184\n",
      "Epoch 41/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0198\n",
      "Epoch 42/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0181\n",
      "Epoch 43/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0193\n",
      "Epoch 44/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0203\n",
      "Epoch 45/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0165\n",
      "Epoch 46/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0203\n",
      "Epoch 47/100\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.0183\n",
      "Epoch 48/100\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.0167\n",
      "Epoch 49/100\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.0181\n",
      "Epoch 50/100\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.0185\n",
      "Epoch 51/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0184\n",
      "Epoch 52/100\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.0187\n",
      "Epoch 53/100\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.0192\n",
      "Epoch 54/100\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.0182\n",
      "Epoch 55/100\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0169\n",
      "Epoch 56/100\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0196\n",
      "Epoch 57/100\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0177\n",
      "Epoch 58/100\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.0163\n",
      "Epoch 59/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0171\n",
      "Epoch 60/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0181\n",
      "Epoch 61/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0174\n",
      "Epoch 62/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0178\n",
      "Epoch 63/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0178\n",
      "Epoch 64/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0174\n",
      "Epoch 65/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0164\n",
      "Epoch 66/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0186\n",
      "Epoch 67/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0168\n",
      "Epoch 68/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0170\n",
      "Epoch 69/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0177\n",
      "Epoch 70/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0179\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0189\n",
      "Epoch 72/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0186\n",
      "Epoch 73/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0179\n",
      "Epoch 74/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0166\n",
      "Epoch 75/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0158\n",
      "Epoch 76/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0194\n",
      "Epoch 77/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0183\n",
      "Epoch 78/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0168\n",
      "Epoch 79/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0168\n",
      "Epoch 80/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0157\n",
      "Epoch 81/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0180\n",
      "Epoch 82/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0157\n",
      "Epoch 83/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0176\n",
      "Epoch 84/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0145\n",
      "Epoch 85/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0172\n",
      "Epoch 86/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0185\n",
      "Epoch 87/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0170\n",
      "Epoch 88/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0180\n",
      "Epoch 89/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0178\n",
      "Epoch 90/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0167\n",
      "Epoch 91/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0178\n",
      "Epoch 92/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0155\n",
      "Epoch 93/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0147\n",
      "Epoch 94/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0157\n",
      "Epoch 95/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0170\n",
      "Epoch 96/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0142\n",
      "Epoch 97/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0185\n",
      "Epoch 98/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0173\n",
      "Epoch 99/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0150\n",
      "Epoch 100/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0152\n",
      "16/16 [==============================] - 1s 2ms/step\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_4 (LSTM)               (None, 1, 100)            47600     \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 1, 100)            0         \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 50)                30200     \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 50)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77,851\n",
      "Trainable params: 77,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "123/123 [==============================] - 5s 6ms/step - loss: 0.3191\n",
      "Epoch 2/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0344\n",
      "Epoch 3/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0273\n",
      "Epoch 4/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0305\n",
      "Epoch 5/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0279\n",
      "Epoch 6/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0252\n",
      "Epoch 7/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0264\n",
      "Epoch 8/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0237\n",
      "Epoch 9/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0239\n",
      "Epoch 10/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0247\n",
      "Epoch 11/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0199\n",
      "Epoch 12/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0282\n",
      "Epoch 13/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0237\n",
      "Epoch 14/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0240\n",
      "Epoch 15/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0222\n",
      "Epoch 16/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0224\n",
      "Epoch 17/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0199\n",
      "Epoch 18/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0229\n",
      "Epoch 19/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0211\n",
      "Epoch 20/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0209\n",
      "Epoch 21/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0211\n",
      "Epoch 22/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0224\n",
      "Epoch 23/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0177\n",
      "Epoch 24/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0207\n",
      "Epoch 25/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0219\n",
      "Epoch 26/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0205\n",
      "Epoch 27/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0201\n",
      "Epoch 28/100\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.0196\n",
      "Epoch 29/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0216\n",
      "Epoch 30/100\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.0219\n",
      "Epoch 31/100\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0218\n",
      "Epoch 32/100\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0189\n",
      "Epoch 33/100\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Epoch 34/100\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0194\n",
      "Epoch 35/100\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0226\n",
      "Epoch 36/100\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0219\n",
      "Epoch 37/100\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.0198\n",
      "Epoch 38/100\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0208\n",
      "Epoch 39/100\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0181\n",
      "Epoch 40/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0186\n",
      "Epoch 41/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0205\n",
      "Epoch 42/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0209\n",
      "Epoch 43/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0223\n",
      "Epoch 44/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0211\n",
      "Epoch 45/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0200\n",
      "Epoch 46/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0188\n",
      "Epoch 47/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0220\n",
      "Epoch 48/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0188\n",
      "Epoch 49/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0192\n",
      "Epoch 50/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0195\n",
      "Epoch 51/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0193\n",
      "Epoch 52/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0199\n",
      "Epoch 53/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0206\n",
      "Epoch 54/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0214\n",
      "Epoch 55/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0186\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0202\n",
      "Epoch 57/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0211\n",
      "Epoch 58/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0208\n",
      "Epoch 59/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0187\n",
      "Epoch 60/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0190\n",
      "Epoch 61/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0185\n",
      "Epoch 62/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0192\n",
      "Epoch 63/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0191\n",
      "Epoch 64/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0201\n",
      "Epoch 65/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0198\n",
      "Epoch 66/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0192\n",
      "Epoch 67/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0201\n",
      "Epoch 68/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0176\n",
      "Epoch 69/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0167\n",
      "Epoch 70/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0173\n",
      "Epoch 71/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0188\n",
      "Epoch 72/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0178\n",
      "Epoch 73/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0174\n",
      "Epoch 74/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0181\n",
      "Epoch 75/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0168\n",
      "Epoch 76/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0187\n",
      "Epoch 77/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0190\n",
      "Epoch 78/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0153\n",
      "Epoch 79/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0164\n",
      "Epoch 80/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0174\n",
      "Epoch 81/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0169\n",
      "Epoch 82/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0177\n",
      "Epoch 83/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0174\n",
      "Epoch 84/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0160\n",
      "Epoch 85/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0200\n",
      "Epoch 86/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0190\n",
      "Epoch 87/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0171\n",
      "Epoch 88/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0164\n",
      "Epoch 89/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0177\n",
      "Epoch 90/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0205\n",
      "Epoch 91/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0165\n",
      "Epoch 92/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0198\n",
      "Epoch 93/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0187\n",
      "Epoch 94/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0193\n",
      "Epoch 95/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0190\n",
      "Epoch 96/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0164\n",
      "Epoch 97/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0162\n",
      "Epoch 98/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0166\n",
      "Epoch 99/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0186\n",
      "Epoch 100/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0191\n",
      "16/16 [==============================] - 1s 2ms/step\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_6 (LSTM)               (None, 1, 100)            47600     \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 1, 100)            0         \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (None, 100)               80400     \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 128,101\n",
      "Trainable params: 128,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "123/123 [==============================] - 5s 7ms/step - loss: 0.2648\n",
      "Epoch 2/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0269\n",
      "Epoch 3/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0255\n",
      "Epoch 4/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0256\n",
      "Epoch 5/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0228\n",
      "Epoch 6/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0223\n",
      "Epoch 7/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0245\n",
      "Epoch 8/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0204\n",
      "Epoch 9/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0202\n",
      "Epoch 10/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0231\n",
      "Epoch 11/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0191\n",
      "Epoch 12/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0192\n",
      "Epoch 13/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0178\n",
      "Epoch 14/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0212\n",
      "Epoch 15/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0229\n",
      "Epoch 16/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0206\n",
      "Epoch 17/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0201\n",
      "Epoch 18/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0206\n",
      "Epoch 19/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0212\n",
      "Epoch 20/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0184\n",
      "Epoch 21/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0182\n",
      "Epoch 22/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0180\n",
      "Epoch 23/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0200\n",
      "Epoch 24/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0207\n",
      "Epoch 25/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0202\n",
      "Epoch 26/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0162\n",
      "Epoch 27/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0195\n",
      "Epoch 28/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0178\n",
      "Epoch 29/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0169\n",
      "Epoch 30/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0170\n",
      "Epoch 31/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0179\n",
      "Epoch 32/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0188\n",
      "Epoch 33/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0172\n",
      "Epoch 34/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0190\n",
      "Epoch 35/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0171\n",
      "Epoch 36/100\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.0198\n",
      "Epoch 37/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0170\n",
      "Epoch 38/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0182\n",
      "Epoch 39/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0179\n",
      "Epoch 40/100\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.0163\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0186\n",
      "Epoch 42/100\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 43/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0167\n",
      "Epoch 44/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0148\n",
      "Epoch 45/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0184\n",
      "Epoch 46/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0157\n",
      "Epoch 47/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0178\n",
      "Epoch 48/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0176\n",
      "Epoch 49/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0170\n",
      "Epoch 50/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0173\n",
      "Epoch 51/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0172\n",
      "Epoch 52/100\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0175\n",
      "Epoch 53/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0168\n",
      "Epoch 54/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0154\n",
      "Epoch 55/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0168\n",
      "Epoch 56/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0166\n",
      "Epoch 57/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0151\n",
      "Epoch 58/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0181\n",
      "Epoch 59/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0163\n",
      "Epoch 60/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0171\n",
      "Epoch 61/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0176\n",
      "Epoch 62/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0168\n",
      "Epoch 63/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0163\n",
      "Epoch 64/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0160\n",
      "Epoch 65/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0153\n",
      "Epoch 66/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0164\n",
      "Epoch 67/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0167\n",
      "Epoch 68/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0145\n",
      "Epoch 69/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0165\n",
      "Epoch 70/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0155\n",
      "Epoch 71/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0164\n",
      "Epoch 72/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0160\n",
      "Epoch 73/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0169\n",
      "Epoch 74/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0148\n",
      "Epoch 75/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0143\n",
      "Epoch 76/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0164\n",
      "Epoch 77/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0131\n",
      "Epoch 78/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0143\n",
      "Epoch 79/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0151\n",
      "Epoch 80/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0147\n",
      "Epoch 81/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0163\n",
      "Epoch 82/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0168\n",
      "Epoch 83/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0171\n",
      "Epoch 84/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0153\n",
      "Epoch 85/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0136\n",
      "Epoch 86/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0163\n",
      "Epoch 87/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0158\n",
      "Epoch 88/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0154\n",
      "Epoch 89/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0164\n",
      "Epoch 90/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0149\n",
      "Epoch 91/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0141\n",
      "Epoch 92/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0145\n",
      "Epoch 93/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0140\n",
      "Epoch 94/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0146\n",
      "Epoch 95/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0159\n",
      "Epoch 96/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0157\n",
      "Epoch 97/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0129\n",
      "Epoch 98/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0175\n",
      "Epoch 99/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0139\n",
      "Epoch 100/100\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0149\n",
      "16/16 [==============================] - 1s 2ms/step\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_8 (LSTM)               (None, 1, 50)             13800     \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 1, 50)             0         \n",
      "                                                                 \n",
      " lstm_9 (LSTM)               (None, 50)                20200     \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 50)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34,051\n",
      "Trainable params: 34,051\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "62/62 [==============================] - 4s 3ms/step - loss: 0.6213\n",
      "Epoch 2/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0554\n",
      "Epoch 3/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0402\n",
      "Epoch 4/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0382\n",
      "Epoch 5/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0320\n",
      "Epoch 6/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0342\n",
      "Epoch 7/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0290\n",
      "Epoch 8/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0276\n",
      "Epoch 9/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0322\n",
      "Epoch 10/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0297\n",
      "Epoch 11/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0253\n",
      "Epoch 12/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0274\n",
      "Epoch 13/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0275\n",
      "Epoch 14/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0291\n",
      "Epoch 15/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0267\n",
      "Epoch 16/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0254\n",
      "Epoch 17/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0246\n",
      "Epoch 18/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0218\n",
      "Epoch 19/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0231\n",
      "Epoch 20/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0258\n",
      "Epoch 21/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0247\n",
      "Epoch 22/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0245\n",
      "Epoch 23/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0262\n",
      "Epoch 24/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0227\n",
      "Epoch 25/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0202\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0217\n",
      "Epoch 27/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0251\n",
      "Epoch 28/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0216\n",
      "Epoch 29/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0229\n",
      "Epoch 30/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0253\n",
      "Epoch 31/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0230\n",
      "Epoch 32/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0237\n",
      "Epoch 33/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0217\n",
      "Epoch 34/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0209\n",
      "Epoch 35/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0226\n",
      "Epoch 36/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0224\n",
      "Epoch 37/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0222\n",
      "Epoch 38/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0220\n",
      "Epoch 39/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0230\n",
      "Epoch 40/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Epoch 41/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0216\n",
      "Epoch 42/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0201\n",
      "Epoch 43/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0226\n",
      "Epoch 44/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0199\n",
      "Epoch 45/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0210\n",
      "Epoch 46/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0200\n",
      "Epoch 47/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0217\n",
      "Epoch 48/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0232\n",
      "Epoch 49/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0221\n",
      "Epoch 50/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0203\n",
      "Epoch 51/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 52/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0189\n",
      "Epoch 53/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0179\n",
      "Epoch 54/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0202\n",
      "Epoch 55/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0184\n",
      "Epoch 56/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0208\n",
      "Epoch 57/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0229\n",
      "Epoch 58/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0197\n",
      "Epoch 59/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0206\n",
      "Epoch 60/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0214\n",
      "Epoch 61/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0186\n",
      "Epoch 62/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0196\n",
      "Epoch 63/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Epoch 64/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Epoch 65/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0219\n",
      "Epoch 66/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0225\n",
      "Epoch 67/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0201\n",
      "Epoch 68/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0203\n",
      "Epoch 69/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0207\n",
      "Epoch 70/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0171\n",
      "Epoch 71/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0193\n",
      "Epoch 72/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0220\n",
      "Epoch 73/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0211\n",
      "Epoch 74/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0202\n",
      "Epoch 75/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0202\n",
      "Epoch 76/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0242\n",
      "Epoch 77/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0186\n",
      "Epoch 78/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0198\n",
      "Epoch 79/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0177\n",
      "Epoch 80/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0184\n",
      "Epoch 81/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0173\n",
      "Epoch 82/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0200\n",
      "Epoch 83/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0205\n",
      "Epoch 84/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0187\n",
      "Epoch 85/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0176\n",
      "Epoch 86/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0222\n",
      "Epoch 87/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0193\n",
      "Epoch 88/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0200\n",
      "Epoch 89/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0189\n",
      "Epoch 90/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0200\n",
      "Epoch 91/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0202\n",
      "Epoch 92/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0185\n",
      "Epoch 93/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0188\n",
      "Epoch 94/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0203\n",
      "Epoch 95/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0212\n",
      "Epoch 96/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0186\n",
      "Epoch 97/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0185\n",
      "Epoch 98/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0191\n",
      "Epoch 99/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0177\n",
      "Epoch 100/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0209\n",
      "16/16 [==============================] - 1s 2ms/step\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_10 (LSTM)              (None, 1, 50)             13800     \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 1, 50)             0         \n",
      "                                                                 \n",
      " lstm_11 (LSTM)              (None, 100)               60400     \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 100)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 74,301\n",
      "Trainable params: 74,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "62/62 [==============================] - 4s 3ms/step - loss: 0.6612\n",
      "Epoch 2/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0524\n",
      "Epoch 3/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0356\n",
      "Epoch 4/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0339\n",
      "Epoch 5/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0302\n",
      "Epoch 6/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0263\n",
      "Epoch 7/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0316\n",
      "Epoch 8/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0233\n",
      "Epoch 9/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0270\n",
      "Epoch 10/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0225\n",
      "Epoch 11/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0240\n",
      "Epoch 12/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0252\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0266\n",
      "Epoch 14/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0250\n",
      "Epoch 15/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0221\n",
      "Epoch 16/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0248\n",
      "Epoch 17/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0210\n",
      "Epoch 18/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0205\n",
      "Epoch 19/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0216\n",
      "Epoch 20/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0218\n",
      "Epoch 21/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0229\n",
      "Epoch 22/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0216\n",
      "Epoch 23/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0208\n",
      "Epoch 24/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0198\n",
      "Epoch 25/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0221\n",
      "Epoch 26/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0218\n",
      "Epoch 27/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0207\n",
      "Epoch 28/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0202\n",
      "Epoch 29/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0199\n",
      "Epoch 30/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0213\n",
      "Epoch 31/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0222\n",
      "Epoch 32/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0210\n",
      "Epoch 33/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0203\n",
      "Epoch 34/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0217\n",
      "Epoch 35/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0179\n",
      "Epoch 36/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0180\n",
      "Epoch 37/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0170\n",
      "Epoch 38/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0190\n",
      "Epoch 39/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0184\n",
      "Epoch 40/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0168\n",
      "Epoch 41/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0183\n",
      "Epoch 42/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0180\n",
      "Epoch 43/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0218\n",
      "Epoch 44/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0182\n",
      "Epoch 45/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0180\n",
      "Epoch 46/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0195\n",
      "Epoch 47/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0178\n",
      "Epoch 48/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0179\n",
      "Epoch 49/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0169\n",
      "Epoch 50/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0185\n",
      "Epoch 51/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0175\n",
      "Epoch 52/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0178\n",
      "Epoch 53/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0189\n",
      "Epoch 54/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0182\n",
      "Epoch 55/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0172\n",
      "Epoch 56/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0176\n",
      "Epoch 57/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0182\n",
      "Epoch 58/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0177\n",
      "Epoch 59/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0184\n",
      "Epoch 60/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0187\n",
      "Epoch 61/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0172\n",
      "Epoch 62/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0184\n",
      "Epoch 63/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0175\n",
      "Epoch 64/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0174\n",
      "Epoch 65/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0183\n",
      "Epoch 66/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0166\n",
      "Epoch 67/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0162\n",
      "Epoch 68/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0172\n",
      "Epoch 69/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0188\n",
      "Epoch 70/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0182\n",
      "Epoch 71/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0164\n",
      "Epoch 72/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0171\n",
      "Epoch 73/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0175\n",
      "Epoch 74/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0168\n",
      "Epoch 75/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0171\n",
      "Epoch 76/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0165\n",
      "Epoch 77/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0159\n",
      "Epoch 78/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0161\n",
      "Epoch 79/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0167\n",
      "Epoch 80/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0168\n",
      "Epoch 81/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0163\n",
      "Epoch 82/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0154\n",
      "Epoch 83/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0151\n",
      "Epoch 84/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0170\n",
      "Epoch 85/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0183\n",
      "Epoch 86/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0157\n",
      "Epoch 87/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0157\n",
      "Epoch 88/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0162\n",
      "Epoch 89/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0180\n",
      "Epoch 90/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0146\n",
      "Epoch 91/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0159\n",
      "Epoch 92/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0174\n",
      "Epoch 93/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0174\n",
      "Epoch 94/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0166\n",
      "Epoch 95/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0168\n",
      "Epoch 96/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0161\n",
      "Epoch 97/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0150\n",
      "Epoch 98/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0153\n",
      "Epoch 99/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0171\n",
      "Epoch 100/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0157\n",
      "16/16 [==============================] - 1s 2ms/step\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_12 (LSTM)              (None, 1, 100)            47600     \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 1, 100)            0         \n",
      "                                                                 \n",
      " lstm_13 (LSTM)              (None, 50)                30200     \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 50)                0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77,851\n",
      "Trainable params: 77,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Epoch 1/100\n",
      "62/62 [==============================] - 4s 3ms/step - loss: 0.4782\n",
      "Epoch 2/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0426\n",
      "Epoch 3/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0311\n",
      "Epoch 4/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0273\n",
      "Epoch 5/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.0266\n",
      "Epoch 6/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0288\n",
      "Epoch 7/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0244\n",
      "Epoch 8/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0231\n",
      "Epoch 9/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0256\n",
      "Epoch 10/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0226\n",
      "Epoch 11/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0233\n",
      "Epoch 12/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0232\n",
      "Epoch 13/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0233\n",
      "Epoch 14/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0219\n",
      "Epoch 15/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0223\n",
      "Epoch 16/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0223\n",
      "Epoch 17/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0247\n",
      "Epoch 18/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0209\n",
      "Epoch 19/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0212\n",
      "Epoch 20/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0214\n",
      "Epoch 21/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0230\n",
      "Epoch 22/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0238\n",
      "Epoch 23/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0198\n",
      "Epoch 24/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0218\n",
      "Epoch 25/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0221\n",
      "Epoch 26/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0188\n",
      "Epoch 27/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0189\n",
      "Epoch 28/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0202\n",
      "Epoch 29/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0187\n",
      "Epoch 30/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0207\n",
      "Epoch 31/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0212\n",
      "Epoch 32/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.0186\n",
      "Epoch 33/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.0195\n",
      "Epoch 34/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0200\n",
      "Epoch 35/100\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0198\n",
      "Epoch 36/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0191\n",
      "Epoch 37/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0182\n",
      "Epoch 38/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0208\n",
      "Epoch 39/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0197\n",
      "Epoch 40/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0193\n",
      "Epoch 41/100\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0221\n",
      "Epoch 42/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.0212\n",
      "Epoch 43/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.0171\n",
      "Epoch 44/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.0193\n",
      "Epoch 45/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.0199\n",
      "Epoch 46/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.0167\n",
      "Epoch 47/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.0203\n",
      "Epoch 48/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.0200\n",
      "Epoch 49/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.0185\n",
      "Epoch 50/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.0200\n",
      "Epoch 51/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.0162\n",
      "Epoch 52/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0173\n",
      "Epoch 53/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0183\n",
      "Epoch 54/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0172\n",
      "Epoch 55/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0182\n",
      "Epoch 56/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0190\n",
      "Epoch 57/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0188\n",
      "Epoch 58/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0175\n",
      "Epoch 59/100\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0193\n",
      "Epoch 60/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0179\n",
      "Epoch 61/100\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0180\n",
      "Epoch 62/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.0191\n",
      "Epoch 63/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.0167\n",
      "Epoch 64/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.0199\n",
      "Epoch 65/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.0198\n",
      "Epoch 66/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.0170\n",
      "Epoch 67/100\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0160\n",
      "Epoch 68/100\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.0222\n",
      "Epoch 69/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.0167\n",
      "Epoch 70/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0178\n",
      "Epoch 71/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0206\n",
      "Epoch 72/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0181\n",
      "Epoch 73/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0228\n",
      "Epoch 74/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0175\n",
      "Epoch 75/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0202\n",
      "Epoch 76/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0167\n",
      "Epoch 77/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0168\n",
      "Epoch 78/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.0192\n",
      "Epoch 79/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0194\n",
      "Epoch 80/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0177\n",
      "Epoch 81/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0175\n",
      "Epoch 82/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0173\n",
      "Epoch 83/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0196\n",
      "Epoch 84/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0169\n",
      "Epoch 85/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.0169\n",
      "Epoch 86/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.0185\n",
      "Epoch 87/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.0179\n",
      "Epoch 88/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0182\n",
      "Epoch 89/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0185\n",
      "Epoch 90/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0176\n",
      "Epoch 91/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0178\n",
      "Epoch 92/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0207\n",
      "Epoch 93/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0171\n",
      "Epoch 94/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.0170\n",
      "Epoch 95/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0164\n",
      "Epoch 96/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0177\n",
      "Epoch 97/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0175\n",
      "Epoch 98/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0172\n",
      "Epoch 99/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0181\n",
      "Epoch 100/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0201\n",
      "16/16 [==============================] - 3s 6ms/step\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_14 (LSTM)              (None, 1, 100)            47600     \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 1, 100)            0         \n",
      "                                                                 \n",
      " lstm_15 (LSTM)              (None, 100)               80400     \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 100)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 128,101\n",
      "Trainable params: 128,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "62/62 [==============================] - 14s 13ms/step - loss: 0.4384\n",
      "Epoch 2/100\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.0314\n",
      "Epoch 3/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0247\n",
      "Epoch 4/100\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.0234\n",
      "Epoch 5/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0207\n",
      "Epoch 6/100\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.0189\n",
      "Epoch 7/100\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.0224\n",
      "Epoch 8/100\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.0196\n",
      "Epoch 9/100\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.0206\n",
      "Epoch 10/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0193\n",
      "Epoch 11/100\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.0199\n",
      "Epoch 12/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0201\n",
      "Epoch 13/100\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.0199\n",
      "Epoch 14/100\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.0210\n",
      "Epoch 15/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0198\n",
      "Epoch 16/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0188\n",
      "Epoch 17/100\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0204\n",
      "Epoch 18/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0176\n",
      "Epoch 19/100\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.0200\n",
      "Epoch 20/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0187\n",
      "Epoch 21/100\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.0189\n",
      "Epoch 22/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0182\n",
      "Epoch 23/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0163\n",
      "Epoch 24/100\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0166\n",
      "Epoch 25/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0150\n",
      "Epoch 26/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0167\n",
      "Epoch 27/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0182\n",
      "Epoch 28/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0177\n",
      "Epoch 29/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0170\n",
      "Epoch 30/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0172\n",
      "Epoch 31/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0177\n",
      "Epoch 32/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0162\n",
      "Epoch 33/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0200\n",
      "Epoch 34/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0159\n",
      "Epoch 35/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0167\n",
      "Epoch 36/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0172\n",
      "Epoch 37/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0183\n",
      "Epoch 38/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0166\n",
      "Epoch 39/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0170\n",
      "Epoch 40/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0174\n",
      "Epoch 41/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0180\n",
      "Epoch 42/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0181\n",
      "Epoch 43/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0149\n",
      "Epoch 44/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0184\n",
      "Epoch 45/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0148\n",
      "Epoch 46/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0150\n",
      "Epoch 47/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0179\n",
      "Epoch 48/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0183\n",
      "Epoch 49/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0145\n",
      "Epoch 50/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0166\n",
      "Epoch 51/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0165\n",
      "Epoch 52/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0181\n",
      "Epoch 53/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0159\n",
      "Epoch 54/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0164\n",
      "Epoch 55/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0158\n",
      "Epoch 56/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0147\n",
      "Epoch 57/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0167\n",
      "Epoch 58/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0160\n",
      "Epoch 59/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0174\n",
      "Epoch 60/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0144\n",
      "Epoch 61/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0168\n",
      "Epoch 62/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0194\n",
      "Epoch 63/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0159\n",
      "Epoch 64/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0143\n",
      "Epoch 65/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0171\n",
      "Epoch 66/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0154\n",
      "Epoch 67/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0161\n",
      "Epoch 68/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0161\n",
      "Epoch 69/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0165\n",
      "Epoch 70/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0166\n",
      "Epoch 71/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0151\n",
      "Epoch 72/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0174\n",
      "Epoch 73/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0150\n",
      "Epoch 74/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0154\n",
      "Epoch 75/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0166\n",
      "Epoch 76/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0139\n",
      "Epoch 77/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0156\n",
      "Epoch 78/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0163\n",
      "Epoch 79/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0149\n",
      "Epoch 80/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0163\n",
      "Epoch 81/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0157\n",
      "Epoch 82/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0166\n",
      "Epoch 83/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0136\n",
      "Epoch 84/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0149\n",
      "Epoch 85/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0143\n",
      "Epoch 86/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0151\n",
      "Epoch 87/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0166\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0155\n",
      "Epoch 89/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0148\n",
      "Epoch 90/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0145\n",
      "Epoch 91/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0148\n",
      "Epoch 92/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0150\n",
      "Epoch 93/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0151\n",
      "Epoch 94/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0155\n",
      "Epoch 95/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0168\n",
      "Epoch 96/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0144\n",
      "Epoch 97/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0161\n",
      "Epoch 98/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0147\n",
      "Epoch 99/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0139\n",
      "Epoch 100/100\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0155\n",
      "16/16 [==============================] - 4s 5ms/step\n",
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_16 (LSTM)              (None, 1, 50)             13800     \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 1, 50)             0         \n",
      "                                                                 \n",
      " lstm_17 (LSTM)              (None, 50)                20200     \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 50)                0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34,051\n",
      "Trainable params: 34,051\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "31/31 [==============================] - 12s 11ms/step - loss: 0.9972\n",
      "Epoch 2/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.3144\n",
      "Epoch 3/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0686\n",
      "Epoch 4/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0491\n",
      "Epoch 5/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0413\n",
      "Epoch 6/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0369\n",
      "Epoch 7/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0323\n",
      "Epoch 8/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.0329\n",
      "Epoch 9/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.0308\n",
      "Epoch 10/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.0309\n",
      "Epoch 11/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.0288\n",
      "Epoch 12/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0294\n",
      "Epoch 13/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0275\n",
      "Epoch 14/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0268\n",
      "Epoch 15/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0266\n",
      "Epoch 16/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0239\n",
      "Epoch 17/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0279\n",
      "Epoch 18/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0255\n",
      "Epoch 19/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0251\n",
      "Epoch 20/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0238\n",
      "Epoch 21/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0283\n",
      "Epoch 22/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0266\n",
      "Epoch 23/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0270\n",
      "Epoch 24/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0245\n",
      "Epoch 25/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0272\n",
      "Epoch 26/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0268\n",
      "Epoch 27/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0236\n",
      "Epoch 28/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0253\n",
      "Epoch 29/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0223\n",
      "Epoch 30/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0238\n",
      "Epoch 31/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.0248\n",
      "Epoch 32/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.0237\n",
      "Epoch 33/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.0235\n",
      "Epoch 34/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.0208\n",
      "Epoch 35/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0238\n",
      "Epoch 36/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0241\n",
      "Epoch 37/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0228\n",
      "Epoch 38/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0230\n",
      "Epoch 39/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0219\n",
      "Epoch 40/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0234\n",
      "Epoch 41/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0201\n",
      "Epoch 42/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0216\n",
      "Epoch 43/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0210\n",
      "Epoch 44/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0233\n",
      "Epoch 45/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.0254\n",
      "Epoch 46/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.0229\n",
      "Epoch 47/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.0241\n",
      "Epoch 48/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0234\n",
      "Epoch 49/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0220\n",
      "Epoch 50/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0196\n",
      "Epoch 51/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.0223\n",
      "Epoch 52/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.0200\n",
      "Epoch 53/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0233\n",
      "Epoch 54/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0207\n",
      "Epoch 55/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0200\n",
      "Epoch 56/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0203\n",
      "Epoch 57/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.0200\n",
      "Epoch 58/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.0206\n",
      "Epoch 59/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.0225\n",
      "Epoch 60/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0212\n",
      "Epoch 61/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0198\n",
      "Epoch 62/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0214\n",
      "Epoch 63/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.0213\n",
      "Epoch 64/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0229\n",
      "Epoch 65/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.0206\n",
      "Epoch 66/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0182\n",
      "Epoch 67/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0242\n",
      "Epoch 68/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0209\n",
      "Epoch 69/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.0226\n",
      "Epoch 70/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.0176\n",
      "Epoch 71/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.0192\n",
      "Epoch 72/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0234\n",
      "Epoch 73/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0217\n",
      "Epoch 74/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0202\n",
      "Epoch 75/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0191\n",
      "Epoch 76/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0191\n",
      "Epoch 77/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0197\n",
      "Epoch 78/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0208\n",
      "Epoch 79/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0198\n",
      "Epoch 80/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0220\n",
      "Epoch 81/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.0228\n",
      "Epoch 82/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0195\n",
      "Epoch 83/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0222\n",
      "Epoch 84/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0200\n",
      "Epoch 85/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0205\n",
      "Epoch 86/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0214\n",
      "Epoch 87/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0198\n",
      "Epoch 88/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0208\n",
      "Epoch 89/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0206\n",
      "Epoch 90/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0205\n",
      "Epoch 91/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0203\n",
      "Epoch 92/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0203\n",
      "Epoch 93/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0196\n",
      "Epoch 94/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0202\n",
      "Epoch 95/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0206\n",
      "Epoch 96/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0185\n",
      "Epoch 97/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0212\n",
      "Epoch 98/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0176\n",
      "Epoch 99/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0197\n",
      "Epoch 100/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0211\n",
      "16/16 [==============================] - 3s 5ms/step\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_18 (LSTM)              (None, 1, 50)             13800     \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 1, 50)             0         \n",
      "                                                                 \n",
      " lstm_19 (LSTM)              (None, 100)               60400     \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 100)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 74,301\n",
      "Trainable params: 74,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "31/31 [==============================] - 14s 12ms/step - loss: 0.8898\n",
      "Epoch 2/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.1404\n",
      "Epoch 3/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0449\n",
      "Epoch 4/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0366\n",
      "Epoch 5/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0334\n",
      "Epoch 6/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0281\n",
      "Epoch 7/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0272\n",
      "Epoch 8/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0283\n",
      "Epoch 9/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0242\n",
      "Epoch 10/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0242\n",
      "Epoch 11/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0245\n",
      "Epoch 12/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0224\n",
      "Epoch 13/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0222\n",
      "Epoch 14/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0227\n",
      "Epoch 15/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0239\n",
      "Epoch 16/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0223\n",
      "Epoch 17/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0234\n",
      "Epoch 18/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0238\n",
      "Epoch 19/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0240\n",
      "Epoch 20/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0212\n",
      "Epoch 21/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0221\n",
      "Epoch 22/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0228\n",
      "Epoch 23/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0218\n",
      "Epoch 24/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0191\n",
      "Epoch 25/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0221\n",
      "Epoch 26/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0200\n",
      "Epoch 27/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0208\n",
      "Epoch 28/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0179\n",
      "Epoch 29/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0201\n",
      "Epoch 30/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0216\n",
      "Epoch 31/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0182\n",
      "Epoch 32/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0210\n",
      "Epoch 33/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0209\n",
      "Epoch 34/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0216\n",
      "Epoch 35/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0204\n",
      "Epoch 36/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0197\n",
      "Epoch 37/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0193\n",
      "Epoch 38/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0187\n",
      "Epoch 39/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0246\n",
      "Epoch 40/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0184\n",
      "Epoch 41/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0191\n",
      "Epoch 42/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0213\n",
      "Epoch 43/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0207\n",
      "Epoch 44/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0199\n",
      "Epoch 45/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0193\n",
      "Epoch 46/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0188\n",
      "Epoch 47/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0186\n",
      "Epoch 48/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0170\n",
      "Epoch 49/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0197\n",
      "Epoch 50/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0199\n",
      "Epoch 51/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0171\n",
      "Epoch 52/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0199\n",
      "Epoch 53/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0189\n",
      "Epoch 54/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0183\n",
      "Epoch 55/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0198\n",
      "Epoch 56/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0179\n",
      "Epoch 57/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0181\n",
      "Epoch 58/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0191\n",
      "Epoch 59/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0170\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0172\n",
      "Epoch 61/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0187\n",
      "Epoch 62/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0175\n",
      "Epoch 63/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0163\n",
      "Epoch 64/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0181\n",
      "Epoch 65/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0175\n",
      "Epoch 66/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0164\n",
      "Epoch 67/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0164\n",
      "Epoch 68/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0169\n",
      "Epoch 69/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0173\n",
      "Epoch 70/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0157\n",
      "Epoch 71/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0182\n",
      "Epoch 72/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0162\n",
      "Epoch 73/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0168\n",
      "Epoch 74/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0172\n",
      "Epoch 75/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0200\n",
      "Epoch 76/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0175\n",
      "Epoch 77/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0201\n",
      "Epoch 78/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0170\n",
      "Epoch 79/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0184\n",
      "Epoch 80/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0153\n",
      "Epoch 81/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0155\n",
      "Epoch 82/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0165\n",
      "Epoch 83/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0163\n",
      "Epoch 84/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0160\n",
      "Epoch 85/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0166\n",
      "Epoch 86/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0161\n",
      "Epoch 87/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0154\n",
      "Epoch 88/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0175\n",
      "Epoch 89/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0178\n",
      "Epoch 90/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0157\n",
      "Epoch 91/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0166\n",
      "Epoch 92/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0162\n",
      "Epoch 93/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0153\n",
      "Epoch 94/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0173\n",
      "Epoch 95/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0167\n",
      "Epoch 96/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0157\n",
      "Epoch 97/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0180\n",
      "Epoch 98/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0163\n",
      "Epoch 99/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0163\n",
      "Epoch 100/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0174\n",
      "16/16 [==============================] - 3s 5ms/step\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_20 (LSTM)              (None, 1, 100)            47600     \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 1, 100)            0         \n",
      "                                                                 \n",
      " lstm_21 (LSTM)              (None, 50)                30200     \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, 50)                0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77,851\n",
      "Trainable params: 77,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "31/31 [==============================] - 13s 13ms/step - loss: 0.8750\n",
      "Epoch 2/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.1363\n",
      "Epoch 3/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0498\n",
      "Epoch 4/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0377\n",
      "Epoch 5/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0311\n",
      "Epoch 6/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0327\n",
      "Epoch 7/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0270\n",
      "Epoch 8/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0245\n",
      "Epoch 9/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0238\n",
      "Epoch 10/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0256\n",
      "Epoch 11/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0246\n",
      "Epoch 12/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0239\n",
      "Epoch 13/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0247\n",
      "Epoch 14/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0223\n",
      "Epoch 15/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0207\n",
      "Epoch 16/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0234\n",
      "Epoch 17/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0229\n",
      "Epoch 18/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0206\n",
      "Epoch 19/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0200\n",
      "Epoch 20/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0210\n",
      "Epoch 21/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0217\n",
      "Epoch 22/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0213\n",
      "Epoch 23/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0208\n",
      "Epoch 24/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0228\n",
      "Epoch 25/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0230\n",
      "Epoch 26/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0230\n",
      "Epoch 27/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0216\n",
      "Epoch 28/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0227\n",
      "Epoch 29/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0222\n",
      "Epoch 30/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0211\n",
      "Epoch 31/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0190\n",
      "Epoch 32/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0182\n",
      "Epoch 33/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0173\n",
      "Epoch 34/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0221\n",
      "Epoch 35/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0213\n",
      "Epoch 36/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0219\n",
      "Epoch 37/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0202\n",
      "Epoch 38/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0205\n",
      "Epoch 39/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0207\n",
      "Epoch 40/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0203\n",
      "Epoch 41/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0198\n",
      "Epoch 42/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0202\n",
      "Epoch 43/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0221\n",
      "Epoch 44/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0191\n",
      "Epoch 45/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0186\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0188\n",
      "Epoch 47/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0223\n",
      "Epoch 48/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0210\n",
      "Epoch 49/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0193\n",
      "Epoch 50/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0216\n",
      "Epoch 51/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0218\n",
      "Epoch 52/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0203\n",
      "Epoch 53/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0167\n",
      "Epoch 54/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0197\n",
      "Epoch 55/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0196\n",
      "Epoch 56/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0184\n",
      "Epoch 57/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0188\n",
      "Epoch 58/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0212\n",
      "Epoch 59/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0180\n",
      "Epoch 60/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0183\n",
      "Epoch 61/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0209\n",
      "Epoch 62/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0177\n",
      "Epoch 63/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0178\n",
      "Epoch 64/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0202\n",
      "Epoch 65/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0186\n",
      "Epoch 66/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0187\n",
      "Epoch 67/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0172\n",
      "Epoch 68/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0184\n",
      "Epoch 69/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0186\n",
      "Epoch 70/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0168\n",
      "Epoch 71/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0180\n",
      "Epoch 72/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0208\n",
      "Epoch 73/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0218\n",
      "Epoch 74/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0198\n",
      "Epoch 75/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0173\n",
      "Epoch 76/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0182\n",
      "Epoch 77/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0210\n",
      "Epoch 78/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0196\n",
      "Epoch 79/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0176\n",
      "Epoch 80/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0179\n",
      "Epoch 81/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0189\n",
      "Epoch 82/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0195\n",
      "Epoch 83/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0189\n",
      "Epoch 84/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0201\n",
      "Epoch 85/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0182\n",
      "Epoch 86/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0179\n",
      "Epoch 87/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0190\n",
      "Epoch 88/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0171\n",
      "Epoch 89/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0191\n",
      "Epoch 90/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.0196\n",
      "Epoch 91/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0174\n",
      "Epoch 92/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0162\n",
      "Epoch 93/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0194\n",
      "Epoch 94/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0195\n",
      "Epoch 95/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0173\n",
      "Epoch 96/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0183\n",
      "Epoch 97/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0173\n",
      "Epoch 98/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0203\n",
      "Epoch 99/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0175\n",
      "Epoch 100/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0202\n",
      "16/16 [==============================] - 3s 5ms/step\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_22 (LSTM)              (None, 1, 100)            47600     \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 1, 100)            0         \n",
      "                                                                 \n",
      " lstm_23 (LSTM)              (None, 100)               80400     \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        (None, 100)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 128,101\n",
      "Trainable params: 128,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "31/31 [==============================] - 12s 14ms/step - loss: 0.7182\n",
      "Epoch 2/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0697\n",
      "Epoch 3/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0346\n",
      "Epoch 4/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0268\n",
      "Epoch 5/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0249\n",
      "Epoch 6/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0235\n",
      "Epoch 7/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0216\n",
      "Epoch 8/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0210\n",
      "Epoch 9/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0221\n",
      "Epoch 10/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0206\n",
      "Epoch 11/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0216\n",
      "Epoch 12/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0211\n",
      "Epoch 13/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0185\n",
      "Epoch 14/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0181\n",
      "Epoch 15/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0189\n",
      "Epoch 16/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0186\n",
      "Epoch 17/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0197\n",
      "Epoch 18/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0202\n",
      "Epoch 19/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0200\n",
      "Epoch 20/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0175\n",
      "Epoch 21/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0175\n",
      "Epoch 22/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0186\n",
      "Epoch 23/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0152\n",
      "Epoch 24/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0161\n",
      "Epoch 25/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0194\n",
      "Epoch 26/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0180\n",
      "Epoch 27/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0173\n",
      "Epoch 28/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0163\n",
      "Epoch 29/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0156\n",
      "Epoch 30/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0174\n",
      "Epoch 31/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0157\n",
      "Epoch 32/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0177\n",
      "Epoch 33/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0163\n",
      "Epoch 34/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0169\n",
      "Epoch 35/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0180\n",
      "Epoch 36/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0177\n",
      "Epoch 37/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0186\n",
      "Epoch 38/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0188\n",
      "Epoch 39/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0179\n",
      "Epoch 40/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0184\n",
      "Epoch 41/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0166\n",
      "Epoch 42/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0160\n",
      "Epoch 43/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0191\n",
      "Epoch 44/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0157\n",
      "Epoch 45/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0155\n",
      "Epoch 46/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0153\n",
      "Epoch 47/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0175\n",
      "Epoch 48/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0142\n",
      "Epoch 49/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0159\n",
      "Epoch 50/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0139\n",
      "Epoch 51/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0151\n",
      "Epoch 52/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0171\n",
      "Epoch 53/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0153\n",
      "Epoch 54/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0154\n",
      "Epoch 55/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0176\n",
      "Epoch 56/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0187\n",
      "Epoch 57/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0156\n",
      "Epoch 58/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0162\n",
      "Epoch 59/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0156\n",
      "Epoch 60/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0173\n",
      "Epoch 61/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0156\n",
      "Epoch 62/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0171\n",
      "Epoch 63/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0167\n",
      "Epoch 64/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0169\n",
      "Epoch 65/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0166\n",
      "Epoch 66/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0164\n",
      "Epoch 67/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0162\n",
      "Epoch 68/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0159\n",
      "Epoch 69/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0155\n",
      "Epoch 70/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0169\n",
      "Epoch 71/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0169\n",
      "Epoch 72/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0173\n",
      "Epoch 73/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0180\n",
      "Epoch 74/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0164\n",
      "Epoch 75/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0152\n",
      "Epoch 76/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0169\n",
      "Epoch 77/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0186\n",
      "Epoch 78/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0180\n",
      "Epoch 79/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0144\n",
      "Epoch 80/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0164\n",
      "Epoch 81/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0178\n",
      "Epoch 82/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0132\n",
      "Epoch 83/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0163\n",
      "Epoch 84/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0162\n",
      "Epoch 85/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0155\n",
      "Epoch 86/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0148\n",
      "Epoch 87/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0169\n",
      "Epoch 88/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0149\n",
      "Epoch 89/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0158\n",
      "Epoch 90/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0156\n",
      "Epoch 91/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0141\n",
      "Epoch 92/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0157\n",
      "Epoch 93/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0150\n",
      "Epoch 94/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0165\n",
      "Epoch 95/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0155\n",
      "Epoch 96/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0135\n",
      "Epoch 97/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0160\n",
      "Epoch 98/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0153\n",
      "Epoch 99/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0150\n",
      "Epoch 100/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0151\n",
      "16/16 [==============================] - 3s 5ms/step\n",
      "Model: \"sequential_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_24 (LSTM)              (None, 1, 50)             13800     \n",
      "                                                                 \n",
      " dropout_24 (Dropout)        (None, 1, 50)             0         \n",
      "                                                                 \n",
      " lstm_25 (LSTM)              (None, 50)                20200     \n",
      "                                                                 \n",
      " dropout_25 (Dropout)        (None, 50)                0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34,051\n",
      "Trainable params: 34,051\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/150\n",
      "123/123 [==============================] - 13s 10ms/step - loss: 0.4149\n",
      "Epoch 2/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0480\n",
      "Epoch 3/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0340\n",
      "Epoch 4/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0335\n",
      "Epoch 5/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0332\n",
      "Epoch 6/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0315\n",
      "Epoch 7/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0273\n",
      "Epoch 8/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0254\n",
      "Epoch 9/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0262\n",
      "Epoch 10/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0256\n",
      "Epoch 11/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0273\n",
      "Epoch 12/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0242\n",
      "Epoch 13/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0255\n",
      "Epoch 14/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0229\n",
      "Epoch 15/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0252\n",
      "Epoch 16/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0240\n",
      "Epoch 17/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0272\n",
      "Epoch 18/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0244\n",
      "Epoch 19/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0261\n",
      "Epoch 20/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0228\n",
      "Epoch 21/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0238\n",
      "Epoch 22/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0234\n",
      "Epoch 23/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0242\n",
      "Epoch 24/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0238\n",
      "Epoch 25/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0225\n",
      "Epoch 26/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0240\n",
      "Epoch 27/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0214\n",
      "Epoch 28/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0216\n",
      "Epoch 29/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0223\n",
      "Epoch 30/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0185\n",
      "Epoch 31/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0229\n",
      "Epoch 32/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0229\n",
      "Epoch 33/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0231\n",
      "Epoch 34/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0217\n",
      "Epoch 35/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0210\n",
      "Epoch 36/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0212\n",
      "Epoch 37/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0220\n",
      "Epoch 38/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0229\n",
      "Epoch 39/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0243\n",
      "Epoch 40/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0215\n",
      "Epoch 41/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0232\n",
      "Epoch 42/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0216\n",
      "Epoch 43/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0205\n",
      "Epoch 44/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0184\n",
      "Epoch 45/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0233\n",
      "Epoch 46/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0200\n",
      "Epoch 47/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0202\n",
      "Epoch 48/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0183\n",
      "Epoch 49/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0191\n",
      "Epoch 50/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0225\n",
      "Epoch 51/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0195\n",
      "Epoch 52/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0210\n",
      "Epoch 53/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0235\n",
      "Epoch 54/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0205\n",
      "Epoch 55/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0220\n",
      "Epoch 56/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0236\n",
      "Epoch 57/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0177\n",
      "Epoch 58/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0183\n",
      "Epoch 59/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0195\n",
      "Epoch 60/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0243\n",
      "Epoch 61/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0221\n",
      "Epoch 62/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0224\n",
      "Epoch 63/150\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.0206\n",
      "Epoch 64/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0205\n",
      "Epoch 65/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0204\n",
      "Epoch 66/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0190\n",
      "Epoch 67/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0214\n",
      "Epoch 68/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0204\n",
      "Epoch 69/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0224\n",
      "Epoch 70/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0216\n",
      "Epoch 71/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0222\n",
      "Epoch 72/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0226\n",
      "Epoch 73/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0212\n",
      "Epoch 74/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0212\n",
      "Epoch 75/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0192\n",
      "Epoch 76/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0201\n",
      "Epoch 77/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0178\n",
      "Epoch 78/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0189\n",
      "Epoch 79/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0190\n",
      "Epoch 80/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0190\n",
      "Epoch 81/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0189\n",
      "Epoch 82/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0186\n",
      "Epoch 83/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0221\n",
      "Epoch 84/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0205\n",
      "Epoch 85/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0204\n",
      "Epoch 86/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0183\n",
      "Epoch 87/150\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.0190\n",
      "Epoch 88/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0184\n",
      "Epoch 89/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0194\n",
      "Epoch 90/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0190\n",
      "Epoch 91/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0251\n",
      "Epoch 92/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0191\n",
      "Epoch 93/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0182\n",
      "Epoch 94/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0203\n",
      "Epoch 95/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0178\n",
      "Epoch 96/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0172\n",
      "Epoch 97/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0188\n",
      "Epoch 98/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0228\n",
      "Epoch 99/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0202\n",
      "Epoch 100/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0180\n",
      "Epoch 101/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0188\n",
      "Epoch 102/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0203\n",
      "Epoch 103/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0183\n",
      "Epoch 104/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0197\n",
      "Epoch 105/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0200\n",
      "Epoch 106/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0202\n",
      "Epoch 107/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0203\n",
      "Epoch 108/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0178\n",
      "Epoch 109/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0181\n",
      "Epoch 110/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0202\n",
      "Epoch 111/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0181\n",
      "Epoch 112/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0172\n",
      "Epoch 113/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0209\n",
      "Epoch 114/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0191\n",
      "Epoch 115/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0159\n",
      "Epoch 116/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0209\n",
      "Epoch 117/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0193\n",
      "Epoch 118/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0160\n",
      "Epoch 119/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0179\n",
      "Epoch 120/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0191\n",
      "Epoch 121/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0180\n",
      "Epoch 122/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0190\n",
      "Epoch 123/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0197\n",
      "Epoch 124/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0199\n",
      "Epoch 125/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0181\n",
      "Epoch 126/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0213\n",
      "Epoch 127/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0189\n",
      "Epoch 128/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0209\n",
      "Epoch 129/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0164\n",
      "Epoch 130/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0212\n",
      "Epoch 131/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0170\n",
      "Epoch 132/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0196\n",
      "Epoch 133/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0182\n",
      "Epoch 134/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0180\n",
      "Epoch 135/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0175\n",
      "Epoch 136/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0202\n",
      "Epoch 137/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0179\n",
      "Epoch 138/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0186\n",
      "Epoch 139/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0171\n",
      "Epoch 140/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0197\n",
      "Epoch 141/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0198\n",
      "Epoch 142/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0205\n",
      "Epoch 143/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0186\n",
      "Epoch 144/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0193\n",
      "Epoch 145/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0185\n",
      "Epoch 146/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0173\n",
      "Epoch 147/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0168\n",
      "Epoch 148/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0172\n",
      "Epoch 149/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0179\n",
      "Epoch 150/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0180\n",
      "16/16 [==============================] - 3s 5ms/step\n",
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_26 (LSTM)              (None, 1, 50)             13800     \n",
      "                                                                 \n",
      " dropout_26 (Dropout)        (None, 1, 50)             0         \n",
      "                                                                 \n",
      " lstm_27 (LSTM)              (None, 100)               60400     \n",
      "                                                                 \n",
      " dropout_27 (Dropout)        (None, 100)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 74,301\n",
      "Trainable params: 74,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/150\n",
      "123/123 [==============================] - 14s 10ms/step - loss: 0.4216\n",
      "Epoch 2/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0351\n",
      "Epoch 3/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0319\n",
      "Epoch 4/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0270\n",
      "Epoch 5/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0290\n",
      "Epoch 6/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0250\n",
      "Epoch 7/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0258\n",
      "Epoch 8/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0255\n",
      "Epoch 9/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0287\n",
      "Epoch 10/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0210\n",
      "Epoch 11/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0273\n",
      "Epoch 12/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0256\n",
      "Epoch 13/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0260\n",
      "Epoch 14/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0216\n",
      "Epoch 15/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0205\n",
      "Epoch 16/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0218\n",
      "Epoch 17/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0220\n",
      "Epoch 18/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0197\n",
      "Epoch 19/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0194\n",
      "Epoch 20/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0202\n",
      "Epoch 21/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0186\n",
      "Epoch 22/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0209\n",
      "Epoch 23/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0216\n",
      "Epoch 24/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0203\n",
      "Epoch 25/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0196\n",
      "Epoch 26/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0212\n",
      "Epoch 27/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0184\n",
      "Epoch 28/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0180\n",
      "Epoch 29/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0185\n",
      "Epoch 30/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0199\n",
      "Epoch 31/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0219\n",
      "Epoch 32/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0210\n",
      "Epoch 33/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0185\n",
      "Epoch 34/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0190\n",
      "Epoch 35/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0205\n",
      "Epoch 36/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0199\n",
      "Epoch 37/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0182\n",
      "Epoch 38/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0179\n",
      "Epoch 39/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0189\n",
      "Epoch 40/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0188\n",
      "Epoch 41/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0207\n",
      "Epoch 42/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0199\n",
      "Epoch 43/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0175\n",
      "Epoch 44/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0179\n",
      "Epoch 45/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0177\n",
      "Epoch 46/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0165\n",
      "Epoch 47/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0203\n",
      "Epoch 48/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0195\n",
      "Epoch 49/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0177\n",
      "Epoch 50/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0180\n",
      "Epoch 51/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0178\n",
      "Epoch 52/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0155\n",
      "Epoch 53/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0174\n",
      "Epoch 54/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0174\n",
      "Epoch 55/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0176\n",
      "Epoch 56/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0179\n",
      "Epoch 57/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0161\n",
      "Epoch 58/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0168\n",
      "Epoch 59/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0169\n",
      "Epoch 60/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0207\n",
      "Epoch 61/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0170\n",
      "Epoch 62/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0172\n",
      "Epoch 63/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0177\n",
      "Epoch 64/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0158\n",
      "Epoch 65/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0161\n",
      "Epoch 66/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0176\n",
      "Epoch 67/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0188\n",
      "Epoch 68/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0184\n",
      "Epoch 69/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0171\n",
      "Epoch 70/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0166\n",
      "Epoch 71/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0150\n",
      "Epoch 72/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0176\n",
      "Epoch 73/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0191\n",
      "Epoch 74/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0174\n",
      "Epoch 75/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0157\n",
      "Epoch 76/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0159\n",
      "Epoch 77/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0157\n",
      "Epoch 78/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0156\n",
      "Epoch 79/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0161\n",
      "Epoch 80/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0169\n",
      "Epoch 81/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0164\n",
      "Epoch 82/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0196\n",
      "Epoch 83/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0194\n",
      "Epoch 84/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0172\n",
      "Epoch 85/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0161\n",
      "Epoch 86/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0164\n",
      "Epoch 87/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0184\n",
      "Epoch 88/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0156\n",
      "Epoch 89/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0167\n",
      "Epoch 90/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0162\n",
      "Epoch 91/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0182\n",
      "Epoch 92/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0185\n",
      "Epoch 93/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0160\n",
      "Epoch 94/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0155\n",
      "Epoch 95/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0165\n",
      "Epoch 96/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0171\n",
      "Epoch 97/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0158\n",
      "Epoch 98/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0152\n",
      "Epoch 99/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0148\n",
      "Epoch 100/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0151\n",
      "Epoch 101/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0152\n",
      "Epoch 102/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0162\n",
      "Epoch 103/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0187\n",
      "Epoch 104/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0176\n",
      "Epoch 105/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0165\n",
      "Epoch 106/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0155\n",
      "Epoch 107/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0161\n",
      "Epoch 108/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0156\n",
      "Epoch 109/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0179\n",
      "Epoch 110/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0162\n",
      "Epoch 111/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0149\n",
      "Epoch 112/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0175\n",
      "Epoch 113/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0162\n",
      "Epoch 114/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0158\n",
      "Epoch 115/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0152\n",
      "Epoch 116/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0161\n",
      "Epoch 117/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0160\n",
      "Epoch 118/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0169\n",
      "Epoch 119/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0145\n",
      "Epoch 120/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0158\n",
      "Epoch 121/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0159\n",
      "Epoch 122/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0152\n",
      "Epoch 123/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0160\n",
      "Epoch 124/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0165\n",
      "Epoch 125/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0166\n",
      "Epoch 126/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0143\n",
      "Epoch 127/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0139\n",
      "Epoch 128/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0151\n",
      "Epoch 129/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0172\n",
      "Epoch 130/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0155\n",
      "Epoch 131/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0176\n",
      "Epoch 132/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0152\n",
      "Epoch 133/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0174\n",
      "Epoch 134/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0144\n",
      "Epoch 135/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0147\n",
      "Epoch 136/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0168\n",
      "Epoch 137/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0144\n",
      "Epoch 138/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0146\n",
      "Epoch 139/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0128\n",
      "Epoch 140/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0167\n",
      "Epoch 141/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0169\n",
      "Epoch 142/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0154\n",
      "Epoch 143/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0148\n",
      "Epoch 144/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0162\n",
      "Epoch 145/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0148\n",
      "Epoch 146/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0144\n",
      "Epoch 147/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0137\n",
      "Epoch 148/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0150\n",
      "Epoch 149/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0147\n",
      "Epoch 150/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0142\n",
      "16/16 [==============================] - 3s 5ms/step\n",
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_28 (LSTM)              (None, 1, 100)            47600     \n",
      "                                                                 \n",
      " dropout_28 (Dropout)        (None, 1, 100)            0         \n",
      "                                                                 \n",
      " lstm_29 (LSTM)              (None, 50)                30200     \n",
      "                                                                 \n",
      " dropout_29 (Dropout)        (None, 50)                0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77,851\n",
      "Trainable params: 77,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/150\n",
      "123/123 [==============================] - 14s 10ms/step - loss: 0.3084\n",
      "Epoch 2/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0308\n",
      "Epoch 3/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0290\n",
      "Epoch 4/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0264\n",
      "Epoch 5/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0291\n",
      "Epoch 6/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0249\n",
      "Epoch 7/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0234\n",
      "Epoch 8/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0233\n",
      "Epoch 9/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0249\n",
      "Epoch 10/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0228\n",
      "Epoch 11/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0230\n",
      "Epoch 12/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0200\n",
      "Epoch 13/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0259\n",
      "Epoch 14/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0224\n",
      "Epoch 15/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0232\n",
      "Epoch 16/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0227\n",
      "Epoch 17/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0216\n",
      "Epoch 18/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0206\n",
      "Epoch 19/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0228\n",
      "Epoch 20/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0219\n",
      "Epoch 21/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0239\n",
      "Epoch 22/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0216\n",
      "Epoch 23/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0186\n",
      "Epoch 24/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0239\n",
      "Epoch 25/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0211\n",
      "Epoch 26/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0190\n",
      "Epoch 27/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0199\n",
      "Epoch 28/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0201\n",
      "Epoch 29/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0207\n",
      "Epoch 30/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0204\n",
      "Epoch 31/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0188\n",
      "Epoch 32/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0204\n",
      "Epoch 33/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0207\n",
      "Epoch 34/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0210\n",
      "Epoch 35/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0179\n",
      "Epoch 36/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0186\n",
      "Epoch 37/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0219\n",
      "Epoch 38/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0199\n",
      "Epoch 39/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0203\n",
      "Epoch 40/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0211\n",
      "Epoch 41/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0209\n",
      "Epoch 42/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0240\n",
      "Epoch 43/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0192\n",
      "Epoch 44/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0223\n",
      "Epoch 45/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0205\n",
      "Epoch 46/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0179\n",
      "Epoch 47/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0173\n",
      "Epoch 48/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0224\n",
      "Epoch 49/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0211\n",
      "Epoch 50/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0204\n",
      "Epoch 51/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0165\n",
      "Epoch 52/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0199\n",
      "Epoch 53/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0183\n",
      "Epoch 54/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0174\n",
      "Epoch 55/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0197\n",
      "Epoch 56/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0209\n",
      "Epoch 57/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0205\n",
      "Epoch 58/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0194\n",
      "Epoch 59/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0195\n",
      "Epoch 60/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0202\n",
      "Epoch 61/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0180\n",
      "Epoch 62/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0200\n",
      "Epoch 63/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0167\n",
      "Epoch 64/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0185\n",
      "Epoch 65/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0201\n",
      "Epoch 66/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0179\n",
      "Epoch 67/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0189\n",
      "Epoch 68/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0186\n",
      "Epoch 69/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0182\n",
      "Epoch 70/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0192\n",
      "Epoch 71/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0217\n",
      "Epoch 72/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0211\n",
      "Epoch 73/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0173\n",
      "Epoch 74/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0165\n",
      "Epoch 75/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0198\n",
      "Epoch 76/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0165\n",
      "Epoch 77/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0187\n",
      "Epoch 78/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0176\n",
      "Epoch 79/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0195\n",
      "Epoch 80/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0174\n",
      "Epoch 81/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0205\n",
      "Epoch 82/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0176\n",
      "Epoch 83/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0200\n",
      "Epoch 84/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0169\n",
      "Epoch 85/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0193\n",
      "Epoch 86/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0172\n",
      "Epoch 87/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0211\n",
      "Epoch 88/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0189\n",
      "Epoch 89/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0171\n",
      "Epoch 90/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0191\n",
      "Epoch 91/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0171\n",
      "Epoch 92/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0162\n",
      "Epoch 93/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0188\n",
      "Epoch 94/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0175\n",
      "Epoch 95/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0196\n",
      "Epoch 96/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0167\n",
      "Epoch 97/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0171\n",
      "Epoch 98/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0171\n",
      "Epoch 99/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0186\n",
      "Epoch 100/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0169\n",
      "Epoch 101/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0173\n",
      "Epoch 102/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0150\n",
      "Epoch 103/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0155\n",
      "Epoch 104/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0185\n",
      "Epoch 105/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0157\n",
      "Epoch 106/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0188\n",
      "Epoch 107/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0188\n",
      "Epoch 108/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0175\n",
      "Epoch 109/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0209\n",
      "Epoch 110/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0176\n",
      "Epoch 111/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0185\n",
      "Epoch 112/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0181\n",
      "Epoch 113/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0165\n",
      "Epoch 114/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0164\n",
      "Epoch 115/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0190\n",
      "Epoch 116/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0174\n",
      "Epoch 117/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0174\n",
      "Epoch 118/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0174\n",
      "Epoch 119/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0170\n",
      "Epoch 120/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0159\n",
      "Epoch 121/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0168\n",
      "Epoch 122/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0157\n",
      "Epoch 123/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0187\n",
      "Epoch 124/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0165\n",
      "Epoch 125/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0168\n",
      "Epoch 126/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0184\n",
      "Epoch 127/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0170\n",
      "Epoch 128/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0170\n",
      "Epoch 129/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0140\n",
      "Epoch 130/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0163\n",
      "Epoch 131/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0163\n",
      "Epoch 132/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0171\n",
      "Epoch 133/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0154\n",
      "Epoch 134/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0159\n",
      "Epoch 135/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0148\n",
      "Epoch 136/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0160\n",
      "Epoch 137/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0160\n",
      "Epoch 138/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0166\n",
      "Epoch 139/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0176\n",
      "Epoch 140/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0145\n",
      "Epoch 141/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0160\n",
      "Epoch 142/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0156\n",
      "Epoch 143/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0144\n",
      "Epoch 144/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0172\n",
      "Epoch 145/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0175\n",
      "Epoch 146/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0155\n",
      "Epoch 147/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0191\n",
      "Epoch 148/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0187\n",
      "Epoch 149/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0149\n",
      "Epoch 150/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0158\n",
      "16/16 [==============================] - 3s 5ms/step\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_30 (LSTM)              (None, 1, 100)            47600     \n",
      "                                                                 \n",
      " dropout_30 (Dropout)        (None, 1, 100)            0         \n",
      "                                                                 \n",
      " lstm_31 (LSTM)              (None, 100)               80400     \n",
      "                                                                 \n",
      " dropout_31 (Dropout)        (None, 100)               0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 128,101\n",
      "Trainable params: 128,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/150\n",
      "123/123 [==============================] - 13s 11ms/step - loss: 0.2526\n",
      "Epoch 2/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0290\n",
      "Epoch 3/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0223\n",
      "Epoch 4/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0227\n",
      "Epoch 5/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0202\n",
      "Epoch 6/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0208\n",
      "Epoch 7/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0222\n",
      "Epoch 8/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0203\n",
      "Epoch 9/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0194\n",
      "Epoch 10/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0218\n",
      "Epoch 11/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0222\n",
      "Epoch 12/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0213\n",
      "Epoch 13/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0192\n",
      "Epoch 14/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0222\n",
      "Epoch 15/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0168\n",
      "Epoch 16/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0235\n",
      "Epoch 17/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0187\n",
      "Epoch 18/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0183\n",
      "Epoch 19/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0186\n",
      "Epoch 20/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0202\n",
      "Epoch 21/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0188\n",
      "Epoch 22/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0184\n",
      "Epoch 23/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0177\n",
      "Epoch 24/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0167\n",
      "Epoch 25/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0166\n",
      "Epoch 26/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0183\n",
      "Epoch 27/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0156\n",
      "Epoch 28/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0163\n",
      "Epoch 29/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0156\n",
      "Epoch 30/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0184\n",
      "Epoch 31/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0178\n",
      "Epoch 32/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0158\n",
      "Epoch 33/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0170\n",
      "Epoch 34/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0155\n",
      "Epoch 35/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0177\n",
      "Epoch 36/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0165\n",
      "Epoch 37/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0157\n",
      "Epoch 38/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0195\n",
      "Epoch 39/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0167\n",
      "Epoch 40/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0158\n",
      "Epoch 41/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0180\n",
      "Epoch 42/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0203\n",
      "Epoch 43/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0178\n",
      "Epoch 44/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0177\n",
      "Epoch 45/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0178\n",
      "Epoch 46/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0178\n",
      "Epoch 47/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0157\n",
      "Epoch 48/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0150\n",
      "Epoch 49/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0164\n",
      "Epoch 50/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0201\n",
      "Epoch 51/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0184\n",
      "Epoch 52/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0154\n",
      "Epoch 53/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0156\n",
      "Epoch 54/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0159\n",
      "Epoch 55/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0173\n",
      "Epoch 56/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0160\n",
      "Epoch 57/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0174\n",
      "Epoch 58/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0163\n",
      "Epoch 59/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0170\n",
      "Epoch 60/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0160\n",
      "Epoch 61/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0156\n",
      "Epoch 62/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0169\n",
      "Epoch 63/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0173\n",
      "Epoch 64/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0152\n",
      "Epoch 65/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0166\n",
      "Epoch 66/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0163\n",
      "Epoch 67/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0155\n",
      "Epoch 68/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0173\n",
      "Epoch 69/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0152\n",
      "Epoch 70/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0180\n",
      "Epoch 71/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0159\n",
      "Epoch 72/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0157\n",
      "Epoch 73/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0167\n",
      "Epoch 74/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0144\n",
      "Epoch 75/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0150\n",
      "Epoch 76/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0183\n",
      "Epoch 77/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0149\n",
      "Epoch 78/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0149\n",
      "Epoch 79/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0169\n",
      "Epoch 80/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0165\n",
      "Epoch 81/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0146\n",
      "Epoch 82/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0144\n",
      "Epoch 83/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0162\n",
      "Epoch 84/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0170\n",
      "Epoch 85/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0138\n",
      "Epoch 86/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0168\n",
      "Epoch 87/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0150\n",
      "Epoch 88/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0146\n",
      "Epoch 89/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0146\n",
      "Epoch 90/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0154\n",
      "Epoch 91/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0162\n",
      "Epoch 92/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0151\n",
      "Epoch 93/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0141\n",
      "Epoch 94/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0143\n",
      "Epoch 95/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0129\n",
      "Epoch 96/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0154\n",
      "Epoch 97/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0137\n",
      "Epoch 98/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0177\n",
      "Epoch 99/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0154\n",
      "Epoch 100/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0153\n",
      "Epoch 101/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0158\n",
      "Epoch 102/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0171\n",
      "Epoch 103/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0142\n",
      "Epoch 104/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0158\n",
      "Epoch 105/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0163\n",
      "Epoch 106/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0151\n",
      "Epoch 107/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0140\n",
      "Epoch 108/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0152\n",
      "Epoch 109/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0138\n",
      "Epoch 110/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0158\n",
      "Epoch 111/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0149\n",
      "Epoch 112/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0152\n",
      "Epoch 113/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0146\n",
      "Epoch 114/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0171\n",
      "Epoch 115/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0138\n",
      "Epoch 116/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0147\n",
      "Epoch 117/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0148\n",
      "Epoch 118/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0132\n",
      "Epoch 119/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0136\n",
      "Epoch 120/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0133\n",
      "Epoch 121/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0136\n",
      "Epoch 122/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0135\n",
      "Epoch 123/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0141\n",
      "Epoch 124/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0153\n",
      "Epoch 125/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0150\n",
      "Epoch 126/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0138\n",
      "Epoch 127/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0147\n",
      "Epoch 128/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0131\n",
      "Epoch 129/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0129\n",
      "Epoch 130/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0137\n",
      "Epoch 131/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0149\n",
      "Epoch 132/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0130\n",
      "Epoch 133/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0134\n",
      "Epoch 134/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0137\n",
      "Epoch 135/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0145\n",
      "Epoch 136/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0162\n",
      "Epoch 137/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0128\n",
      "Epoch 138/150\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0150\n",
      "Epoch 139/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0138\n",
      "Epoch 140/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0128\n",
      "Epoch 141/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0141\n",
      "Epoch 142/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0142\n",
      "Epoch 143/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0155\n",
      "Epoch 144/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0145\n",
      "Epoch 145/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0136\n",
      "Epoch 146/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0138\n",
      "Epoch 147/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0142\n",
      "Epoch 148/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0131\n",
      "Epoch 149/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0135\n",
      "Epoch 150/150\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0136\n",
      "16/16 [==============================] - 3s 6ms/step\n",
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_32 (LSTM)              (None, 1, 50)             13800     \n",
      "                                                                 \n",
      " dropout_32 (Dropout)        (None, 1, 50)             0         \n",
      "                                                                 \n",
      " lstm_33 (LSTM)              (None, 50)                20200     \n",
      "                                                                 \n",
      " dropout_33 (Dropout)        (None, 50)                0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34,051\n",
      "Trainable params: 34,051\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/150\n",
      "62/62 [==============================] - 13s 10ms/step - loss: 0.7298\n",
      "Epoch 2/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0777\n",
      "Epoch 3/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0441\n",
      "Epoch 4/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0394\n",
      "Epoch 5/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0310\n",
      "Epoch 6/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0313\n",
      "Epoch 7/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0289\n",
      "Epoch 8/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0311\n",
      "Epoch 9/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0281\n",
      "Epoch 10/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0289\n",
      "Epoch 11/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0248\n",
      "Epoch 12/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0304\n",
      "Epoch 13/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0259\n",
      "Epoch 14/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0278\n",
      "Epoch 15/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0266\n",
      "Epoch 16/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0214\n",
      "Epoch 17/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0227\n",
      "Epoch 18/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0283\n",
      "Epoch 19/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0244\n",
      "Epoch 20/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0233\n",
      "Epoch 21/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0251\n",
      "Epoch 22/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0279\n",
      "Epoch 23/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0248\n",
      "Epoch 24/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0222\n",
      "Epoch 25/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0197\n",
      "Epoch 26/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0257\n",
      "Epoch 27/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0228\n",
      "Epoch 28/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0233\n",
      "Epoch 29/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0217\n",
      "Epoch 30/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0221\n",
      "Epoch 31/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0209\n",
      "Epoch 32/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0228\n",
      "Epoch 33/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0241\n",
      "Epoch 34/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0231\n",
      "Epoch 35/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0218\n",
      "Epoch 36/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0213\n",
      "Epoch 37/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0250\n",
      "Epoch 38/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0208\n",
      "Epoch 39/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0234\n",
      "Epoch 40/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0233\n",
      "Epoch 41/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0223\n",
      "Epoch 42/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0257\n",
      "Epoch 43/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0212\n",
      "Epoch 44/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0207\n",
      "Epoch 45/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0208\n",
      "Epoch 46/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0212\n",
      "Epoch 47/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0244\n",
      "Epoch 48/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0192\n",
      "Epoch 49/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0198\n",
      "Epoch 50/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0204\n",
      "Epoch 51/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0244\n",
      "Epoch 52/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0194\n",
      "Epoch 53/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0220\n",
      "Epoch 54/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0221\n",
      "Epoch 55/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0227\n",
      "Epoch 56/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0214\n",
      "Epoch 57/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0206\n",
      "Epoch 58/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0223\n",
      "Epoch 59/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0189\n",
      "Epoch 60/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0216\n",
      "Epoch 61/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0217\n",
      "Epoch 62/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0216\n",
      "Epoch 63/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0196\n",
      "Epoch 64/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0194\n",
      "Epoch 65/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0198\n",
      "Epoch 66/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0220\n",
      "Epoch 67/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0195\n",
      "Epoch 68/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0197\n",
      "Epoch 69/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0204\n",
      "Epoch 70/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0201\n",
      "Epoch 71/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0183\n",
      "Epoch 72/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0198\n",
      "Epoch 73/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0189\n",
      "Epoch 74/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0180\n",
      "Epoch 75/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0214\n",
      "Epoch 76/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0197\n",
      "Epoch 77/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0233\n",
      "Epoch 78/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0224\n",
      "Epoch 79/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0189\n",
      "Epoch 80/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0198\n",
      "Epoch 81/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0198\n",
      "Epoch 82/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0183\n",
      "Epoch 83/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0192\n",
      "Epoch 84/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0180\n",
      "Epoch 85/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0189\n",
      "Epoch 86/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0184\n",
      "Epoch 87/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0215\n",
      "Epoch 88/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0215\n",
      "Epoch 89/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0194\n",
      "Epoch 90/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0210\n",
      "Epoch 91/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0222\n",
      "Epoch 92/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0171\n",
      "Epoch 93/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0207\n",
      "Epoch 94/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0212\n",
      "Epoch 95/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0184\n",
      "Epoch 96/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0180\n",
      "Epoch 97/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0203\n",
      "Epoch 98/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0185\n",
      "Epoch 99/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0185\n",
      "Epoch 100/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0169\n",
      "Epoch 101/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0188\n",
      "Epoch 102/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0193\n",
      "Epoch 103/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0194\n",
      "Epoch 104/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0198\n",
      "Epoch 105/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0191\n",
      "Epoch 106/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0208\n",
      "Epoch 107/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0173\n",
      "Epoch 108/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0191\n",
      "Epoch 109/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0165\n",
      "Epoch 110/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0189\n",
      "Epoch 111/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0190\n",
      "Epoch 112/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0184\n",
      "Epoch 113/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0193\n",
      "Epoch 114/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0179\n",
      "Epoch 115/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0197\n",
      "Epoch 116/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0190\n",
      "Epoch 117/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0193\n",
      "Epoch 118/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0169\n",
      "Epoch 119/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0199\n",
      "Epoch 120/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0193\n",
      "Epoch 121/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0182\n",
      "Epoch 122/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0199\n",
      "Epoch 123/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0170\n",
      "Epoch 124/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0183\n",
      "Epoch 125/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0177\n",
      "Epoch 126/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0174\n",
      "Epoch 127/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0169\n",
      "Epoch 128/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0195\n",
      "Epoch 129/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0181\n",
      "Epoch 130/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0199\n",
      "Epoch 131/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0225\n",
      "Epoch 132/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0160\n",
      "Epoch 133/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0199\n",
      "Epoch 134/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0188\n",
      "Epoch 135/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0184\n",
      "Epoch 136/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0196\n",
      "Epoch 137/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0191\n",
      "Epoch 138/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0215\n",
      "Epoch 139/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0164\n",
      "Epoch 140/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0171\n",
      "Epoch 141/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0175\n",
      "Epoch 142/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0204\n",
      "Epoch 143/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0155\n",
      "Epoch 144/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0180\n",
      "Epoch 145/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0164\n",
      "Epoch 146/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0184\n",
      "Epoch 147/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0165\n",
      "Epoch 148/150\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0185\n",
      "Epoch 149/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0182\n",
      "Epoch 150/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0177\n",
      "16/16 [==============================] - 3s 5ms/step\n",
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_34 (LSTM)              (None, 1, 50)             13800     \n",
      "                                                                 \n",
      " dropout_34 (Dropout)        (None, 1, 50)             0         \n",
      "                                                                 \n",
      " lstm_35 (LSTM)              (None, 100)               60400     \n",
      "                                                                 \n",
      " dropout_35 (Dropout)        (None, 100)               0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 74,301\n",
      "Trainable params: 74,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/150\n",
      "62/62 [==============================] - 14s 11ms/step - loss: 0.5727\n",
      "Epoch 2/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0447\n",
      "Epoch 3/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0326\n",
      "Epoch 4/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0289\n",
      "Epoch 5/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0274\n",
      "Epoch 6/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0260\n",
      "Epoch 7/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0251\n",
      "Epoch 8/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0258\n",
      "Epoch 9/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0245\n",
      "Epoch 10/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0241\n",
      "Epoch 11/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0232\n",
      "Epoch 12/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0228\n",
      "Epoch 13/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0244\n",
      "Epoch 14/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0237\n",
      "Epoch 15/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0209\n",
      "Epoch 16/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0236\n",
      "Epoch 17/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0221\n",
      "Epoch 18/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0192\n",
      "Epoch 19/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0231\n",
      "Epoch 20/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0213\n",
      "Epoch 21/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0232\n",
      "Epoch 22/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0214\n",
      "Epoch 23/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0215\n",
      "Epoch 24/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0222\n",
      "Epoch 25/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0196\n",
      "Epoch 26/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0205\n",
      "Epoch 27/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0201\n",
      "Epoch 28/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0202\n",
      "Epoch 29/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0207\n",
      "Epoch 30/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0209\n",
      "Epoch 31/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0188\n",
      "Epoch 32/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0184\n",
      "Epoch 33/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0244\n",
      "Epoch 34/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0199\n",
      "Epoch 35/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0191\n",
      "Epoch 36/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0177\n",
      "Epoch 37/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0179\n",
      "Epoch 38/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0198\n",
      "Epoch 39/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0187\n",
      "Epoch 40/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0194\n",
      "Epoch 41/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0179\n",
      "Epoch 42/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0188\n",
      "Epoch 43/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0207\n",
      "Epoch 44/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0184\n",
      "Epoch 45/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0195\n",
      "Epoch 46/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0205\n",
      "Epoch 47/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0191\n",
      "Epoch 48/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0188\n",
      "Epoch 49/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0180\n",
      "Epoch 50/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0179\n",
      "Epoch 51/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0170\n",
      "Epoch 52/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0167\n",
      "Epoch 53/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0169\n",
      "Epoch 54/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0167\n",
      "Epoch 55/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0161\n",
      "Epoch 56/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0186\n",
      "Epoch 57/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0184\n",
      "Epoch 58/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0185\n",
      "Epoch 59/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0150\n",
      "Epoch 60/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0190\n",
      "Epoch 61/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0163\n",
      "Epoch 62/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0182\n",
      "Epoch 63/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0185\n",
      "Epoch 64/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0169\n",
      "Epoch 65/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0187\n",
      "Epoch 66/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0190\n",
      "Epoch 67/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0173\n",
      "Epoch 68/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0170\n",
      "Epoch 69/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0180\n",
      "Epoch 70/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0169\n",
      "Epoch 71/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0187\n",
      "Epoch 72/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0185\n",
      "Epoch 73/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0170\n",
      "Epoch 74/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0156\n",
      "Epoch 75/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0173\n",
      "Epoch 76/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0169\n",
      "Epoch 77/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0168\n",
      "Epoch 78/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0175\n",
      "Epoch 79/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0189\n",
      "Epoch 80/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0167\n",
      "Epoch 81/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0161\n",
      "Epoch 82/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0180\n",
      "Epoch 83/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0153\n",
      "Epoch 84/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0155\n",
      "Epoch 85/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0156\n",
      "Epoch 86/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0173\n",
      "Epoch 87/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0158\n",
      "Epoch 88/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0168\n",
      "Epoch 89/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0159\n",
      "Epoch 90/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0176\n",
      "Epoch 91/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0165\n",
      "Epoch 92/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0179\n",
      "Epoch 93/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0159\n",
      "Epoch 94/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0149\n",
      "Epoch 95/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0157\n",
      "Epoch 96/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0169\n",
      "Epoch 97/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0180\n",
      "Epoch 98/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0151\n",
      "Epoch 99/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0185\n",
      "Epoch 100/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0176\n",
      "Epoch 101/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0172\n",
      "Epoch 102/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0163\n",
      "Epoch 103/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0153\n",
      "Epoch 104/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0157\n",
      "Epoch 105/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0170\n",
      "Epoch 106/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0188\n",
      "Epoch 107/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0157\n",
      "Epoch 108/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0159\n",
      "Epoch 109/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0158\n",
      "Epoch 110/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0158\n",
      "Epoch 111/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0174\n",
      "Epoch 112/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0156\n",
      "Epoch 113/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0175\n",
      "Epoch 114/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0169\n",
      "Epoch 115/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0158\n",
      "Epoch 116/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0150\n",
      "Epoch 117/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0172\n",
      "Epoch 118/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0164\n",
      "Epoch 119/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0148\n",
      "Epoch 120/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0142\n",
      "Epoch 121/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0163\n",
      "Epoch 122/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0180\n",
      "Epoch 123/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0166\n",
      "Epoch 124/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0170\n",
      "Epoch 125/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0157\n",
      "Epoch 126/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0154\n",
      "Epoch 127/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0145\n",
      "Epoch 128/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0140\n",
      "Epoch 129/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0179\n",
      "Epoch 130/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0170\n",
      "Epoch 131/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0158\n",
      "Epoch 132/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0165\n",
      "Epoch 133/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0140\n",
      "Epoch 134/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0154\n",
      "Epoch 135/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0148\n",
      "Epoch 136/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0149\n",
      "Epoch 137/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0165\n",
      "Epoch 138/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0139\n",
      "Epoch 139/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0175\n",
      "Epoch 140/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0164\n",
      "Epoch 141/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0143\n",
      "Epoch 142/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0164\n",
      "Epoch 143/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0161\n",
      "Epoch 144/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0149\n",
      "Epoch 145/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0155\n",
      "Epoch 146/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0167\n",
      "Epoch 147/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0148\n",
      "Epoch 148/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0155\n",
      "Epoch 149/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0154\n",
      "Epoch 150/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0142\n",
      "16/16 [==============================] - 2s 5ms/step\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_36 (LSTM)              (None, 1, 100)            47600     \n",
      "                                                                 \n",
      " dropout_36 (Dropout)        (None, 1, 100)            0         \n",
      "                                                                 \n",
      " lstm_37 (LSTM)              (None, 50)                30200     \n",
      "                                                                 \n",
      " dropout_37 (Dropout)        (None, 50)                0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77,851\n",
      "Trainable params: 77,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/150\n",
      "62/62 [==============================] - 12s 11ms/step - loss: 0.5058\n",
      "Epoch 2/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0536\n",
      "Epoch 3/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0310\n",
      "Epoch 4/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0310\n",
      "Epoch 5/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0240\n",
      "Epoch 6/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0239\n",
      "Epoch 7/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0288\n",
      "Epoch 8/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0255\n",
      "Epoch 9/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0230\n",
      "Epoch 10/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0265\n",
      "Epoch 11/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0238\n",
      "Epoch 12/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0253\n",
      "Epoch 13/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0230\n",
      "Epoch 14/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0243\n",
      "Epoch 15/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0232\n",
      "Epoch 16/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0228\n",
      "Epoch 17/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0205\n",
      "Epoch 18/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0208\n",
      "Epoch 19/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0189\n",
      "Epoch 20/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0246\n",
      "Epoch 21/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0203\n",
      "Epoch 22/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0240\n",
      "Epoch 23/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0217\n",
      "Epoch 24/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0208\n",
      "Epoch 25/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0194\n",
      "Epoch 26/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0200\n",
      "Epoch 27/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0208\n",
      "Epoch 28/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0199\n",
      "Epoch 29/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0204\n",
      "Epoch 30/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0186\n",
      "Epoch 31/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0204\n",
      "Epoch 32/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0212\n",
      "Epoch 33/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0177\n",
      "Epoch 34/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0211\n",
      "Epoch 35/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0201\n",
      "Epoch 36/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0215\n",
      "Epoch 37/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0198\n",
      "Epoch 38/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0185\n",
      "Epoch 39/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0227\n",
      "Epoch 40/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0179\n",
      "Epoch 41/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0191\n",
      "Epoch 42/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0197\n",
      "Epoch 43/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0200\n",
      "Epoch 44/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0209\n",
      "Epoch 45/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0180\n",
      "Epoch 46/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0218\n",
      "Epoch 47/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0175\n",
      "Epoch 48/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0186\n",
      "Epoch 49/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0204\n",
      "Epoch 50/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0211\n",
      "Epoch 51/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0176\n",
      "Epoch 52/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0178\n",
      "Epoch 53/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0194\n",
      "Epoch 54/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0180\n",
      "Epoch 55/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0185\n",
      "Epoch 56/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0196\n",
      "Epoch 57/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0187\n",
      "Epoch 58/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0212\n",
      "Epoch 59/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0184\n",
      "Epoch 60/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0170\n",
      "Epoch 61/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0193\n",
      "Epoch 62/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0162\n",
      "Epoch 63/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0184\n",
      "Epoch 64/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0192\n",
      "Epoch 65/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0183\n",
      "Epoch 66/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0188\n",
      "Epoch 67/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0185\n",
      "Epoch 68/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0195\n",
      "Epoch 69/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0209\n",
      "Epoch 70/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0172\n",
      "Epoch 71/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0182\n",
      "Epoch 72/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0162\n",
      "Epoch 73/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0185\n",
      "Epoch 74/150\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.0180\n",
      "Epoch 75/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0177\n",
      "Epoch 76/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0167\n",
      "Epoch 77/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0201\n",
      "Epoch 78/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0181\n",
      "Epoch 79/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0185\n",
      "Epoch 80/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0188\n",
      "Epoch 81/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0196\n",
      "Epoch 82/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0182\n",
      "Epoch 83/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0180\n",
      "Epoch 84/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0207\n",
      "Epoch 85/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0203\n",
      "Epoch 86/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0162\n",
      "Epoch 87/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0194\n",
      "Epoch 88/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0177\n",
      "Epoch 89/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0199\n",
      "Epoch 90/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0169\n",
      "Epoch 91/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0170\n",
      "Epoch 92/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0184\n",
      "Epoch 93/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0185\n",
      "Epoch 94/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0195\n",
      "Epoch 95/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0189\n",
      "Epoch 96/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0163\n",
      "Epoch 97/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0176\n",
      "Epoch 98/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0168\n",
      "Epoch 99/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0198\n",
      "Epoch 100/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0192\n",
      "Epoch 101/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0182\n",
      "Epoch 102/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0182\n",
      "Epoch 103/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0181\n",
      "Epoch 104/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0188\n",
      "Epoch 105/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0182\n",
      "Epoch 106/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0196\n",
      "Epoch 107/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0191\n",
      "Epoch 108/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0176\n",
      "Epoch 109/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0166\n",
      "Epoch 110/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0178\n",
      "Epoch 111/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0185\n",
      "Epoch 112/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0168\n",
      "Epoch 113/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0180\n",
      "Epoch 114/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0193\n",
      "Epoch 115/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0181\n",
      "Epoch 116/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0170\n",
      "Epoch 117/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0171\n",
      "Epoch 118/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0192\n",
      "Epoch 119/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0171\n",
      "Epoch 120/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0184\n",
      "Epoch 121/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0179\n",
      "Epoch 122/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0166\n",
      "Epoch 123/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0184\n",
      "Epoch 124/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0178\n",
      "Epoch 125/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0181\n",
      "Epoch 126/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0165\n",
      "Epoch 127/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0167\n",
      "Epoch 128/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0163\n",
      "Epoch 129/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0180\n",
      "Epoch 130/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0157\n",
      "Epoch 131/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0163\n",
      "Epoch 132/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0170\n",
      "Epoch 133/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0151\n",
      "Epoch 134/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0183\n",
      "Epoch 135/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0174\n",
      "Epoch 136/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0164\n",
      "Epoch 137/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0191\n",
      "Epoch 138/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0172\n",
      "Epoch 139/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0184\n",
      "Epoch 140/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0164\n",
      "Epoch 141/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0174\n",
      "Epoch 142/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0170\n",
      "Epoch 143/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0179\n",
      "Epoch 144/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0168\n",
      "Epoch 145/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0165\n",
      "Epoch 146/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0183\n",
      "Epoch 147/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0190\n",
      "Epoch 148/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0155\n",
      "Epoch 149/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0191\n",
      "Epoch 150/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0187\n",
      "16/16 [==============================] - 3s 5ms/step\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_38 (LSTM)              (None, 1, 100)            47600     \n",
      "                                                                 \n",
      " dropout_38 (Dropout)        (None, 1, 100)            0         \n",
      "                                                                 \n",
      " lstm_39 (LSTM)              (None, 100)               80400     \n",
      "                                                                 \n",
      " dropout_39 (Dropout)        (None, 100)               0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 128,101\n",
      "Trainable params: 128,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/150\n",
      "62/62 [==============================] - 13s 12ms/step - loss: 0.4533\n",
      "Epoch 2/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0350\n",
      "Epoch 3/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0250\n",
      "Epoch 4/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0227\n",
      "Epoch 5/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0234\n",
      "Epoch 6/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0205\n",
      "Epoch 7/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0218\n",
      "Epoch 8/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0223\n",
      "Epoch 9/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0193\n",
      "Epoch 10/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0220\n",
      "Epoch 11/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0193\n",
      "Epoch 12/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0212\n",
      "Epoch 13/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0203\n",
      "Epoch 14/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0191\n",
      "Epoch 15/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0201\n",
      "Epoch 16/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0204\n",
      "Epoch 17/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0211\n",
      "Epoch 18/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0191\n",
      "Epoch 19/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0183\n",
      "Epoch 20/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0180\n",
      "Epoch 21/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0228\n",
      "Epoch 22/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0213\n",
      "Epoch 23/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0184\n",
      "Epoch 24/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0169\n",
      "Epoch 25/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0175\n",
      "Epoch 26/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0172\n",
      "Epoch 27/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0174\n",
      "Epoch 28/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0175\n",
      "Epoch 29/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0200\n",
      "Epoch 30/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0206\n",
      "Epoch 31/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0164\n",
      "Epoch 32/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0172\n",
      "Epoch 33/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0184\n",
      "Epoch 34/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0175\n",
      "Epoch 35/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0158\n",
      "Epoch 36/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0193\n",
      "Epoch 37/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0180\n",
      "Epoch 38/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0163\n",
      "Epoch 39/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0169\n",
      "Epoch 40/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0182\n",
      "Epoch 41/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0173\n",
      "Epoch 42/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0164\n",
      "Epoch 43/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0169\n",
      "Epoch 44/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0174\n",
      "Epoch 45/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0160\n",
      "Epoch 46/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0162\n",
      "Epoch 47/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0165\n",
      "Epoch 48/150\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0155\n",
      "Epoch 49/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0159\n",
      "Epoch 50/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0154\n",
      "Epoch 51/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0165\n",
      "Epoch 52/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0154\n",
      "Epoch 53/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0173\n",
      "Epoch 54/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0169\n",
      "Epoch 55/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0165\n",
      "Epoch 56/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0167\n",
      "Epoch 57/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0165\n",
      "Epoch 58/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0175\n",
      "Epoch 59/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0173\n",
      "Epoch 60/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0157\n",
      "Epoch 61/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0153\n",
      "Epoch 62/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0157\n",
      "Epoch 63/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0172\n",
      "Epoch 64/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0158\n",
      "Epoch 65/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0158\n",
      "Epoch 66/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0201\n",
      "Epoch 67/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0144\n",
      "Epoch 68/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0169\n",
      "Epoch 69/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0144\n",
      "Epoch 70/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0138\n",
      "Epoch 71/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0165\n",
      "Epoch 72/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0154\n",
      "Epoch 73/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0159\n",
      "Epoch 74/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0150\n",
      "Epoch 75/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0161\n",
      "Epoch 76/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0157\n",
      "Epoch 77/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0151\n",
      "Epoch 78/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0159\n",
      "Epoch 79/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0144\n",
      "Epoch 80/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0156\n",
      "Epoch 81/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0143\n",
      "Epoch 82/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0136\n",
      "Epoch 83/150\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.0158\n",
      "Epoch 84/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0151\n",
      "Epoch 85/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0154\n",
      "Epoch 86/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0169\n",
      "Epoch 87/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0143\n",
      "Epoch 88/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0172\n",
      "Epoch 89/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0150\n",
      "Epoch 90/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0147\n",
      "Epoch 91/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0159\n",
      "Epoch 92/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0162\n",
      "Epoch 93/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0140\n",
      "Epoch 94/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0158\n",
      "Epoch 95/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0151\n",
      "Epoch 96/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0136\n",
      "Epoch 97/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0141\n",
      "Epoch 98/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0167\n",
      "Epoch 99/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0146\n",
      "Epoch 100/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0143\n",
      "Epoch 101/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0145\n",
      "Epoch 102/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0153\n",
      "Epoch 103/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0133\n",
      "Epoch 104/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0183\n",
      "Epoch 105/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0149\n",
      "Epoch 106/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0140\n",
      "Epoch 107/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0148\n",
      "Epoch 108/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0150\n",
      "Epoch 109/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0147\n",
      "Epoch 110/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0143\n",
      "Epoch 111/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0141\n",
      "Epoch 112/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0161\n",
      "Epoch 113/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0149\n",
      "Epoch 114/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0140\n",
      "Epoch 115/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0146\n",
      "Epoch 116/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0142\n",
      "Epoch 117/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0154\n",
      "Epoch 118/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0137\n",
      "Epoch 119/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0144\n",
      "Epoch 120/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0126\n",
      "Epoch 121/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0139\n",
      "Epoch 122/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0157\n",
      "Epoch 123/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0138\n",
      "Epoch 124/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0146\n",
      "Epoch 125/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0156\n",
      "Epoch 126/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0165\n",
      "Epoch 127/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0135\n",
      "Epoch 128/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0138\n",
      "Epoch 129/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0153\n",
      "Epoch 130/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0134\n",
      "Epoch 131/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0129\n",
      "Epoch 132/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0156\n",
      "Epoch 133/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0136\n",
      "Epoch 134/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0153\n",
      "Epoch 135/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0177\n",
      "Epoch 136/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0140\n",
      "Epoch 137/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0160\n",
      "Epoch 138/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0130\n",
      "Epoch 139/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0126\n",
      "Epoch 140/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0136\n",
      "Epoch 141/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0156\n",
      "Epoch 142/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0129\n",
      "Epoch 143/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0137\n",
      "Epoch 144/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0145\n",
      "Epoch 145/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0153\n",
      "Epoch 146/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0139\n",
      "Epoch 147/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0126\n",
      "Epoch 148/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0148\n",
      "Epoch 149/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0155\n",
      "Epoch 150/150\n",
      "62/62 [==============================] - 1s 11ms/step - loss: 0.0131\n",
      "16/16 [==============================] - 3s 5ms/step\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      " lstm_40 (LSTM)              (None, 1, 50)             13800     \n",
      "                                                                 \n",
      " dropout_40 (Dropout)        (None, 1, 50)             0         \n",
      "                                                                 \n",
      " lstm_41 (LSTM)              (None, 50)                20200     \n",
      "                                                                 \n",
      " dropout_41 (Dropout)        (None, 50)                0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34,051\n",
      "Trainable params: 34,051\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/150\n",
      "31/31 [==============================] - 12s 11ms/step - loss: 1.0354\n",
      "Epoch 2/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.3313\n",
      "Epoch 3/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0601\n",
      "Epoch 4/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0502\n",
      "Epoch 5/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0406\n",
      "Epoch 6/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0360\n",
      "Epoch 7/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0324\n",
      "Epoch 8/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0316\n",
      "Epoch 9/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0312\n",
      "Epoch 10/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0316\n",
      "Epoch 11/150\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.0281\n",
      "Epoch 12/150\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.0288\n",
      "Epoch 13/150\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.0250\n",
      "Epoch 14/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0264\n",
      "Epoch 15/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0273\n",
      "Epoch 16/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0254\n",
      "Epoch 17/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0268\n",
      "Epoch 18/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0251\n",
      "Epoch 19/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0254\n",
      "Epoch 20/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0248\n",
      "Epoch 21/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0290\n",
      "Epoch 22/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0233\n",
      "Epoch 23/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0205\n",
      "Epoch 24/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0258\n",
      "Epoch 25/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0247\n",
      "Epoch 26/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0251\n",
      "Epoch 27/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0247\n",
      "Epoch 28/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0244\n",
      "Epoch 29/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0226\n",
      "Epoch 30/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0240\n",
      "Epoch 31/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0235\n",
      "Epoch 32/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0227\n",
      "Epoch 33/150\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.0221\n",
      "Epoch 34/150\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.0247\n",
      "Epoch 35/150\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.0220\n",
      "Epoch 36/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0196\n",
      "Epoch 37/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0226\n",
      "Epoch 38/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0247\n",
      "Epoch 39/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0241\n",
      "Epoch 40/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0213\n",
      "Epoch 41/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0218\n",
      "Epoch 42/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0221\n",
      "Epoch 43/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0213\n",
      "Epoch 44/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0226\n",
      "Epoch 45/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0215\n",
      "Epoch 46/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0223\n",
      "Epoch 47/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0196\n",
      "Epoch 48/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0207\n",
      "Epoch 49/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0209\n",
      "Epoch 50/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0220\n",
      "Epoch 51/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0206\n",
      "Epoch 52/150\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.0211\n",
      "Epoch 53/150\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.0206\n",
      "Epoch 54/150\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.0244\n",
      "Epoch 55/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0214\n",
      "Epoch 56/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0223\n",
      "Epoch 57/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0222\n",
      "Epoch 58/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0192\n",
      "Epoch 59/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0219\n",
      "Epoch 60/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0198\n",
      "Epoch 61/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0214\n",
      "Epoch 62/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0187\n",
      "Epoch 63/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0205\n",
      "Epoch 64/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0237\n",
      "Epoch 65/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0204\n",
      "Epoch 66/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0198\n",
      "Epoch 67/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0197\n",
      "Epoch 68/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0206\n",
      "Epoch 69/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0204\n",
      "Epoch 70/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0192\n",
      "Epoch 71/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0199\n",
      "Epoch 72/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0203\n",
      "Epoch 73/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0207\n",
      "Epoch 74/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0228\n",
      "Epoch 75/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0200\n",
      "Epoch 76/150\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.0228\n",
      "Epoch 77/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0198\n",
      "Epoch 78/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0229\n",
      "Epoch 79/150\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.0211\n",
      "Epoch 80/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0210\n",
      "Epoch 81/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0192\n",
      "Epoch 82/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0208\n",
      "Epoch 83/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0203\n",
      "Epoch 84/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0213\n",
      "Epoch 85/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0218\n",
      "Epoch 86/150\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.0223\n",
      "Epoch 87/150\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.0192\n",
      "Epoch 88/150\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.0195\n",
      "Epoch 89/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0200\n",
      "Epoch 90/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0203\n",
      "Epoch 91/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0194\n",
      "Epoch 92/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0202\n",
      "Epoch 93/150\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.0203\n",
      "Epoch 94/150\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.0193\n",
      "Epoch 95/150\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.0189\n",
      "Epoch 96/150\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.0166\n",
      "Epoch 97/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0199\n",
      "Epoch 98/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0193\n",
      "Epoch 99/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0211\n",
      "Epoch 100/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0193\n",
      "Epoch 101/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0214\n",
      "Epoch 102/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0182\n",
      "Epoch 103/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0206\n",
      "Epoch 104/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0199\n",
      "Epoch 105/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0195\n",
      "Epoch 106/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0177\n",
      "Epoch 107/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0203\n",
      "Epoch 108/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0191\n",
      "Epoch 109/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0219\n",
      "Epoch 110/150\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.0183\n",
      "Epoch 111/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0192\n",
      "Epoch 112/150\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.0213\n",
      "Epoch 113/150\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.0182\n",
      "Epoch 114/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0206\n",
      "Epoch 115/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0199\n",
      "Epoch 116/150\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.0191\n",
      "Epoch 117/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0198\n",
      "Epoch 118/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0212\n",
      "Epoch 119/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0179\n",
      "Epoch 120/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0190\n",
      "Epoch 121/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0212\n",
      "Epoch 122/150\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.0172\n",
      "Epoch 123/150\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.0178\n",
      "Epoch 124/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0206\n",
      "Epoch 125/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0227\n",
      "Epoch 126/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0208\n",
      "Epoch 127/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0193\n",
      "Epoch 128/150\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.0199\n",
      "Epoch 129/150\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.0186\n",
      "Epoch 130/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0201\n",
      "Epoch 131/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0184\n",
      "Epoch 132/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0178\n",
      "Epoch 133/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0177\n",
      "Epoch 134/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0218\n",
      "Epoch 135/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0204\n",
      "Epoch 136/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0217\n",
      "Epoch 137/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0198\n",
      "Epoch 138/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0191\n",
      "Epoch 139/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0177\n",
      "Epoch 140/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0195\n",
      "Epoch 141/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0189\n",
      "Epoch 142/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0196\n",
      "Epoch 143/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0178\n",
      "Epoch 144/150\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.0192\n",
      "Epoch 145/150\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.0202\n",
      "Epoch 146/150\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.0202\n",
      "Epoch 147/150\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.0193\n",
      "Epoch 148/150\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.0186\n",
      "Epoch 149/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0182\n",
      "Epoch 150/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0205\n",
      "16/16 [==============================] - 5s 5ms/step\n",
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_42 (LSTM)              (None, 1, 50)             13800     \n",
      "                                                                 \n",
      " dropout_42 (Dropout)        (None, 1, 50)             0         \n",
      "                                                                 \n",
      " lstm_43 (LSTM)              (None, 100)               60400     \n",
      "                                                                 \n",
      " dropout_43 (Dropout)        (None, 100)               0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 74,301\n",
      "Trainable params: 74,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/150\n",
      "31/31 [==============================] - 12s 13ms/step - loss: 0.9414\n",
      "Epoch 2/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.1980\n",
      "Epoch 3/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0565\n",
      "Epoch 4/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0386\n",
      "Epoch 5/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0355\n",
      "Epoch 6/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0262\n",
      "Epoch 7/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0289\n",
      "Epoch 8/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0282\n",
      "Epoch 9/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0231\n",
      "Epoch 10/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0270\n",
      "Epoch 11/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0269\n",
      "Epoch 12/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0269\n",
      "Epoch 13/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0245\n",
      "Epoch 14/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0244\n",
      "Epoch 15/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0246\n",
      "Epoch 16/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0231\n",
      "Epoch 17/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0208\n",
      "Epoch 18/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0233\n",
      "Epoch 19/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0232\n",
      "Epoch 20/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0229\n",
      "Epoch 21/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0216\n",
      "Epoch 22/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0215\n",
      "Epoch 23/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0239\n",
      "Epoch 24/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0218\n",
      "Epoch 25/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0202\n",
      "Epoch 26/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0189\n",
      "Epoch 27/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0214\n",
      "Epoch 28/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0217\n",
      "Epoch 29/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0214\n",
      "Epoch 30/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0211\n",
      "Epoch 31/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0204\n",
      "Epoch 32/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0202\n",
      "Epoch 33/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0180\n",
      "Epoch 34/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0228\n",
      "Epoch 35/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0214\n",
      "Epoch 36/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0210\n",
      "Epoch 37/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0189\n",
      "Epoch 38/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0194\n",
      "Epoch 39/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0188\n",
      "Epoch 40/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0204\n",
      "Epoch 41/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0181\n",
      "Epoch 42/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0187\n",
      "Epoch 43/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0197\n",
      "Epoch 44/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0199\n",
      "Epoch 45/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0185\n",
      "Epoch 46/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0185\n",
      "Epoch 47/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0181\n",
      "Epoch 48/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0202\n",
      "Epoch 49/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0171\n",
      "Epoch 50/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0175\n",
      "Epoch 51/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0171\n",
      "Epoch 52/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0185\n",
      "Epoch 53/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0203\n",
      "Epoch 54/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0183\n",
      "Epoch 55/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0179\n",
      "Epoch 56/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0186\n",
      "Epoch 57/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0162\n",
      "Epoch 58/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0176\n",
      "Epoch 59/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0176\n",
      "Epoch 60/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0194\n",
      "Epoch 61/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0196\n",
      "Epoch 62/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0179\n",
      "Epoch 63/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0180\n",
      "Epoch 64/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0180\n",
      "Epoch 65/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0195\n",
      "Epoch 66/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0169\n",
      "Epoch 67/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0177\n",
      "Epoch 68/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0168\n",
      "Epoch 69/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0160\n",
      "Epoch 70/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0174\n",
      "Epoch 71/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0164\n",
      "Epoch 72/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0178\n",
      "Epoch 73/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0192\n",
      "Epoch 74/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0187\n",
      "Epoch 75/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0158\n",
      "Epoch 76/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0168\n",
      "Epoch 77/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0160\n",
      "Epoch 78/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0155\n",
      "Epoch 79/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0172\n",
      "Epoch 80/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0151\n",
      "Epoch 81/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0153\n",
      "Epoch 82/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0160\n",
      "Epoch 83/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0157\n",
      "Epoch 84/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0171\n",
      "Epoch 85/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0161\n",
      "Epoch 86/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0181\n",
      "Epoch 87/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0163\n",
      "Epoch 88/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0173\n",
      "Epoch 89/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0154\n",
      "Epoch 90/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0170\n",
      "Epoch 91/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0175\n",
      "Epoch 92/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0165\n",
      "Epoch 93/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0169\n",
      "Epoch 94/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0155\n",
      "Epoch 95/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0145\n",
      "Epoch 96/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0183\n",
      "Epoch 97/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0168\n",
      "Epoch 98/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0172\n",
      "Epoch 99/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0172\n",
      "Epoch 100/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0173\n",
      "Epoch 101/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0167\n",
      "Epoch 102/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0166\n",
      "Epoch 103/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0179\n",
      "Epoch 104/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0177\n",
      "Epoch 105/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0168\n",
      "Epoch 106/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0151\n",
      "Epoch 107/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0154\n",
      "Epoch 108/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0150\n",
      "Epoch 109/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0175\n",
      "Epoch 110/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0155\n",
      "Epoch 111/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0145\n",
      "Epoch 112/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0159\n",
      "Epoch 113/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0160\n",
      "Epoch 114/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0172\n",
      "Epoch 115/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0148\n",
      "Epoch 116/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0155\n",
      "Epoch 117/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0188\n",
      "Epoch 118/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0162\n",
      "Epoch 119/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0149\n",
      "Epoch 120/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0179\n",
      "Epoch 121/150\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0147\n",
      "Epoch 122/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0154\n",
      "Epoch 123/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0154\n",
      "Epoch 124/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0178\n",
      "Epoch 125/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0159\n",
      "Epoch 126/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0158\n",
      "Epoch 127/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0153\n",
      "Epoch 128/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0132\n",
      "Epoch 129/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0159\n",
      "Epoch 130/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0169\n",
      "Epoch 131/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0165\n",
      "Epoch 132/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0160\n",
      "Epoch 133/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0154\n",
      "Epoch 134/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0158\n",
      "Epoch 135/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0151\n",
      "Epoch 136/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0167\n",
      "Epoch 137/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0165\n",
      "Epoch 138/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0158\n",
      "Epoch 139/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0168\n",
      "Epoch 140/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0177\n",
      "Epoch 141/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0153\n",
      "Epoch 142/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0149\n",
      "Epoch 143/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0151\n",
      "Epoch 144/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0145\n",
      "Epoch 145/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0149\n",
      "Epoch 146/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0168\n",
      "Epoch 147/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0156\n",
      "Epoch 148/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0153\n",
      "Epoch 149/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0152\n",
      "Epoch 150/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0160\n",
      "16/16 [==============================] - 3s 5ms/step\n",
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_44 (LSTM)              (None, 1, 100)            47600     \n",
      "                                                                 \n",
      " dropout_44 (Dropout)        (None, 1, 100)            0         \n",
      "                                                                 \n",
      " lstm_45 (LSTM)              (None, 50)                30200     \n",
      "                                                                 \n",
      " dropout_45 (Dropout)        (None, 50)                0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77,851\n",
      "Trainable params: 77,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/150\n",
      "31/31 [==============================] - 12s 13ms/step - loss: 0.8134\n",
      "Epoch 2/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.1059\n",
      "Epoch 3/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0445\n",
      "Epoch 4/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0350\n",
      "Epoch 5/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0298\n",
      "Epoch 6/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0269\n",
      "Epoch 7/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0273\n",
      "Epoch 8/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0256\n",
      "Epoch 9/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0236\n",
      "Epoch 10/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0246\n",
      "Epoch 11/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0235\n",
      "Epoch 12/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0262\n",
      "Epoch 13/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0252\n",
      "Epoch 14/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0236\n",
      "Epoch 15/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0241\n",
      "Epoch 16/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0237\n",
      "Epoch 17/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0239\n",
      "Epoch 18/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0221\n",
      "Epoch 19/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0236\n",
      "Epoch 20/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0217\n",
      "Epoch 21/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0230\n",
      "Epoch 22/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0240\n",
      "Epoch 23/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0201\n",
      "Epoch 24/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0218\n",
      "Epoch 25/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0224\n",
      "Epoch 26/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0206\n",
      "Epoch 27/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0194\n",
      "Epoch 28/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0181\n",
      "Epoch 29/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0201\n",
      "Epoch 30/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0215\n",
      "Epoch 31/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0206\n",
      "Epoch 32/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0223\n",
      "Epoch 33/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0220\n",
      "Epoch 34/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0178\n",
      "Epoch 35/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0194\n",
      "Epoch 36/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0212\n",
      "Epoch 37/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0214\n",
      "Epoch 38/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0215\n",
      "Epoch 39/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0195\n",
      "Epoch 40/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0198\n",
      "Epoch 41/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0195\n",
      "Epoch 42/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0178\n",
      "Epoch 43/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0186\n",
      "Epoch 44/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0197\n",
      "Epoch 45/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0175\n",
      "Epoch 46/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0206\n",
      "Epoch 47/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0194\n",
      "Epoch 48/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0183\n",
      "Epoch 49/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0200\n",
      "Epoch 50/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0202\n",
      "Epoch 51/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0207\n",
      "Epoch 52/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0200\n",
      "Epoch 53/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0201\n",
      "Epoch 54/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0197\n",
      "Epoch 55/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0171\n",
      "Epoch 56/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0191\n",
      "Epoch 57/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0203\n",
      "Epoch 58/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0188\n",
      "Epoch 59/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0187\n",
      "Epoch 60/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0189\n",
      "Epoch 61/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0181\n",
      "Epoch 62/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0222\n",
      "Epoch 63/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0187\n",
      "Epoch 64/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0179\n",
      "Epoch 65/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0191\n",
      "Epoch 66/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0188\n",
      "Epoch 67/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0171\n",
      "Epoch 68/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0170\n",
      "Epoch 69/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0185\n",
      "Epoch 70/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0194\n",
      "Epoch 71/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0176\n",
      "Epoch 72/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0180\n",
      "Epoch 73/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0192\n",
      "Epoch 74/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0166\n",
      "Epoch 75/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0168\n",
      "Epoch 76/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0188\n",
      "Epoch 77/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0168\n",
      "Epoch 78/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0180\n",
      "Epoch 79/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0192\n",
      "Epoch 80/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0182\n",
      "Epoch 81/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0172\n",
      "Epoch 82/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0183\n",
      "Epoch 83/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0191\n",
      "Epoch 84/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0188\n",
      "Epoch 85/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0182\n",
      "Epoch 86/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0191\n",
      "Epoch 87/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0175\n",
      "Epoch 88/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0187\n",
      "Epoch 89/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0172\n",
      "Epoch 90/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0225\n",
      "Epoch 91/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0168\n",
      "Epoch 92/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0168\n",
      "Epoch 93/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0191\n",
      "Epoch 94/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0183\n",
      "Epoch 95/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0179\n",
      "Epoch 96/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0182\n",
      "Epoch 97/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0173\n",
      "Epoch 98/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0173\n",
      "Epoch 99/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0173\n",
      "Epoch 100/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0188\n",
      "Epoch 101/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0170\n",
      "Epoch 102/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0194\n",
      "Epoch 103/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0181\n",
      "Epoch 104/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0188\n",
      "Epoch 105/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0190\n",
      "Epoch 106/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0186\n",
      "Epoch 107/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0169\n",
      "Epoch 108/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0188\n",
      "Epoch 109/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0190\n",
      "Epoch 110/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0191\n",
      "Epoch 111/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0196\n",
      "Epoch 112/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0190\n",
      "Epoch 113/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0194\n",
      "Epoch 114/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0153\n",
      "Epoch 115/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0205\n",
      "Epoch 116/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0178\n",
      "Epoch 117/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0206\n",
      "Epoch 118/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0164\n",
      "Epoch 119/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0166\n",
      "Epoch 120/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0190\n",
      "Epoch 121/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0156\n",
      "Epoch 122/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0187\n",
      "Epoch 123/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0150\n",
      "Epoch 124/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0144\n",
      "Epoch 125/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0186\n",
      "Epoch 126/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0176\n",
      "Epoch 127/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0175\n",
      "Epoch 128/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0186\n",
      "Epoch 129/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0186\n",
      "Epoch 130/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0183\n",
      "Epoch 131/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0164\n",
      "Epoch 132/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0189\n",
      "Epoch 133/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0189\n",
      "Epoch 134/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0183\n",
      "Epoch 135/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0182\n",
      "Epoch 136/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0165\n",
      "Epoch 137/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0194\n",
      "Epoch 138/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0184\n",
      "Epoch 139/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0182\n",
      "Epoch 140/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0171\n",
      "Epoch 141/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0169\n",
      "Epoch 142/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0181\n",
      "Epoch 143/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0151\n",
      "Epoch 144/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0173\n",
      "Epoch 145/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0162\n",
      "Epoch 146/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0169\n",
      "Epoch 147/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0208\n",
      "Epoch 148/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0182\n",
      "Epoch 149/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0180\n",
      "Epoch 150/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0200\n",
      "16/16 [==============================] - 3s 5ms/step\n",
      "Model: \"sequential_23\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_46 (LSTM)              (None, 1, 100)            47600     \n",
      "                                                                 \n",
      " dropout_46 (Dropout)        (None, 1, 100)            0         \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " lstm_47 (LSTM)              (None, 100)               80400     \n",
      "                                                                 \n",
      " dropout_47 (Dropout)        (None, 100)               0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 128,101\n",
      "Trainable params: 128,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/150\n",
      "31/31 [==============================] - 12s 14ms/step - loss: 0.8232\n",
      "Epoch 2/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0732\n",
      "Epoch 3/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0354\n",
      "Epoch 4/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0262\n",
      "Epoch 5/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0227\n",
      "Epoch 6/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0222\n",
      "Epoch 7/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0211\n",
      "Epoch 8/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0211\n",
      "Epoch 9/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0228\n",
      "Epoch 10/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0231\n",
      "Epoch 11/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0221\n",
      "Epoch 12/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0182\n",
      "Epoch 13/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0197\n",
      "Epoch 14/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0222\n",
      "Epoch 15/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0183\n",
      "Epoch 16/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0207\n",
      "Epoch 17/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0176\n",
      "Epoch 18/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0186\n",
      "Epoch 19/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0167\n",
      "Epoch 20/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0189\n",
      "Epoch 21/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0190\n",
      "Epoch 22/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0182\n",
      "Epoch 23/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0196\n",
      "Epoch 24/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0177\n",
      "Epoch 25/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0172\n",
      "Epoch 26/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0198\n",
      "Epoch 27/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0202\n",
      "Epoch 28/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0171\n",
      "Epoch 29/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0169\n",
      "Epoch 30/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0170\n",
      "Epoch 31/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0189\n",
      "Epoch 32/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0168\n",
      "Epoch 33/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0185\n",
      "Epoch 34/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0167\n",
      "Epoch 35/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0173\n",
      "Epoch 36/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0168\n",
      "Epoch 37/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0171\n",
      "Epoch 38/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0172\n",
      "Epoch 39/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0168\n",
      "Epoch 40/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0175\n",
      "Epoch 41/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0176\n",
      "Epoch 42/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0154\n",
      "Epoch 43/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0171\n",
      "Epoch 44/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0154\n",
      "Epoch 45/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0165\n",
      "Epoch 46/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0156\n",
      "Epoch 47/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0163\n",
      "Epoch 48/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0150\n",
      "Epoch 49/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0168\n",
      "Epoch 50/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0153\n",
      "Epoch 51/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0161\n",
      "Epoch 52/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0160\n",
      "Epoch 53/150\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.0164\n",
      "Epoch 54/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0170\n",
      "Epoch 55/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0162\n",
      "Epoch 56/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0176\n",
      "Epoch 57/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0160\n",
      "Epoch 58/150\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.0159\n",
      "Epoch 59/150\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.0177\n",
      "Epoch 60/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0162\n",
      "Epoch 61/150\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.0174\n",
      "Epoch 62/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0162\n",
      "Epoch 63/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0157\n",
      "Epoch 64/150\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.0143\n",
      "Epoch 65/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0156\n",
      "Epoch 66/150\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.0157\n",
      "Epoch 67/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0162\n",
      "Epoch 68/150\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.0160\n",
      "Epoch 69/150\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.0153\n",
      "Epoch 70/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0144\n",
      "Epoch 71/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0156\n",
      "Epoch 72/150\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.0165\n",
      "Epoch 73/150\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.0151\n",
      "Epoch 74/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0162\n",
      "Epoch 75/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0150\n",
      "Epoch 76/150\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.0160\n",
      "Epoch 77/150\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.0143\n",
      "Epoch 78/150\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.0176\n",
      "Epoch 79/150\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.0148\n",
      "Epoch 80/150\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.0149\n",
      "Epoch 81/150\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.0133\n",
      "Epoch 82/150\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.0139\n",
      "Epoch 83/150\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.0153\n",
      "Epoch 84/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0161\n",
      "Epoch 85/150\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.0156\n",
      "Epoch 86/150\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.0153\n",
      "Epoch 87/150\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.0143\n",
      "Epoch 88/150\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.0152\n",
      "Epoch 89/150\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.0169\n",
      "Epoch 90/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0149\n",
      "Epoch 91/150\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.0146\n",
      "Epoch 92/150\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.0154\n",
      "Epoch 93/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 14ms/step - loss: 0.0160\n",
      "Epoch 94/150\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.0159\n",
      "Epoch 95/150\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.0147\n",
      "Epoch 96/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0131\n",
      "Epoch 97/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0161\n",
      "Epoch 98/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0157\n",
      "Epoch 99/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0156\n",
      "Epoch 100/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0152\n",
      "Epoch 101/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0161\n",
      "Epoch 102/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0156\n",
      "Epoch 103/150\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.0156\n",
      "Epoch 104/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0152\n",
      "Epoch 105/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0147\n",
      "Epoch 106/150\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0169\n",
      "Epoch 107/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0155\n",
      "Epoch 108/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0146\n",
      "Epoch 109/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0153\n",
      "Epoch 110/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0143\n",
      "Epoch 111/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0136\n",
      "Epoch 112/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0138\n",
      "Epoch 113/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0137\n",
      "Epoch 114/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0153\n",
      "Epoch 115/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0156\n",
      "Epoch 116/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0158\n",
      "Epoch 117/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0144\n",
      "Epoch 118/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0135\n",
      "Epoch 119/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0145\n",
      "Epoch 120/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0150\n",
      "Epoch 121/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0154\n",
      "Epoch 122/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0138\n",
      "Epoch 123/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0148\n",
      "Epoch 124/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0144\n",
      "Epoch 125/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0155\n",
      "Epoch 126/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0138\n",
      "Epoch 127/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0157\n",
      "Epoch 128/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0118\n",
      "Epoch 129/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0146\n",
      "Epoch 130/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0142\n",
      "Epoch 131/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0137\n",
      "Epoch 132/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0134\n",
      "Epoch 133/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0130\n",
      "Epoch 134/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0132\n",
      "Epoch 135/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0149\n",
      "Epoch 136/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0154\n",
      "Epoch 137/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0144\n",
      "Epoch 138/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0165\n",
      "Epoch 139/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0159\n",
      "Epoch 140/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0146\n",
      "Epoch 141/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0139\n",
      "Epoch 142/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0145\n",
      "Epoch 143/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0155\n",
      "Epoch 144/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0135\n",
      "Epoch 145/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0135\n",
      "Epoch 146/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0134\n",
      "Epoch 147/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0146\n",
      "Epoch 148/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0143\n",
      "Epoch 149/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0150\n",
      "Epoch 150/150\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0143\n",
      "16/16 [==============================] - 3s 6ms/step\n",
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_48 (LSTM)              (None, 1, 50)             13800     \n",
      "                                                                 \n",
      " dropout_48 (Dropout)        (None, 1, 50)             0         \n",
      "                                                                 \n",
      " lstm_49 (LSTM)              (None, 50)                20200     \n",
      "                                                                 \n",
      " dropout_49 (Dropout)        (None, 50)                0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34,051\n",
      "Trainable params: 34,051\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "123/123 [==============================] - 16s 9ms/step - loss: 0.4333\n",
      "Epoch 2/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0435\n",
      "Epoch 3/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0311\n",
      "Epoch 4/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0303\n",
      "Epoch 5/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0304\n",
      "Epoch 6/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0338\n",
      "Epoch 7/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0315\n",
      "Epoch 8/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0319\n",
      "Epoch 9/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0228\n",
      "Epoch 10/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0275\n",
      "Epoch 11/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0252\n",
      "Epoch 12/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0235\n",
      "Epoch 13/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0254\n",
      "Epoch 14/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0230\n",
      "Epoch 15/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0258\n",
      "Epoch 16/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0268\n",
      "Epoch 17/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0229\n",
      "Epoch 18/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0250\n",
      "Epoch 19/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0243\n",
      "Epoch 20/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0232\n",
      "Epoch 21/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0238\n",
      "Epoch 22/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0250\n",
      "Epoch 23/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0251\n",
      "Epoch 24/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0213\n",
      "Epoch 25/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0261\n",
      "Epoch 26/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0252\n",
      "Epoch 27/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0226\n",
      "Epoch 28/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0220\n",
      "Epoch 29/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0251\n",
      "Epoch 30/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0239\n",
      "Epoch 31/200\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0210\n",
      "Epoch 32/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0252\n",
      "Epoch 33/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0241\n",
      "Epoch 34/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0197\n",
      "Epoch 35/200\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.0226\n",
      "Epoch 36/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0227\n",
      "Epoch 37/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0212\n",
      "Epoch 38/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0216\n",
      "Epoch 39/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0222\n",
      "Epoch 40/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0204\n",
      "Epoch 41/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0203\n",
      "Epoch 42/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0232\n",
      "Epoch 43/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0208\n",
      "Epoch 44/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0215\n",
      "Epoch 45/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0236\n",
      "Epoch 46/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0239\n",
      "Epoch 47/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0204\n",
      "Epoch 48/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0231\n",
      "Epoch 49/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0208\n",
      "Epoch 50/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0226\n",
      "Epoch 51/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0208\n",
      "Epoch 52/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0199\n",
      "Epoch 53/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0204\n",
      "Epoch 54/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0233\n",
      "Epoch 55/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0220\n",
      "Epoch 56/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0194\n",
      "Epoch 57/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0202\n",
      "Epoch 58/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0196\n",
      "Epoch 59/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0212\n",
      "Epoch 60/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0218\n",
      "Epoch 61/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0214\n",
      "Epoch 62/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0208\n",
      "Epoch 63/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0184\n",
      "Epoch 64/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0231\n",
      "Epoch 65/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0224\n",
      "Epoch 66/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0216\n",
      "Epoch 67/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0189\n",
      "Epoch 68/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0217\n",
      "Epoch 69/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0216\n",
      "Epoch 70/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0222\n",
      "Epoch 71/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0212\n",
      "Epoch 72/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0177\n",
      "Epoch 73/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0187\n",
      "Epoch 74/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0188\n",
      "Epoch 75/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0223\n",
      "Epoch 76/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0180\n",
      "Epoch 77/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0211\n",
      "Epoch 78/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0233\n",
      "Epoch 79/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0202\n",
      "Epoch 80/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0174\n",
      "Epoch 81/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0214\n",
      "Epoch 82/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0201\n",
      "Epoch 83/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0187\n",
      "Epoch 84/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0181\n",
      "Epoch 85/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0202\n",
      "Epoch 86/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0201\n",
      "Epoch 87/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0230\n",
      "Epoch 88/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0186\n",
      "Epoch 89/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0215\n",
      "Epoch 90/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0176\n",
      "Epoch 91/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0196\n",
      "Epoch 92/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0184\n",
      "Epoch 93/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0191\n",
      "Epoch 94/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0199\n",
      "Epoch 95/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0199\n",
      "Epoch 96/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0209\n",
      "Epoch 97/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0199\n",
      "Epoch 98/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0205\n",
      "Epoch 99/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0200\n",
      "Epoch 100/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0204\n",
      "Epoch 101/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0197\n",
      "Epoch 102/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0189\n",
      "Epoch 103/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0185\n",
      "Epoch 104/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0164\n",
      "Epoch 105/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0206\n",
      "Epoch 106/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0217\n",
      "Epoch 107/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0202\n",
      "Epoch 108/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0174\n",
      "Epoch 109/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0206\n",
      "Epoch 110/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0186\n",
      "Epoch 111/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0165\n",
      "Epoch 112/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0193\n",
      "Epoch 113/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0186\n",
      "Epoch 114/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0198\n",
      "Epoch 115/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0192\n",
      "Epoch 116/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0183\n",
      "Epoch 117/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0184\n",
      "Epoch 118/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0167\n",
      "Epoch 119/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0187\n",
      "Epoch 120/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0183\n",
      "Epoch 121/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0223\n",
      "Epoch 122/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0186\n",
      "Epoch 123/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0174\n",
      "Epoch 124/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0196\n",
      "Epoch 125/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0178\n",
      "Epoch 126/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0176\n",
      "Epoch 127/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0209\n",
      "Epoch 128/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0175\n",
      "Epoch 129/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0184\n",
      "Epoch 130/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0176\n",
      "Epoch 131/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0189\n",
      "Epoch 132/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0198\n",
      "Epoch 133/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0193\n",
      "Epoch 134/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0194\n",
      "Epoch 135/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0182\n",
      "Epoch 136/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0190\n",
      "Epoch 137/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0163\n",
      "Epoch 138/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0193\n",
      "Epoch 139/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0177\n",
      "Epoch 140/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0174\n",
      "Epoch 141/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0168\n",
      "Epoch 142/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0190\n",
      "Epoch 143/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0178\n",
      "Epoch 144/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0192\n",
      "Epoch 145/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0177\n",
      "Epoch 146/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0171\n",
      "Epoch 147/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0204\n",
      "Epoch 148/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0197\n",
      "Epoch 149/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0175\n",
      "Epoch 150/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0184\n",
      "Epoch 151/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0165\n",
      "Epoch 152/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0189\n",
      "Epoch 153/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0188\n",
      "Epoch 154/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0159\n",
      "Epoch 155/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0181\n",
      "Epoch 156/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0177\n",
      "Epoch 157/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0180\n",
      "Epoch 158/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0155\n",
      "Epoch 159/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0184\n",
      "Epoch 160/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0204\n",
      "Epoch 161/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0160\n",
      "Epoch 162/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0191\n",
      "Epoch 163/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0156\n",
      "Epoch 164/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0148\n",
      "Epoch 165/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0174\n",
      "Epoch 166/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0159\n",
      "Epoch 167/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0177\n",
      "Epoch 168/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0166\n",
      "Epoch 169/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0168\n",
      "Epoch 170/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0172\n",
      "Epoch 171/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0172\n",
      "Epoch 172/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0191\n",
      "Epoch 173/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0146\n",
      "Epoch 174/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0183\n",
      "Epoch 175/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0163\n",
      "Epoch 176/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0196\n",
      "Epoch 177/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0185\n",
      "Epoch 178/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0170\n",
      "Epoch 179/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0176\n",
      "Epoch 180/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0176\n",
      "Epoch 181/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0194\n",
      "Epoch 182/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0178\n",
      "Epoch 183/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0186\n",
      "Epoch 184/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0189\n",
      "Epoch 185/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0168\n",
      "Epoch 186/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0164\n",
      "Epoch 187/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0190\n",
      "Epoch 188/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0159\n",
      "Epoch 189/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0185\n",
      "Epoch 190/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0179\n",
      "Epoch 191/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0169\n",
      "Epoch 192/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0161\n",
      "Epoch 193/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0171\n",
      "Epoch 194/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0185\n",
      "Epoch 195/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0166\n",
      "Epoch 196/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0175\n",
      "Epoch 197/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0171\n",
      "Epoch 198/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0162\n",
      "Epoch 199/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0176\n",
      "Epoch 200/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0154\n",
      "16/16 [==============================] - 3s 4ms/step\n",
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_50 (LSTM)              (None, 1, 50)             13800     \n",
      "                                                                 \n",
      " dropout_50 (Dropout)        (None, 1, 50)             0         \n",
      "                                                                 \n",
      " lstm_51 (LSTM)              (None, 100)               60400     \n",
      "                                                                 \n",
      " dropout_51 (Dropout)        (None, 100)               0         \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 74,301\n",
      "Trainable params: 74,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "123/123 [==============================] - 13s 10ms/step - loss: 0.3409\n",
      "Epoch 2/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0314\n",
      "Epoch 3/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0312\n",
      "Epoch 4/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0260\n",
      "Epoch 5/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0292\n",
      "Epoch 6/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0266\n",
      "Epoch 7/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0237\n",
      "Epoch 8/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0226\n",
      "Epoch 9/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0258\n",
      "Epoch 10/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0263\n",
      "Epoch 11/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0226\n",
      "Epoch 12/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0226\n",
      "Epoch 13/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0243\n",
      "Epoch 14/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0200\n",
      "Epoch 15/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0258\n",
      "Epoch 16/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0207\n",
      "Epoch 17/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0229\n",
      "Epoch 18/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0208\n",
      "Epoch 19/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0185\n",
      "Epoch 20/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0211\n",
      "Epoch 21/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0198\n",
      "Epoch 22/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0205\n",
      "Epoch 23/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0185\n",
      "Epoch 24/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0202\n",
      "Epoch 25/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0208\n",
      "Epoch 26/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0201\n",
      "Epoch 27/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0231\n",
      "Epoch 28/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0192\n",
      "Epoch 29/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0188\n",
      "Epoch 30/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0210\n",
      "Epoch 31/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0188\n",
      "Epoch 32/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0209\n",
      "Epoch 33/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0192\n",
      "Epoch 34/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0215\n",
      "Epoch 35/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0209\n",
      "Epoch 36/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0186\n",
      "Epoch 37/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0200\n",
      "Epoch 38/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0185\n",
      "Epoch 39/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0193\n",
      "Epoch 40/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0187\n",
      "Epoch 41/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0196\n",
      "Epoch 42/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0183\n",
      "Epoch 43/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0184\n",
      "Epoch 44/200\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0186\n",
      "Epoch 45/200\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0193\n",
      "Epoch 46/200\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0176\n",
      "Epoch 47/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0192\n",
      "Epoch 48/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0160\n",
      "Epoch 49/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0187\n",
      "Epoch 50/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0181\n",
      "Epoch 51/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0183\n",
      "Epoch 52/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0192\n",
      "Epoch 53/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0173\n",
      "Epoch 54/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0185\n",
      "Epoch 55/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0165\n",
      "Epoch 56/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0179\n",
      "Epoch 57/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0193\n",
      "Epoch 58/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0175\n",
      "Epoch 59/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0175\n",
      "Epoch 60/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0192\n",
      "Epoch 61/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0200\n",
      "Epoch 62/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0168\n",
      "Epoch 63/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0176\n",
      "Epoch 64/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0161\n",
      "Epoch 65/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0175\n",
      "Epoch 66/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0167\n",
      "Epoch 67/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0170\n",
      "Epoch 68/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0185\n",
      "Epoch 69/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0178\n",
      "Epoch 70/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0179\n",
      "Epoch 71/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0154\n",
      "Epoch 72/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0171\n",
      "Epoch 73/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0192\n",
      "Epoch 74/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0198\n",
      "Epoch 75/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0180\n",
      "Epoch 76/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0185\n",
      "Epoch 77/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0178\n",
      "Epoch 78/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0165\n",
      "Epoch 79/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0170\n",
      "Epoch 80/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0178\n",
      "Epoch 81/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0184\n",
      "Epoch 82/200\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0173\n",
      "Epoch 83/200\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0178\n",
      "Epoch 84/200\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0178\n",
      "Epoch 85/200\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0168\n",
      "Epoch 86/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0181\n",
      "Epoch 87/200\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0177\n",
      "Epoch 88/200\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0159\n",
      "Epoch 89/200\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0173\n",
      "Epoch 90/200\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0163\n",
      "Epoch 91/200\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0146\n",
      "Epoch 92/200\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0174\n",
      "Epoch 93/200\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0166\n",
      "Epoch 94/200\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0154\n",
      "Epoch 95/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0175\n",
      "Epoch 96/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0163\n",
      "Epoch 97/200\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0194\n",
      "Epoch 98/200\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0180\n",
      "Epoch 99/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0186\n",
      "Epoch 100/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0155\n",
      "Epoch 101/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0171\n",
      "Epoch 102/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0171\n",
      "Epoch 103/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0155\n",
      "Epoch 104/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0162\n",
      "Epoch 105/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0146\n",
      "Epoch 106/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0159\n",
      "Epoch 107/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0160\n",
      "Epoch 108/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0148\n",
      "Epoch 109/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0160\n",
      "Epoch 110/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0158\n",
      "Epoch 111/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0163\n",
      "Epoch 112/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0163\n",
      "Epoch 113/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0163\n",
      "Epoch 114/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0159\n",
      "Epoch 115/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0202\n",
      "Epoch 116/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0169\n",
      "Epoch 117/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0168\n",
      "Epoch 118/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0166\n",
      "Epoch 119/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0159\n",
      "Epoch 120/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0148\n",
      "Epoch 121/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0165\n",
      "Epoch 122/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0150\n",
      "Epoch 123/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0165\n",
      "Epoch 124/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0191\n",
      "Epoch 125/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0165\n",
      "Epoch 126/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0148\n",
      "Epoch 127/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0144\n",
      "Epoch 128/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0152\n",
      "Epoch 129/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0170\n",
      "Epoch 130/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0162\n",
      "Epoch 131/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0153\n",
      "Epoch 132/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0164\n",
      "Epoch 133/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0183\n",
      "Epoch 134/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0154\n",
      "Epoch 135/200\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0168\n",
      "Epoch 136/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0143\n",
      "Epoch 137/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0152\n",
      "Epoch 138/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0144\n",
      "Epoch 139/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0142\n",
      "Epoch 140/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0156\n",
      "Epoch 141/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0165\n",
      "Epoch 142/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0164\n",
      "Epoch 143/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0179\n",
      "Epoch 144/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0164\n",
      "Epoch 145/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0165\n",
      "Epoch 146/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0147\n",
      "Epoch 147/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0151\n",
      "Epoch 148/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0163\n",
      "Epoch 149/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0165\n",
      "Epoch 150/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0159\n",
      "Epoch 151/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0156\n",
      "Epoch 152/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0148\n",
      "Epoch 153/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0147\n",
      "Epoch 154/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0139\n",
      "Epoch 155/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0152\n",
      "Epoch 156/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0145\n",
      "Epoch 157/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0157\n",
      "Epoch 158/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0158\n",
      "Epoch 159/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0139\n",
      "Epoch 160/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0155\n",
      "Epoch 161/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0155\n",
      "Epoch 162/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0145\n",
      "Epoch 163/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0164\n",
      "Epoch 164/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0165\n",
      "Epoch 165/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0145\n",
      "Epoch 166/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0150\n",
      "Epoch 167/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0157\n",
      "Epoch 168/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0148\n",
      "Epoch 169/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0152\n",
      "Epoch 170/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0176\n",
      "Epoch 171/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0185\n",
      "Epoch 172/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0141\n",
      "Epoch 173/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0166\n",
      "Epoch 174/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0171\n",
      "Epoch 175/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0140\n",
      "Epoch 176/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0135\n",
      "Epoch 177/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0132\n",
      "Epoch 178/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0162\n",
      "Epoch 179/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0149\n",
      "Epoch 180/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0155\n",
      "Epoch 181/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0149\n",
      "Epoch 182/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0150\n",
      "Epoch 183/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0140\n",
      "Epoch 184/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0149\n",
      "Epoch 185/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0144\n",
      "Epoch 186/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0133\n",
      "Epoch 187/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0168\n",
      "Epoch 188/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0142\n",
      "Epoch 189/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0151\n",
      "Epoch 190/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0158\n",
      "Epoch 191/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0151\n",
      "Epoch 192/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0135\n",
      "Epoch 193/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0132\n",
      "Epoch 194/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0152\n",
      "Epoch 195/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0129\n",
      "Epoch 196/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0140\n",
      "Epoch 197/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0157\n",
      "Epoch 198/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0142\n",
      "Epoch 199/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0145\n",
      "Epoch 200/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0133\n",
      "16/16 [==============================] - 3s 5ms/step\n",
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_52 (LSTM)              (None, 1, 100)            47600     \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dropout_52 (Dropout)        (None, 1, 100)            0         \n",
      "                                                                 \n",
      " lstm_53 (LSTM)              (None, 50)                30200     \n",
      "                                                                 \n",
      " dropout_53 (Dropout)        (None, 50)                0         \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77,851\n",
      "Trainable params: 77,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "123/123 [==============================] - 13s 10ms/step - loss: 0.3757\n",
      "Epoch 2/200\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0308\n",
      "Epoch 3/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0310\n",
      "Epoch 4/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0256\n",
      "Epoch 5/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0293\n",
      "Epoch 6/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0237\n",
      "Epoch 7/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0225\n",
      "Epoch 8/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0231\n",
      "Epoch 9/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0222\n",
      "Epoch 10/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0247\n",
      "Epoch 11/200\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0235\n",
      "Epoch 12/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0246\n",
      "Epoch 13/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0249\n",
      "Epoch 14/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0207\n",
      "Epoch 15/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0194\n",
      "Epoch 16/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0228\n",
      "Epoch 17/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0237\n",
      "Epoch 18/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0225\n",
      "Epoch 19/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0201\n",
      "Epoch 20/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0241\n",
      "Epoch 21/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0205\n",
      "Epoch 22/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0233\n",
      "Epoch 23/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0196\n",
      "Epoch 24/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0236\n",
      "Epoch 25/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0202\n",
      "Epoch 26/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0209\n",
      "Epoch 27/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0204\n",
      "Epoch 28/200\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0212\n",
      "Epoch 29/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0212\n",
      "Epoch 30/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0223\n",
      "Epoch 31/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0212\n",
      "Epoch 32/200\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0209\n",
      "Epoch 33/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0213\n",
      "Epoch 34/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0203\n",
      "Epoch 35/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0196\n",
      "Epoch 36/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0218\n",
      "Epoch 37/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0197\n",
      "Epoch 38/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0194\n",
      "Epoch 39/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0196\n",
      "Epoch 40/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0181\n",
      "Epoch 41/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0222\n",
      "Epoch 42/200\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0200\n",
      "Epoch 43/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0175\n",
      "Epoch 44/200\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0195\n",
      "Epoch 45/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0176\n",
      "Epoch 46/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0177\n",
      "Epoch 47/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0194\n",
      "Epoch 48/200\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.0213\n",
      "Epoch 49/200\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0224\n",
      "Epoch 50/200\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0183\n",
      "Epoch 51/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0198\n",
      "Epoch 52/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0170\n",
      "Epoch 53/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0200\n",
      "Epoch 54/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0184\n",
      "Epoch 55/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0207\n",
      "Epoch 56/200\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0172\n",
      "Epoch 57/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0196\n",
      "Epoch 58/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0218\n",
      "Epoch 59/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0211\n",
      "Epoch 60/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0196\n",
      "Epoch 61/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0209\n",
      "Epoch 62/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0195\n",
      "Epoch 63/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0176\n",
      "Epoch 64/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0195\n",
      "Epoch 65/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0185\n",
      "Epoch 66/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0220\n",
      "Epoch 67/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0191\n",
      "Epoch 68/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0189\n",
      "Epoch 69/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0187\n",
      "Epoch 70/200\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0184\n",
      "Epoch 71/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0200\n",
      "Epoch 72/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0202\n",
      "Epoch 73/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0190\n",
      "Epoch 74/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0181\n",
      "Epoch 75/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0191\n",
      "Epoch 76/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0191\n",
      "Epoch 77/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0186\n",
      "Epoch 78/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0167\n",
      "Epoch 79/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0196\n",
      "Epoch 80/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0200\n",
      "Epoch 81/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0178\n",
      "Epoch 82/200\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0186\n",
      "Epoch 83/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0175\n",
      "Epoch 84/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0174\n",
      "Epoch 85/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0187\n",
      "Epoch 86/200\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0160\n",
      "Epoch 87/200\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0177\n",
      "Epoch 88/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0165\n",
      "Epoch 89/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0166\n",
      "Epoch 90/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0200\n",
      "Epoch 91/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0158\n",
      "Epoch 92/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0194\n",
      "Epoch 93/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0173\n",
      "Epoch 94/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0187\n",
      "Epoch 95/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0155\n",
      "Epoch 96/200\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0186\n",
      "Epoch 97/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0180\n",
      "Epoch 98/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0169\n",
      "Epoch 99/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0181\n",
      "Epoch 100/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0176\n",
      "Epoch 101/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0155\n",
      "Epoch 102/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0175\n",
      "Epoch 103/200\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0164\n",
      "Epoch 104/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0171\n",
      "Epoch 105/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0169\n",
      "Epoch 106/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0156\n",
      "Epoch 107/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0173\n",
      "Epoch 108/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0148\n",
      "Epoch 109/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0174\n",
      "Epoch 110/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0177\n",
      "Epoch 111/200\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0169\n",
      "Epoch 112/200\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0159\n",
      "Epoch 113/200\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0170\n",
      "Epoch 114/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0161\n",
      "Epoch 115/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0170\n",
      "Epoch 116/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0188\n",
      "Epoch 117/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0146\n",
      "Epoch 118/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0165\n",
      "Epoch 119/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0196\n",
      "Epoch 120/200\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0158\n",
      "Epoch 121/200\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0176\n",
      "Epoch 122/200\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0175\n",
      "Epoch 123/200\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0151\n",
      "Epoch 124/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0153\n",
      "Epoch 125/200\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0180\n",
      "Epoch 126/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0188\n",
      "Epoch 127/200\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0157\n",
      "Epoch 128/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0159\n",
      "Epoch 129/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0170\n",
      "Epoch 130/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0165\n",
      "Epoch 131/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0164\n",
      "Epoch 132/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0162\n",
      "Epoch 133/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0154\n",
      "Epoch 134/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0162\n",
      "Epoch 135/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0154\n",
      "Epoch 136/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0165\n",
      "Epoch 137/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0170\n",
      "Epoch 138/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0166\n",
      "Epoch 139/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0165\n",
      "Epoch 140/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0168\n",
      "Epoch 141/200\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0176\n",
      "Epoch 142/200\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0163\n",
      "Epoch 143/200\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0170\n",
      "Epoch 144/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0156\n",
      "Epoch 145/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0177\n",
      "Epoch 146/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0172\n",
      "Epoch 147/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0169\n",
      "Epoch 148/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0160\n",
      "Epoch 149/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0158\n",
      "Epoch 150/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0169\n",
      "Epoch 151/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0179\n",
      "Epoch 152/200\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0160\n",
      "Epoch 153/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0153\n",
      "Epoch 154/200\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0154\n",
      "Epoch 155/200\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0175\n",
      "Epoch 156/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0152\n",
      "Epoch 157/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0145\n",
      "Epoch 158/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0189\n",
      "Epoch 159/200\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0177\n",
      "Epoch 160/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0167\n",
      "Epoch 161/200\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0156\n",
      "Epoch 162/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0162\n",
      "Epoch 163/200\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0155\n",
      "Epoch 164/200\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0170\n",
      "Epoch 165/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0169\n",
      "Epoch 166/200\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0152\n",
      "Epoch 167/200\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0154\n",
      "Epoch 168/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0158\n",
      "Epoch 169/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0158\n",
      "Epoch 170/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0156\n",
      "Epoch 171/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0152\n",
      "Epoch 172/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0157\n",
      "Epoch 173/200\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0157\n",
      "Epoch 174/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0165\n",
      "Epoch 175/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0157\n",
      "Epoch 176/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0166\n",
      "Epoch 177/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0151\n",
      "Epoch 178/200\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0144\n",
      "Epoch 179/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0140\n",
      "Epoch 180/200\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0143\n",
      "Epoch 181/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0134\n",
      "Epoch 182/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0133\n",
      "Epoch 183/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0154\n",
      "Epoch 184/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0146\n",
      "Epoch 185/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0145\n",
      "Epoch 186/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0160\n",
      "Epoch 187/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0159\n",
      "Epoch 188/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0159\n",
      "Epoch 189/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0164\n",
      "Epoch 190/200\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0160\n",
      "Epoch 191/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0163\n",
      "Epoch 192/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0168\n",
      "Epoch 193/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0165\n",
      "Epoch 194/200\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0153\n",
      "Epoch 195/200\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0132\n",
      "Epoch 196/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0168\n",
      "Epoch 197/200\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0148\n",
      "Epoch 198/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0151\n",
      "Epoch 199/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0162\n",
      "Epoch 200/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0148\n",
      "16/16 [==============================] - 3s 5ms/step\n",
      "Model: \"sequential_27\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_54 (LSTM)              (None, 1, 100)            47600     \n",
      "                                                                 \n",
      " dropout_54 (Dropout)        (None, 1, 100)            0         \n",
      "                                                                 \n",
      " lstm_55 (LSTM)              (None, 100)               80400     \n",
      "                                                                 \n",
      " dropout_55 (Dropout)        (None, 100)               0         \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 128,101\n",
      "Trainable params: 128,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "123/123 [==============================] - 1318s 4ms/step - loss: 0.2760\n",
      "Epoch 2/200\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.0295\n",
      "Epoch 3/200\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.0264\n",
      "Epoch 4/200\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.0256\n",
      "Epoch 5/200\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0223\n",
      "Epoch 6/200\n",
      "123/123 [==============================] - 1s 11ms/step - loss: 0.0207\n",
      "Epoch 7/200\n",
      "123/123 [==============================] - 1s 11ms/step - loss: 0.0219\n",
      "Epoch 8/200\n",
      "123/123 [==============================] - 1s 11ms/step - loss: 0.0197\n",
      "Epoch 9/200\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0224\n",
      "Epoch 10/200\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0194\n",
      "Epoch 11/200\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0221\n",
      "Epoch 12/200\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0226\n",
      "Epoch 13/200\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0219\n",
      "Epoch 14/200\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0194\n",
      "Epoch 15/200\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0185\n",
      "Epoch 16/200\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0217\n",
      "Epoch 17/200\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0177\n",
      "Epoch 18/200\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0222\n",
      "Epoch 19/200\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0206\n",
      "Epoch 20/200\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0187\n",
      "Epoch 21/200\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0203\n",
      "Epoch 22/200\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0191\n",
      "Epoch 23/200\n",
      "123/123 [==============================] - 1s 11ms/step - loss: 0.0202\n",
      "Epoch 24/200\n",
      "123/123 [==============================] - 1s 11ms/step - loss: 0.0191\n",
      "Epoch 25/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0200\n",
      "Epoch 26/200\n",
      "123/123 [==============================] - 1s 11ms/step - loss: 0.0177\n",
      "Epoch 27/200\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0163\n",
      "Epoch 28/200\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0168\n",
      "Epoch 29/200\n",
      "123/123 [==============================] - 1s 11ms/step - loss: 0.0189\n",
      "Epoch 30/200\n",
      "123/123 [==============================] - 1s 10ms/step - loss: 0.0208\n",
      "Epoch 31/200\n",
      "123/123 [==============================] - 1s 9ms/step - loss: 0.0195\n",
      "Epoch 32/200\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.0170\n",
      "Epoch 33/200\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.0173\n",
      "Epoch 34/200\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0165\n",
      "Epoch 35/200\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.0166\n",
      "Epoch 36/200\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.0188\n",
      "Epoch 37/200\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.0160\n",
      "Epoch 38/200\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.0166\n",
      "Epoch 39/200\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.0186\n",
      "Epoch 40/200\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.0167\n",
      "Epoch 41/200\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.0168\n",
      "Epoch 42/200\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.0165\n",
      "Epoch 43/200\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0162\n",
      "Epoch 44/200\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0168\n",
      "Epoch 45/200\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.0146\n",
      "Epoch 46/200\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.0172\n",
      "Epoch 47/200\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0164\n",
      "Epoch 48/200\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.0174\n",
      "Epoch 49/200\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0169\n",
      "Epoch 50/200\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.0166\n",
      "Epoch 51/200\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.0148\n",
      "Epoch 52/200\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.0165\n",
      "Epoch 53/200\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.0175\n",
      "Epoch 54/200\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.0155\n",
      "Epoch 55/200\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.0164\n",
      "Epoch 56/200\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0174\n",
      "Epoch 57/200\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0167\n",
      "Epoch 58/200\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.0157\n",
      "Epoch 59/200\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0158\n",
      "Epoch 60/200\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0170\n",
      "Epoch 61/200\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.0177\n",
      "Epoch 62/200\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.0163\n",
      "Epoch 63/200\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0158\n",
      "Epoch 64/200\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.0153\n",
      "Epoch 65/200\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0136\n",
      "Epoch 66/200\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.0178\n",
      "Epoch 67/200\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.0162\n",
      "Epoch 68/200\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.0165\n",
      "Epoch 69/200\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.0161\n",
      "Epoch 70/200\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.0174\n",
      "Epoch 71/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/123 [==============================] - 1s 4ms/step - loss: 0.0170\n",
      "Epoch 72/200\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.0164\n",
      "Epoch 73/200\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.0163\n",
      "Epoch 74/200\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.0179\n",
      "Epoch 75/200\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.0138\n",
      "Epoch 76/200\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.0155\n",
      "Epoch 77/200\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.0163\n",
      "Epoch 78/200\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.0153\n",
      "Epoch 79/200\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 80/200\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.0155\n",
      "Epoch 81/200\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.0149\n",
      "Epoch 82/200\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.0153\n",
      "Epoch 83/200\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.0154\n",
      "Epoch 84/200\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.0133\n",
      "Epoch 85/200\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0157\n",
      "Epoch 86/200\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.0178\n",
      "Epoch 87/200\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.0150\n",
      "Epoch 88/200\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.0141\n",
      "Epoch 89/200\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.0142\n",
      "Epoch 90/200\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.0157\n",
      "Epoch 91/200\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0156\n",
      "Epoch 92/200\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.0132\n",
      "Epoch 93/200\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.0147\n",
      "Epoch 94/200\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0158\n",
      "Epoch 95/200\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.0140\n",
      "Epoch 96/200\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.0142\n",
      "Epoch 97/200\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.0153\n",
      "Epoch 98/200\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.0138\n",
      "Epoch 99/200\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.0157\n",
      "Epoch 100/200\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0144\n",
      "Epoch 101/200\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.0150\n",
      "Epoch 102/200\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.0172\n",
      "Epoch 103/200\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.0151\n",
      "Epoch 104/200\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0164\n",
      "Epoch 105/200\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.0147\n",
      "Epoch 106/200\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0127\n",
      "Epoch 107/200\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.0147\n",
      "Epoch 108/200\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.0158\n",
      "Epoch 109/200\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.0140\n",
      "Epoch 110/200\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0145\n",
      "Epoch 111/200\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.0142\n",
      "Epoch 112/200\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.0153\n",
      "Epoch 113/200\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.0161\n",
      "Epoch 114/200\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.0131\n",
      "Epoch 115/200\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.0136\n",
      "Epoch 116/200\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.0140\n",
      "Epoch 117/200\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.0145\n",
      "Epoch 118/200\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.0137\n",
      "Epoch 119/200\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.0146\n",
      "Epoch 120/200\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.0138\n",
      "Epoch 121/200\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.0152\n",
      "Epoch 122/200\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.0123\n",
      "Epoch 123/200\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0164\n",
      "Epoch 124/200\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.0161\n",
      "Epoch 125/200\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0139\n",
      "Epoch 126/200\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0147\n",
      "Epoch 127/200\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.0147\n",
      "Epoch 128/200\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.0133\n",
      "Epoch 129/200\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0140\n",
      "Epoch 130/200\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.0129\n",
      "Epoch 131/200\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0128\n",
      "Epoch 132/200\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0158\n",
      "Epoch 133/200\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.0158\n",
      "Epoch 134/200\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.0143\n",
      "Epoch 135/200\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0139\n",
      "Epoch 136/200\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.0151\n",
      "Epoch 137/200\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.0154\n",
      "Epoch 138/200\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.0138\n",
      "Epoch 139/200\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.0152\n",
      "Epoch 140/200\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0125\n",
      "Epoch 141/200\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.0131\n",
      "Epoch 142/200\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.0125\n",
      "Epoch 143/200\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.0138\n",
      "Epoch 144/200\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.0140\n",
      "Epoch 145/200\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.0150\n",
      "Epoch 146/200\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.0135\n",
      "Epoch 147/200\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.0140\n",
      "Epoch 148/200\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0125\n",
      "Epoch 149/200\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.0121\n",
      "Epoch 150/200\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.0135\n",
      "Epoch 151/200\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0148\n",
      "Epoch 152/200\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.0140\n",
      "Epoch 153/200\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.0121\n",
      "Epoch 154/200\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.0138\n",
      "Epoch 155/200\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.0134\n",
      "Epoch 156/200\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.0134\n",
      "Epoch 157/200\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.0151\n",
      "Epoch 158/200\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0142\n",
      "Epoch 159/200\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0125\n",
      "Epoch 160/200\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.0131\n",
      "Epoch 161/200\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0134\n",
      "Epoch 162/200\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.0144\n",
      "Epoch 163/200\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.0142\n",
      "Epoch 164/200\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.0132\n",
      "Epoch 165/200\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0129\n",
      "Epoch 166/200\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0142\n",
      "Epoch 167/200\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.0132\n",
      "Epoch 168/200\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.0124\n",
      "Epoch 169/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123/123 [==============================] - 1s 5ms/step - loss: 0.0127\n",
      "Epoch 170/200\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.0139\n",
      "Epoch 171/200\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.0136\n",
      "Epoch 172/200\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.0130\n",
      "Epoch 173/200\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.0118\n",
      "Epoch 174/200\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.0115\n",
      "Epoch 175/200\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.0147\n",
      "Epoch 176/200\n",
      "123/123 [==============================] - 1s 4ms/step - loss: 0.0118\n",
      "Epoch 177/200\n",
      "123/123 [==============================] - 0s 4ms/step - loss: 0.0119\n",
      "Epoch 178/200\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0121\n",
      "Epoch 179/200\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.0126\n",
      "Epoch 180/200\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0129\n",
      "Epoch 181/200\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0132\n",
      "Epoch 182/200\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.0121\n",
      "Epoch 183/200\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.0131\n",
      "Epoch 184/200\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0126\n",
      "Epoch 185/200\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.0129\n",
      "Epoch 186/200\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0113\n",
      "Epoch 187/200\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.0126\n",
      "Epoch 188/200\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0138\n",
      "Epoch 189/200\n",
      "123/123 [==============================] - 0s 3ms/step - loss: 0.0134\n",
      "Epoch 190/200\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0119\n",
      "Epoch 191/200\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.0125\n",
      "Epoch 192/200\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.0125\n",
      "Epoch 193/200\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.0131\n",
      "Epoch 194/200\n",
      "123/123 [==============================] - 1s 5ms/step - loss: 0.0124\n",
      "Epoch 195/200\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.0112\n",
      "Epoch 196/200\n",
      "123/123 [==============================] - 1s 7ms/step - loss: 0.0126\n",
      "Epoch 197/200\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0123\n",
      "Epoch 198/200\n",
      "123/123 [==============================] - 1s 6ms/step - loss: 0.0118\n",
      "Epoch 199/200\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.0135\n",
      "Epoch 200/200\n",
      "123/123 [==============================] - 1s 8ms/step - loss: 0.0125\n",
      "16/16 [==============================] - 1s 4ms/step\n",
      "Model: \"sequential_28\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_56 (LSTM)              (None, 1, 50)             13800     \n",
      "                                                                 \n",
      " dropout_56 (Dropout)        (None, 1, 50)             0         \n",
      "                                                                 \n",
      " lstm_57 (LSTM)              (None, 50)                20200     \n",
      "                                                                 \n",
      " dropout_57 (Dropout)        (None, 50)                0         \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34,051\n",
      "Trainable params: 34,051\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "62/62 [==============================] - 5s 3ms/step - loss: 0.7536\n",
      "Epoch 2/200\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0615\n",
      "Epoch 3/200\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0407\n",
      "Epoch 4/200\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0326\n",
      "Epoch 5/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0309\n",
      "Epoch 6/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0298\n",
      "Epoch 7/200\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0346\n",
      "Epoch 8/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0263\n",
      "Epoch 9/200\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0275\n",
      "Epoch 10/200\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0253\n",
      "Epoch 11/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0269\n",
      "Epoch 12/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0271\n",
      "Epoch 13/200\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0259\n",
      "Epoch 14/200\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0267\n",
      "Epoch 15/200\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0270\n",
      "Epoch 16/200\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.0259\n",
      "Epoch 17/200\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0287\n",
      "Epoch 18/200\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0257\n",
      "Epoch 19/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0263\n",
      "Epoch 20/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0250\n",
      "Epoch 21/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0254\n",
      "Epoch 22/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0235\n",
      "Epoch 23/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0229\n",
      "Epoch 24/200\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0247\n",
      "Epoch 25/200\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.0245\n",
      "Epoch 26/200\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0206\n",
      "Epoch 27/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0224\n",
      "Epoch 28/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0216\n",
      "Epoch 29/200\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0255\n",
      "Epoch 30/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0223\n",
      "Epoch 31/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0260\n",
      "Epoch 32/200\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0215\n",
      "Epoch 33/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0209\n",
      "Epoch 34/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0195\n",
      "Epoch 35/200\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0249\n",
      "Epoch 36/200\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0220\n",
      "Epoch 37/200\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0241\n",
      "Epoch 38/200\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0240\n",
      "Epoch 39/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0200\n",
      "Epoch 40/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0226\n",
      "Epoch 41/200\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 42/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0245\n",
      "Epoch 43/200\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0201\n",
      "Epoch 44/200\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0213\n",
      "Epoch 45/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0195\n",
      "Epoch 46/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0199\n",
      "Epoch 47/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0197\n",
      "Epoch 48/200\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0227\n",
      "Epoch 49/200\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0214\n",
      "Epoch 50/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0217\n",
      "Epoch 51/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0218\n",
      "Epoch 52/200\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.0192\n",
      "Epoch 53/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0186\n",
      "Epoch 54/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0209\n",
      "Epoch 55/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 0s 8ms/step - loss: 0.0198\n",
      "Epoch 56/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0231\n",
      "Epoch 57/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0196\n",
      "Epoch 58/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0189\n",
      "Epoch 59/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0203\n",
      "Epoch 60/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0200\n",
      "Epoch 61/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0204\n",
      "Epoch 62/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0199\n",
      "Epoch 63/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0197\n",
      "Epoch 64/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0230\n",
      "Epoch 65/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0192\n",
      "Epoch 66/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0207\n",
      "Epoch 67/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0239\n",
      "Epoch 68/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0214\n",
      "Epoch 69/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0196\n",
      "Epoch 70/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0203\n",
      "Epoch 71/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0190\n",
      "Epoch 72/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0196\n",
      "Epoch 73/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0190\n",
      "Epoch 74/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0194\n",
      "Epoch 75/200\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0193\n",
      "Epoch 76/200\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0185\n",
      "Epoch 77/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0189\n",
      "Epoch 78/200\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0198\n",
      "Epoch 79/200\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0200\n",
      "Epoch 80/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0209\n",
      "Epoch 81/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0202\n",
      "Epoch 82/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0187\n",
      "Epoch 83/200\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0190\n",
      "Epoch 84/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0193\n",
      "Epoch 85/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0194\n",
      "Epoch 86/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0211\n",
      "Epoch 87/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0188\n",
      "Epoch 88/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0188\n",
      "Epoch 89/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0191\n",
      "Epoch 90/200\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0192\n",
      "Epoch 91/200\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0192\n",
      "Epoch 92/200\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0179\n",
      "Epoch 93/200\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0193\n",
      "Epoch 94/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0200\n",
      "Epoch 95/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0215\n",
      "Epoch 96/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0176\n",
      "Epoch 97/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0217\n",
      "Epoch 98/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0203\n",
      "Epoch 99/200\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0196\n",
      "Epoch 100/200\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0180\n",
      "Epoch 101/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0204\n",
      "Epoch 102/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0202\n",
      "Epoch 103/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0200\n",
      "Epoch 104/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0195\n",
      "Epoch 105/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0193\n",
      "Epoch 106/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0193\n",
      "Epoch 107/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0176\n",
      "Epoch 108/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0178\n",
      "Epoch 109/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0197\n",
      "Epoch 110/200\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0181\n",
      "Epoch 111/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0211\n",
      "Epoch 112/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0199\n",
      "Epoch 113/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0205\n",
      "Epoch 114/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0195\n",
      "Epoch 115/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0219\n",
      "Epoch 116/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0172\n",
      "Epoch 117/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0210\n",
      "Epoch 118/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0192\n",
      "Epoch 119/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0195\n",
      "Epoch 120/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0179\n",
      "Epoch 121/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0185\n",
      "Epoch 122/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0189\n",
      "Epoch 123/200\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0198\n",
      "Epoch 124/200\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0205\n",
      "Epoch 125/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0185\n",
      "Epoch 126/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0209\n",
      "Epoch 127/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0209\n",
      "Epoch 128/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0184\n",
      "Epoch 129/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0193\n",
      "Epoch 130/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0200\n",
      "Epoch 131/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0179\n",
      "Epoch 132/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0182\n",
      "Epoch 133/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0193\n",
      "Epoch 134/200\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0205\n",
      "Epoch 135/200\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0209\n",
      "Epoch 136/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0174\n",
      "Epoch 137/200\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 138/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0211\n",
      "Epoch 139/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0197\n",
      "Epoch 140/200\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0179\n",
      "Epoch 141/200\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0205\n",
      "Epoch 142/200\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0187\n",
      "Epoch 143/200\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0202\n",
      "Epoch 144/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0179\n",
      "Epoch 145/200\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0211\n",
      "Epoch 146/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0211\n",
      "Epoch 147/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0201\n",
      "Epoch 148/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0181\n",
      "Epoch 149/200\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0167\n",
      "Epoch 150/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0199\n",
      "Epoch 151/200\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 152/200\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0169\n",
      "Epoch 153/200\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0173\n",
      "Epoch 154/200\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0175\n",
      "Epoch 155/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0171\n",
      "Epoch 156/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0203\n",
      "Epoch 157/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0194\n",
      "Epoch 158/200\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 159/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0210\n",
      "Epoch 160/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0168\n",
      "Epoch 161/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0185\n",
      "Epoch 162/200\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0207\n",
      "Epoch 163/200\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0192\n",
      "Epoch 164/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0181\n",
      "Epoch 165/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0191\n",
      "Epoch 166/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0161\n",
      "Epoch 167/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0209\n",
      "Epoch 168/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0210\n",
      "Epoch 169/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0195\n",
      "Epoch 170/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0191\n",
      "Epoch 171/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0184\n",
      "Epoch 172/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0180\n",
      "Epoch 173/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0165\n",
      "Epoch 174/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0174\n",
      "Epoch 175/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0169\n",
      "Epoch 176/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0203\n",
      "Epoch 177/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0166\n",
      "Epoch 178/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0155\n",
      "Epoch 179/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0191\n",
      "Epoch 180/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0191\n",
      "Epoch 181/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0192\n",
      "Epoch 182/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0196\n",
      "Epoch 183/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0171\n",
      "Epoch 184/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0171\n",
      "Epoch 185/200\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0205\n",
      "Epoch 186/200\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0185\n",
      "Epoch 187/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0179\n",
      "Epoch 188/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0166\n",
      "Epoch 189/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0184\n",
      "Epoch 190/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0169\n",
      "Epoch 191/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0183\n",
      "Epoch 192/200\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0169\n",
      "Epoch 193/200\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0189\n",
      "Epoch 194/200\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 195/200\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0210\n",
      "Epoch 196/200\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0165\n",
      "Epoch 197/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0153\n",
      "Epoch 198/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0174\n",
      "Epoch 199/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0201\n",
      "Epoch 200/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0167\n",
      "16/16 [==============================] - 1s 2ms/step\n",
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_58 (LSTM)              (None, 1, 50)             13800     \n",
      "                                                                 \n",
      " dropout_58 (Dropout)        (None, 1, 50)             0         \n",
      "                                                                 \n",
      " lstm_59 (LSTM)              (None, 100)               60400     \n",
      "                                                                 \n",
      " dropout_59 (Dropout)        (None, 100)               0         \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 74,301\n",
      "Trainable params: 74,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "62/62 [==============================] - 5s 3ms/step - loss: 0.5617\n",
      "Epoch 2/200\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0509\n",
      "Epoch 3/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0350\n",
      "Epoch 4/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0313\n",
      "Epoch 5/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0290\n",
      "Epoch 6/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0253\n",
      "Epoch 7/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0256\n",
      "Epoch 8/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0268\n",
      "Epoch 9/200\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0267\n",
      "Epoch 10/200\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0260\n",
      "Epoch 11/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0245\n",
      "Epoch 12/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0237\n",
      "Epoch 13/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0228\n",
      "Epoch 14/200\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0237\n",
      "Epoch 15/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0245\n",
      "Epoch 16/200\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0212\n",
      "Epoch 17/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0231\n",
      "Epoch 18/200\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0240\n",
      "Epoch 19/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0222\n",
      "Epoch 20/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0255\n",
      "Epoch 21/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0232\n",
      "Epoch 22/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0205\n",
      "Epoch 23/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0215\n",
      "Epoch 24/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0222\n",
      "Epoch 25/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0205\n",
      "Epoch 26/200\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0201\n",
      "Epoch 27/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0217\n",
      "Epoch 28/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0246\n",
      "Epoch 29/200\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0208\n",
      "Epoch 30/200\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0197\n",
      "Epoch 31/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0184\n",
      "Epoch 32/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0200\n",
      "Epoch 33/200\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0167\n",
      "Epoch 34/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0185\n",
      "Epoch 35/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0190\n",
      "Epoch 36/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0204\n",
      "Epoch 37/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0194\n",
      "Epoch 38/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0187\n",
      "Epoch 39/200\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0184\n",
      "Epoch 40/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0190\n",
      "Epoch 41/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0188\n",
      "Epoch 42/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0184\n",
      "Epoch 43/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0181\n",
      "Epoch 44/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0161\n",
      "Epoch 45/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0194\n",
      "Epoch 46/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0190\n",
      "Epoch 47/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0175\n",
      "Epoch 48/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0184\n",
      "Epoch 49/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0199\n",
      "Epoch 50/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0162\n",
      "Epoch 51/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0172\n",
      "Epoch 52/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0194\n",
      "Epoch 53/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0195\n",
      "Epoch 54/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0168\n",
      "Epoch 55/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0187\n",
      "Epoch 56/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0176\n",
      "Epoch 57/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0156\n",
      "Epoch 58/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0169\n",
      "Epoch 59/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0162\n",
      "Epoch 60/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0183\n",
      "Epoch 61/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0159\n",
      "Epoch 62/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0154\n",
      "Epoch 63/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0172\n",
      "Epoch 64/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0156\n",
      "Epoch 65/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0155\n",
      "Epoch 66/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0145\n",
      "Epoch 67/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0171\n",
      "Epoch 68/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0186\n",
      "Epoch 69/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0179\n",
      "Epoch 70/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0152\n",
      "Epoch 71/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0159\n",
      "Epoch 72/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0174\n",
      "Epoch 73/200\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0174\n",
      "Epoch 74/200\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0153\n",
      "Epoch 75/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0190\n",
      "Epoch 76/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0174\n",
      "Epoch 77/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0177\n",
      "Epoch 78/200\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0180\n",
      "Epoch 79/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0158\n",
      "Epoch 80/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0176\n",
      "Epoch 81/200\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0164\n",
      "Epoch 82/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0151\n",
      "Epoch 83/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0155\n",
      "Epoch 84/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0158\n",
      "Epoch 85/200\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0171\n",
      "Epoch 86/200\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0161\n",
      "Epoch 87/200\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0151\n",
      "Epoch 88/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0155\n",
      "Epoch 89/200\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0152\n",
      "Epoch 90/200\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.0156\n",
      "Epoch 91/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0171\n",
      "Epoch 92/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0169\n",
      "Epoch 93/200\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0162\n",
      "Epoch 94/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0165\n",
      "Epoch 95/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0173\n",
      "Epoch 96/200\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0167\n",
      "Epoch 97/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0165\n",
      "Epoch 98/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0149\n",
      "Epoch 99/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0156\n",
      "Epoch 100/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0165\n",
      "Epoch 101/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0164\n",
      "Epoch 102/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0160\n",
      "Epoch 103/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0149\n",
      "Epoch 104/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0138\n",
      "Epoch 105/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0161\n",
      "Epoch 106/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0150\n",
      "Epoch 107/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0163\n",
      "Epoch 108/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0139\n",
      "Epoch 109/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0167\n",
      "Epoch 110/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0153\n",
      "Epoch 111/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0149\n",
      "Epoch 112/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0162\n",
      "Epoch 113/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0143\n",
      "Epoch 114/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0161\n",
      "Epoch 115/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0163\n",
      "Epoch 116/200\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0140\n",
      "Epoch 117/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0157\n",
      "Epoch 118/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0150\n",
      "Epoch 119/200\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0167\n",
      "Epoch 120/200\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0160\n",
      "Epoch 121/200\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0153\n",
      "Epoch 122/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0167\n",
      "Epoch 123/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0162\n",
      "Epoch 124/200\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0159\n",
      "Epoch 125/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0159\n",
      "Epoch 126/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0177\n",
      "Epoch 127/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0152\n",
      "Epoch 128/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0162\n",
      "Epoch 129/200\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0170\n",
      "Epoch 130/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0166\n",
      "Epoch 131/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0158\n",
      "Epoch 132/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0151\n",
      "Epoch 133/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0177\n",
      "Epoch 134/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0151\n",
      "Epoch 135/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0169\n",
      "Epoch 136/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0149\n",
      "Epoch 137/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0144\n",
      "Epoch 138/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0158\n",
      "Epoch 139/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0150\n",
      "Epoch 140/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0171\n",
      "Epoch 141/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0141\n",
      "Epoch 142/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0165\n",
      "Epoch 143/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0150\n",
      "Epoch 144/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0152\n",
      "Epoch 145/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0132\n",
      "Epoch 146/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0140\n",
      "Epoch 147/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0164\n",
      "Epoch 148/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0148\n",
      "Epoch 149/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0155\n",
      "Epoch 150/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0144\n",
      "Epoch 151/200\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 152/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0156\n",
      "Epoch 153/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0158\n",
      "Epoch 154/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0145\n",
      "Epoch 155/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0150\n",
      "Epoch 156/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0150\n",
      "Epoch 157/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0156\n",
      "Epoch 158/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0160\n",
      "Epoch 159/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0164\n",
      "Epoch 160/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0153\n",
      "Epoch 161/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0147\n",
      "Epoch 162/200\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0164\n",
      "Epoch 163/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0166\n",
      "Epoch 164/200\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0158\n",
      "Epoch 165/200\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0146\n",
      "Epoch 166/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0160\n",
      "Epoch 167/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0138\n",
      "Epoch 168/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0154\n",
      "Epoch 169/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0148\n",
      "Epoch 170/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0144\n",
      "Epoch 171/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0148\n",
      "Epoch 172/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0149\n",
      "Epoch 173/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0151\n",
      "Epoch 174/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0138\n",
      "Epoch 175/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0134\n",
      "Epoch 176/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0140\n",
      "Epoch 177/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0142\n",
      "Epoch 178/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0140\n",
      "Epoch 179/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0159\n",
      "Epoch 180/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0144\n",
      "Epoch 181/200\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0125\n",
      "Epoch 182/200\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0135\n",
      "Epoch 183/200\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0127\n",
      "Epoch 184/200\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0139\n",
      "Epoch 185/200\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0150\n",
      "Epoch 186/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0145\n",
      "Epoch 187/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0150\n",
      "Epoch 188/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0150\n",
      "Epoch 189/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0167\n",
      "Epoch 190/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0150\n",
      "Epoch 191/200\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0143\n",
      "Epoch 192/200\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0157\n",
      "Epoch 193/200\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0167\n",
      "Epoch 194/200\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0155\n",
      "Epoch 195/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0149\n",
      "Epoch 196/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0159\n",
      "Epoch 197/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0147\n",
      "Epoch 198/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0133\n",
      "Epoch 199/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0132\n",
      "Epoch 200/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0151\n",
      "16/16 [==============================] - 1s 2ms/step\n",
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_60 (LSTM)              (None, 1, 100)            47600     \n",
      "                                                                 \n",
      " dropout_60 (Dropout)        (None, 1, 100)            0         \n",
      "                                                                 \n",
      " lstm_61 (LSTM)              (None, 50)                30200     \n",
      "                                                                 \n",
      " dropout_61 (Dropout)        (None, 50)                0         \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77,851\n",
      "Trainable params: 77,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "62/62 [==============================] - 5s 6ms/step - loss: 0.4914\n",
      "Epoch 2/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0522\n",
      "Epoch 3/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0334\n",
      "Epoch 4/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0269\n",
      "Epoch 5/200\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0241\n",
      "Epoch 6/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0254\n",
      "Epoch 7/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0230\n",
      "Epoch 8/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0241\n",
      "Epoch 9/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0252\n",
      "Epoch 10/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0232\n",
      "Epoch 11/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0249\n",
      "Epoch 12/200\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0248\n",
      "Epoch 13/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0250\n",
      "Epoch 14/200\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0229\n",
      "Epoch 15/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0253\n",
      "Epoch 16/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0228\n",
      "Epoch 17/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0218\n",
      "Epoch 18/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0196\n",
      "Epoch 19/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0196\n",
      "Epoch 20/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0209\n",
      "Epoch 21/200\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0208\n",
      "Epoch 22/200\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0206\n",
      "Epoch 23/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0196\n",
      "Epoch 24/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0194\n",
      "Epoch 25/200\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0212\n",
      "Epoch 26/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0202\n",
      "Epoch 27/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0196\n",
      "Epoch 28/200\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0203\n",
      "Epoch 29/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0199\n",
      "Epoch 30/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0201\n",
      "Epoch 31/200\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0227\n",
      "Epoch 32/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0191\n",
      "Epoch 33/200\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0195\n",
      "Epoch 34/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0193\n",
      "Epoch 35/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0228\n",
      "Epoch 36/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0228\n",
      "Epoch 37/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0193\n",
      "Epoch 38/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0197\n",
      "Epoch 39/200\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0188\n",
      "Epoch 40/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0223\n",
      "Epoch 41/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0200\n",
      "Epoch 42/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0204\n",
      "Epoch 43/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0215\n",
      "Epoch 44/200\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0199\n",
      "Epoch 45/200\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0201\n",
      "Epoch 46/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0189\n",
      "Epoch 47/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0201\n",
      "Epoch 48/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0194\n",
      "Epoch 49/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0238\n",
      "Epoch 50/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0205\n",
      "Epoch 51/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0214\n",
      "Epoch 52/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0194\n",
      "Epoch 53/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0206\n",
      "Epoch 54/200\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0218\n",
      "Epoch 55/200\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.0194\n",
      "Epoch 56/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0211\n",
      "Epoch 57/200\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0184\n",
      "Epoch 58/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0185\n",
      "Epoch 59/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0192\n",
      "Epoch 60/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0194\n",
      "Epoch 61/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0176\n",
      "Epoch 62/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0186\n",
      "Epoch 63/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0218\n",
      "Epoch 64/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0200\n",
      "Epoch 65/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0220\n",
      "Epoch 66/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0183\n",
      "Epoch 67/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0204\n",
      "Epoch 68/200\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0188\n",
      "Epoch 69/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0174\n",
      "Epoch 70/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0181\n",
      "Epoch 71/200\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0205\n",
      "Epoch 72/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0157\n",
      "Epoch 73/200\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0180\n",
      "Epoch 74/200\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0192\n",
      "Epoch 75/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0173\n",
      "Epoch 76/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0167\n",
      "Epoch 77/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0175\n",
      "Epoch 78/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0193\n",
      "Epoch 79/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0184\n",
      "Epoch 80/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0201\n",
      "Epoch 81/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0180\n",
      "Epoch 82/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0176\n",
      "Epoch 83/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0203\n",
      "Epoch 84/200\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0181\n",
      "Epoch 85/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0187\n",
      "Epoch 86/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0175\n",
      "Epoch 87/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0189\n",
      "Epoch 88/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0168\n",
      "Epoch 89/200\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.0184\n",
      "Epoch 90/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0197\n",
      "Epoch 91/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0176\n",
      "Epoch 92/200\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0189\n",
      "Epoch 93/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0181\n",
      "Epoch 94/200\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0191\n",
      "Epoch 95/200\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0199\n",
      "Epoch 96/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0164\n",
      "Epoch 97/200\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0199\n",
      "Epoch 98/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0176\n",
      "Epoch 99/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0206\n",
      "Epoch 100/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0168\n",
      "Epoch 101/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0203\n",
      "Epoch 102/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0177\n",
      "Epoch 103/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0180\n",
      "Epoch 104/200\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0167\n",
      "Epoch 105/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0162\n",
      "Epoch 106/200\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.0197\n",
      "Epoch 107/200\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.0184\n",
      "Epoch 108/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0198\n",
      "Epoch 109/200\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.0179\n",
      "Epoch 110/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0169\n",
      "Epoch 111/200\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.0169\n",
      "Epoch 112/200\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.0189\n",
      "Epoch 113/200\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.0178\n",
      "Epoch 114/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0164\n",
      "Epoch 115/200\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.0173\n",
      "Epoch 116/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0181\n",
      "Epoch 117/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0171\n",
      "Epoch 118/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0188\n",
      "Epoch 119/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0191\n",
      "Epoch 120/200\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0161\n",
      "Epoch 121/200\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.0179\n",
      "Epoch 122/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0161\n",
      "Epoch 123/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0175\n",
      "Epoch 124/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0187\n",
      "Epoch 125/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0174\n",
      "Epoch 126/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0181\n",
      "Epoch 127/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 128/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0168\n",
      "Epoch 129/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0172\n",
      "Epoch 130/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0174\n",
      "Epoch 131/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0201\n",
      "Epoch 132/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0177\n",
      "Epoch 133/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0172\n",
      "Epoch 134/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0173\n",
      "Epoch 135/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0194\n",
      "Epoch 136/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0172\n",
      "Epoch 137/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0160\n",
      "Epoch 138/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0155\n",
      "Epoch 139/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0184\n",
      "Epoch 140/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0178\n",
      "Epoch 141/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0160\n",
      "Epoch 142/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0163\n",
      "Epoch 143/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0158\n",
      "Epoch 144/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0185\n",
      "Epoch 145/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0166\n",
      "Epoch 146/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0165\n",
      "Epoch 147/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0149\n",
      "Epoch 148/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0165\n",
      "Epoch 149/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0165\n",
      "Epoch 150/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0171\n",
      "Epoch 151/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0176\n",
      "Epoch 152/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0171\n",
      "Epoch 153/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0148\n",
      "Epoch 154/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0176\n",
      "Epoch 155/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0163\n",
      "Epoch 156/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0172\n",
      "Epoch 157/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0170\n",
      "Epoch 158/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0203\n",
      "Epoch 159/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0152\n",
      "Epoch 160/200\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0160\n",
      "Epoch 161/200\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0161\n",
      "Epoch 162/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0167\n",
      "Epoch 163/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0153\n",
      "Epoch 164/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0166\n",
      "Epoch 165/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0163\n",
      "Epoch 166/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0166\n",
      "Epoch 167/200\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0159\n",
      "Epoch 168/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0167\n",
      "Epoch 169/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0168\n",
      "Epoch 170/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0167\n",
      "Epoch 171/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0157\n",
      "Epoch 172/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0160\n",
      "Epoch 173/200\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0157\n",
      "Epoch 174/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0171\n",
      "Epoch 175/200\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0150\n",
      "Epoch 176/200\n",
      "62/62 [==============================] - 1s 23ms/step - loss: 0.0161\n",
      "Epoch 177/200\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.0170\n",
      "Epoch 178/200\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.0177\n",
      "Epoch 179/200\n",
      "62/62 [==============================] - 1s 12ms/step - loss: 0.0158\n",
      "Epoch 180/200\n",
      "62/62 [==============================] - 1s 13ms/step - loss: 0.0153\n",
      "Epoch 181/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0157\n",
      "Epoch 182/200\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.0154\n",
      "Epoch 183/200\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0130\n",
      "Epoch 184/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0152\n",
      "Epoch 185/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0167\n",
      "Epoch 186/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0180\n",
      "Epoch 187/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0178\n",
      "Epoch 188/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0173\n",
      "Epoch 189/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0171\n",
      "Epoch 190/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0167\n",
      "Epoch 191/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0157\n",
      "Epoch 192/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0158\n",
      "Epoch 193/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0158\n",
      "Epoch 194/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0153\n",
      "Epoch 195/200\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0171\n",
      "Epoch 196/200\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.0154\n",
      "Epoch 197/200\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0166\n",
      "Epoch 198/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0164\n",
      "Epoch 199/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0161\n",
      "Epoch 200/200\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0140\n",
      "16/16 [==============================] - 2s 3ms/step\n",
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_62 (LSTM)              (None, 1, 100)            47600     \n",
      "                                                                 \n",
      " dropout_62 (Dropout)        (None, 1, 100)            0         \n",
      "                                                                 \n",
      " lstm_63 (LSTM)              (None, 100)               80400     \n",
      "                                                                 \n",
      " dropout_63 (Dropout)        (None, 100)               0         \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 128,101\n",
      "Trainable params: 128,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "62/62 [==============================] - 10s 4ms/step - loss: 0.4511\n",
      "Epoch 2/200\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.0345\n",
      "Epoch 3/200\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.0242\n",
      "Epoch 4/200\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.0228\n",
      "Epoch 5/200\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.0210\n",
      "Epoch 6/200\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.0224\n",
      "Epoch 7/200\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.0208\n",
      "Epoch 8/200\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0218\n",
      "Epoch 9/200\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.0216\n",
      "Epoch 10/200\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.0228\n",
      "Epoch 11/200\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.0191\n",
      "Epoch 12/200\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.0176\n",
      "Epoch 13/200\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.0211\n",
      "Epoch 14/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0173\n",
      "Epoch 15/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0190\n",
      "Epoch 16/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0179\n",
      "Epoch 17/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0177\n",
      "Epoch 18/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0213\n",
      "Epoch 19/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0198\n",
      "Epoch 20/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0182\n",
      "Epoch 21/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0211\n",
      "Epoch 22/200\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.0191\n",
      "Epoch 23/200\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.0178\n",
      "Epoch 24/200\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0191\n",
      "Epoch 25/200\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0229\n",
      "Epoch 26/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0187\n",
      "Epoch 27/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0168\n",
      "Epoch 28/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0175\n",
      "Epoch 29/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0166\n",
      "Epoch 30/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0183\n",
      "Epoch 31/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0174\n",
      "Epoch 32/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0185\n",
      "Epoch 33/200\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0175\n",
      "Epoch 34/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0188\n",
      "Epoch 35/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0184\n",
      "Epoch 36/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0197\n",
      "Epoch 37/200\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0148\n",
      "Epoch 38/200\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.0188\n",
      "Epoch 39/200\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0162\n",
      "Epoch 40/200\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0179\n",
      "Epoch 41/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0183\n",
      "Epoch 42/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0141\n",
      "Epoch 43/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0168\n",
      "Epoch 44/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0160\n",
      "Epoch 45/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0146\n",
      "Epoch 46/200\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0177\n",
      "Epoch 47/200\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0178\n",
      "Epoch 48/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0177\n",
      "Epoch 49/200\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.0163\n",
      "Epoch 50/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0179\n",
      "Epoch 51/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0164\n",
      "Epoch 52/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0153\n",
      "Epoch 53/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0158\n",
      "Epoch 54/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0202\n",
      "Epoch 55/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0187\n",
      "Epoch 56/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0156\n",
      "Epoch 57/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0161\n",
      "Epoch 58/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0150\n",
      "Epoch 59/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0166\n",
      "Epoch 60/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0151\n",
      "Epoch 61/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0149\n",
      "Epoch 62/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0172\n",
      "Epoch 63/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0139\n",
      "Epoch 64/200\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0149\n",
      "Epoch 65/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0153\n",
      "Epoch 66/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0154\n",
      "Epoch 67/200\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.0173\n",
      "Epoch 68/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0179\n",
      "Epoch 69/200\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.0154\n",
      "Epoch 70/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0171\n",
      "Epoch 71/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0168\n",
      "Epoch 72/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0166\n",
      "Epoch 73/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0134\n",
      "Epoch 74/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0160\n",
      "Epoch 75/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0182\n",
      "Epoch 76/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0161\n",
      "Epoch 77/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0154\n",
      "Epoch 78/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0181\n",
      "Epoch 79/200\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.0162\n",
      "Epoch 80/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0164\n",
      "Epoch 81/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0158\n",
      "Epoch 82/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0173\n",
      "Epoch 83/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0147\n",
      "Epoch 84/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0152\n",
      "Epoch 85/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0162\n",
      "Epoch 86/200\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0164\n",
      "Epoch 87/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0148\n",
      "Epoch 88/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0170\n",
      "Epoch 89/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0175\n",
      "Epoch 90/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0155\n",
      "Epoch 91/200\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.0153\n",
      "Epoch 92/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0152\n",
      "Epoch 93/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0131\n",
      "Epoch 94/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0160\n",
      "Epoch 95/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0155\n",
      "Epoch 96/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0165\n",
      "Epoch 97/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0159\n",
      "Epoch 98/200\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.0163\n",
      "Epoch 99/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0162\n",
      "Epoch 100/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0160\n",
      "Epoch 101/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0143\n",
      "Epoch 102/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0156\n",
      "Epoch 103/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0162\n",
      "Epoch 104/200\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.0153\n",
      "Epoch 105/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0141\n",
      "Epoch 106/200\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0154\n",
      "Epoch 107/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0149\n",
      "Epoch 108/200\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.0161\n",
      "Epoch 109/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0139\n",
      "Epoch 110/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0143\n",
      "Epoch 111/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0135\n",
      "Epoch 112/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0163\n",
      "Epoch 113/200\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.0162\n",
      "Epoch 114/200\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.0153\n",
      "Epoch 115/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - 0s 8ms/step - loss: 0.0142\n",
      "Epoch 116/200\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.0148\n",
      "Epoch 117/200\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0143\n",
      "Epoch 118/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0145\n",
      "Epoch 119/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0135\n",
      "Epoch 120/200\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.0137\n",
      "Epoch 121/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0144\n",
      "Epoch 122/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0137\n",
      "Epoch 123/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0170\n",
      "Epoch 124/200\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.0163\n",
      "Epoch 125/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0129\n",
      "Epoch 126/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0162\n",
      "Epoch 127/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0140\n",
      "Epoch 128/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0151\n",
      "Epoch 129/200\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0150\n",
      "Epoch 130/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0150\n",
      "Epoch 131/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0143\n",
      "Epoch 132/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0154\n",
      "Epoch 133/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0138\n",
      "Epoch 134/200\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.0135\n",
      "Epoch 135/200\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.0147\n",
      "Epoch 136/200\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.0129\n",
      "Epoch 137/200\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0143\n",
      "Epoch 138/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0141\n",
      "Epoch 139/200\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.0135\n",
      "Epoch 140/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0154\n",
      "Epoch 141/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0122\n",
      "Epoch 142/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0153\n",
      "Epoch 143/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0156\n",
      "Epoch 144/200\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.0141\n",
      "Epoch 145/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0131\n",
      "Epoch 146/200\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0131\n",
      "Epoch 147/200\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.0147\n",
      "Epoch 148/200\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.0144\n",
      "Epoch 149/200\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.0142\n",
      "Epoch 150/200\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0139\n",
      "Epoch 151/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0140\n",
      "Epoch 152/200\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0139\n",
      "Epoch 153/200\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0137\n",
      "Epoch 154/200\n",
      "62/62 [==============================] - 1s 8ms/step - loss: 0.0154\n",
      "Epoch 155/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0140\n",
      "Epoch 156/200\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0142\n",
      "Epoch 157/200\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0143\n",
      "Epoch 158/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0129\n",
      "Epoch 159/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0143\n",
      "Epoch 160/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0134\n",
      "Epoch 161/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0137\n",
      "Epoch 162/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0144\n",
      "Epoch 163/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0154\n",
      "Epoch 164/200\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0126\n",
      "Epoch 165/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0135\n",
      "Epoch 166/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0137\n",
      "Epoch 167/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0123\n",
      "Epoch 168/200\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0123\n",
      "Epoch 169/200\n",
      "62/62 [==============================] - 1s 9ms/step - loss: 0.0139\n",
      "Epoch 170/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0139\n",
      "Epoch 171/200\n",
      "62/62 [==============================] - 0s 8ms/step - loss: 0.0139\n",
      "Epoch 172/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0155\n",
      "Epoch 173/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0130\n",
      "Epoch 174/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0128\n",
      "Epoch 175/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0126\n",
      "Epoch 176/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0136\n",
      "Epoch 177/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0128\n",
      "Epoch 178/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0132\n",
      "Epoch 179/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0125\n",
      "Epoch 180/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0132\n",
      "Epoch 181/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0127\n",
      "Epoch 182/200\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0145\n",
      "Epoch 183/200\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0128\n",
      "Epoch 184/200\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 0.0127\n",
      "Epoch 185/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0140\n",
      "Epoch 186/200\n",
      "62/62 [==============================] - 0s 4ms/step - loss: 0.0128\n",
      "Epoch 187/200\n",
      "62/62 [==============================] - 0s 7ms/step - loss: 0.0128\n",
      "Epoch 188/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0129\n",
      "Epoch 189/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0150\n",
      "Epoch 190/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0132\n",
      "Epoch 191/200\n",
      "62/62 [==============================] - 0s 6ms/step - loss: 0.0147\n",
      "Epoch 192/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0135\n",
      "Epoch 193/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0130\n",
      "Epoch 194/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0148\n",
      "Epoch 195/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0124\n",
      "Epoch 196/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0135\n",
      "Epoch 197/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0154\n",
      "Epoch 198/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0140\n",
      "Epoch 199/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0138\n",
      "Epoch 200/200\n",
      "62/62 [==============================] - 0s 5ms/step - loss: 0.0113\n",
      "16/16 [==============================] - 1s 2ms/step\n",
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_64 (LSTM)              (None, 1, 50)             13800     \n",
      "                                                                 \n",
      " dropout_64 (Dropout)        (None, 1, 50)             0         \n",
      "                                                                 \n",
      " lstm_65 (LSTM)              (None, 50)                20200     \n",
      "                                                                 \n",
      " dropout_65 (Dropout)        (None, 50)                0         \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34,051\n",
      "Trainable params: 34,051\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 6s 4ms/step - loss: 0.9990\n",
      "Epoch 2/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.2926\n",
      "Epoch 3/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0616\n",
      "Epoch 4/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0442\n",
      "Epoch 5/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0396\n",
      "Epoch 6/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0307\n",
      "Epoch 7/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0324\n",
      "Epoch 8/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0287\n",
      "Epoch 9/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0300\n",
      "Epoch 10/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0335\n",
      "Epoch 11/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0292\n",
      "Epoch 12/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0307\n",
      "Epoch 13/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0289\n",
      "Epoch 14/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0285\n",
      "Epoch 15/200\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0244\n",
      "Epoch 16/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0245\n",
      "Epoch 17/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0266\n",
      "Epoch 18/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0229\n",
      "Epoch 19/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0260\n",
      "Epoch 20/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.0273\n",
      "Epoch 21/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0287\n",
      "Epoch 22/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0259\n",
      "Epoch 23/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0301\n",
      "Epoch 24/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0259\n",
      "Epoch 25/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0252\n",
      "Epoch 26/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0209\n",
      "Epoch 27/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0223\n",
      "Epoch 28/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0238\n",
      "Epoch 29/200\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0253\n",
      "Epoch 30/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0221\n",
      "Epoch 31/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0237\n",
      "Epoch 32/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0244\n",
      "Epoch 33/200\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0234\n",
      "Epoch 34/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0212\n",
      "Epoch 35/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0211\n",
      "Epoch 36/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0253\n",
      "Epoch 37/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0242\n",
      "Epoch 38/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0212\n",
      "Epoch 39/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0250\n",
      "Epoch 40/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0218\n",
      "Epoch 41/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.0181\n",
      "Epoch 42/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.0228\n",
      "Epoch 43/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.0230\n",
      "Epoch 44/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.0218\n",
      "Epoch 45/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.0221\n",
      "Epoch 46/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.0199\n",
      "Epoch 47/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0216\n",
      "Epoch 48/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0230\n",
      "Epoch 49/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0220\n",
      "Epoch 50/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.0201\n",
      "Epoch 51/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0219\n",
      "Epoch 52/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0201\n",
      "Epoch 53/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0207\n",
      "Epoch 54/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.0223\n",
      "Epoch 55/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.0207\n",
      "Epoch 56/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.0198\n",
      "Epoch 57/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.0191\n",
      "Epoch 58/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.0195\n",
      "Epoch 59/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0216\n",
      "Epoch 60/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.0210\n",
      "Epoch 61/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.0235\n",
      "Epoch 62/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0193\n",
      "Epoch 63/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0245\n",
      "Epoch 64/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0209\n",
      "Epoch 65/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0234\n",
      "Epoch 66/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0223\n",
      "Epoch 67/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.0197\n",
      "Epoch 68/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.0202\n",
      "Epoch 69/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0180\n",
      "Epoch 70/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0185\n",
      "Epoch 71/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0203\n",
      "Epoch 72/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0194\n",
      "Epoch 73/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0208\n",
      "Epoch 74/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0182\n",
      "Epoch 75/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0193\n",
      "Epoch 76/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0205\n",
      "Epoch 77/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0196\n",
      "Epoch 78/200\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0212\n",
      "Epoch 79/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0213\n",
      "Epoch 80/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0181\n",
      "Epoch 81/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0187\n",
      "Epoch 82/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0206\n",
      "Epoch 83/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0204\n",
      "Epoch 84/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0214\n",
      "Epoch 85/200\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0191\n",
      "Epoch 86/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0190\n",
      "Epoch 87/200\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0196\n",
      "Epoch 88/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0196\n",
      "Epoch 89/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0190\n",
      "Epoch 90/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0179\n",
      "Epoch 91/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0190\n",
      "Epoch 92/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0200\n",
      "Epoch 93/200\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0199\n",
      "Epoch 94/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0187\n",
      "Epoch 95/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0216\n",
      "Epoch 96/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0195\n",
      "Epoch 97/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0227\n",
      "Epoch 98/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0191\n",
      "Epoch 99/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0218\n",
      "Epoch 100/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0205\n",
      "Epoch 101/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0200\n",
      "Epoch 102/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0199\n",
      "Epoch 103/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0186\n",
      "Epoch 104/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0184\n",
      "Epoch 105/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0166\n",
      "Epoch 106/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0193\n",
      "Epoch 107/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0189\n",
      "Epoch 108/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0210\n",
      "Epoch 109/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0200\n",
      "Epoch 110/200\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0196\n",
      "Epoch 111/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0178\n",
      "Epoch 112/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.0174\n",
      "Epoch 113/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0203\n",
      "Epoch 114/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0193\n",
      "Epoch 115/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0196\n",
      "Epoch 116/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0197\n",
      "Epoch 117/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0204\n",
      "Epoch 118/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0176\n",
      "Epoch 119/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0195\n",
      "Epoch 120/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0193\n",
      "Epoch 121/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0179\n",
      "Epoch 122/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0184\n",
      "Epoch 123/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0197\n",
      "Epoch 124/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0198\n",
      "Epoch 125/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0180\n",
      "Epoch 126/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0183\n",
      "Epoch 127/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0183\n",
      "Epoch 128/200\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0192\n",
      "Epoch 129/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0211\n",
      "Epoch 130/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0195\n",
      "Epoch 131/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0174\n",
      "Epoch 132/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0198\n",
      "Epoch 133/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0160\n",
      "Epoch 134/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0194\n",
      "Epoch 135/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0182\n",
      "Epoch 136/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0202\n",
      "Epoch 137/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0188\n",
      "Epoch 138/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0173\n",
      "Epoch 139/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0179\n",
      "Epoch 140/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0170\n",
      "Epoch 141/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0181\n",
      "Epoch 142/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0197\n",
      "Epoch 143/200\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0178\n",
      "Epoch 144/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0185\n",
      "Epoch 145/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0187\n",
      "Epoch 146/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0175\n",
      "Epoch 147/200\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0172\n",
      "Epoch 148/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0194\n",
      "Epoch 149/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0188\n",
      "Epoch 150/200\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0193\n",
      "Epoch 151/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0181\n",
      "Epoch 152/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0175\n",
      "Epoch 153/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0164\n",
      "Epoch 154/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0203\n",
      "Epoch 155/200\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0188\n",
      "Epoch 156/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0187\n",
      "Epoch 157/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0177\n",
      "Epoch 158/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0198\n",
      "Epoch 159/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0184\n",
      "Epoch 160/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0175\n",
      "Epoch 161/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0176\n",
      "Epoch 162/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0192\n",
      "Epoch 163/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0164\n",
      "Epoch 164/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0182\n",
      "Epoch 165/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0182\n",
      "Epoch 166/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0197\n",
      "Epoch 167/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0177\n",
      "Epoch 168/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0192\n",
      "Epoch 169/200\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0176\n",
      "Epoch 170/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0189\n",
      "Epoch 171/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0177\n",
      "Epoch 172/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0192\n",
      "Epoch 173/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0172\n",
      "Epoch 174/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0160\n",
      "Epoch 175/200\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0170\n",
      "Epoch 176/200\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0185\n",
      "Epoch 177/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0192\n",
      "Epoch 178/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0170\n",
      "Epoch 179/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0189\n",
      "Epoch 180/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0182\n",
      "Epoch 181/200\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0177\n",
      "Epoch 182/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0170\n",
      "Epoch 183/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0175\n",
      "Epoch 184/200\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0172\n",
      "Epoch 185/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0183\n",
      "Epoch 186/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0197\n",
      "Epoch 187/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.0163\n",
      "Epoch 188/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0171\n",
      "Epoch 189/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.0170\n",
      "Epoch 190/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.0189\n",
      "Epoch 191/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.0155\n",
      "Epoch 192/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0175\n",
      "Epoch 193/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0198\n",
      "Epoch 194/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.0177\n",
      "Epoch 195/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0183\n",
      "Epoch 196/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0181\n",
      "Epoch 197/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0177\n",
      "Epoch 198/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0173\n",
      "Epoch 199/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0201\n",
      "Epoch 200/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0172\n",
      "16/16 [==============================] - 1s 2ms/step\n",
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_66 (LSTM)              (None, 1, 50)             13800     \n",
      "                                                                 \n",
      " dropout_66 (Dropout)        (None, 1, 50)             0         \n",
      "                                                                 \n",
      " lstm_67 (LSTM)              (None, 100)               60400     \n",
      "                                                                 \n",
      " dropout_67 (Dropout)        (None, 100)               0         \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 74,301\n",
      "Trainable params: 74,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "31/31 [==============================] - 4s 3ms/step - loss: 0.9780\n",
      "Epoch 2/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.1902\n",
      "Epoch 3/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0499\n",
      "Epoch 4/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0371\n",
      "Epoch 5/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0360\n",
      "Epoch 6/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0279\n",
      "Epoch 7/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0272\n",
      "Epoch 8/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0250\n",
      "Epoch 9/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0257\n",
      "Epoch 10/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0238\n",
      "Epoch 11/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0225\n",
      "Epoch 12/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0262\n",
      "Epoch 13/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0242\n",
      "Epoch 14/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0229\n",
      "Epoch 15/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0232\n",
      "Epoch 16/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0218\n",
      "Epoch 17/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0250\n",
      "Epoch 18/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0201\n",
      "Epoch 19/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0229\n",
      "Epoch 20/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0213\n",
      "Epoch 21/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0218\n",
      "Epoch 22/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0210\n",
      "Epoch 23/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0207\n",
      "Epoch 24/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0211\n",
      "Epoch 25/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0225\n",
      "Epoch 26/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0202\n",
      "Epoch 27/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0214\n",
      "Epoch 28/200\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.0212\n",
      "Epoch 29/200\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0183\n",
      "Epoch 30/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0191\n",
      "Epoch 31/200\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0207\n",
      "Epoch 32/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0202\n",
      "Epoch 33/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0219\n",
      "Epoch 34/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0191\n",
      "Epoch 35/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0195\n",
      "Epoch 36/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0219\n",
      "Epoch 37/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0187\n",
      "Epoch 38/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0201\n",
      "Epoch 39/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0199\n",
      "Epoch 40/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0185\n",
      "Epoch 41/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0198\n",
      "Epoch 42/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0189\n",
      "Epoch 43/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0167\n",
      "Epoch 44/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0208\n",
      "Epoch 45/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0190\n",
      "Epoch 46/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0179\n",
      "Epoch 47/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0192\n",
      "Epoch 48/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0178\n",
      "Epoch 49/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0177\n",
      "Epoch 50/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0160\n",
      "Epoch 51/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0177\n",
      "Epoch 52/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0169\n",
      "Epoch 53/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0180\n",
      "Epoch 54/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0181\n",
      "Epoch 55/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0183\n",
      "Epoch 56/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0160\n",
      "Epoch 57/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0180\n",
      "Epoch 58/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0172\n",
      "Epoch 59/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0179\n",
      "Epoch 60/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0174\n",
      "Epoch 61/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0166\n",
      "Epoch 62/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0169\n",
      "Epoch 63/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0164\n",
      "Epoch 64/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0173\n",
      "Epoch 65/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0192\n",
      "Epoch 66/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0165\n",
      "Epoch 67/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0168\n",
      "Epoch 68/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0166\n",
      "Epoch 69/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0157\n",
      "Epoch 70/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0162\n",
      "Epoch 71/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0165\n",
      "Epoch 72/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0179\n",
      "Epoch 73/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0183\n",
      "Epoch 74/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0169\n",
      "Epoch 75/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0180\n",
      "Epoch 76/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0184\n",
      "Epoch 77/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0157\n",
      "Epoch 78/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0172\n",
      "Epoch 79/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0173\n",
      "Epoch 80/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0174\n",
      "Epoch 81/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0170\n",
      "Epoch 82/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0203\n",
      "Epoch 83/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0163\n",
      "Epoch 84/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0167\n",
      "Epoch 85/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0161\n",
      "Epoch 86/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0179\n",
      "Epoch 87/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0176\n",
      "Epoch 88/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0151\n",
      "Epoch 89/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0164\n",
      "Epoch 90/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0164\n",
      "Epoch 91/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0166\n",
      "Epoch 92/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0179\n",
      "Epoch 93/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0167\n",
      "Epoch 94/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0162\n",
      "Epoch 95/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0165\n",
      "Epoch 96/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0163\n",
      "Epoch 97/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0166\n",
      "Epoch 98/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0152\n",
      "Epoch 99/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0163\n",
      "Epoch 100/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0148\n",
      "Epoch 101/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0168\n",
      "Epoch 102/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0155\n",
      "Epoch 103/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0150\n",
      "Epoch 104/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0162\n",
      "Epoch 105/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0171\n",
      "Epoch 106/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0160\n",
      "Epoch 107/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0145\n",
      "Epoch 108/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0152\n",
      "Epoch 109/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0177\n",
      "Epoch 110/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0174\n",
      "Epoch 111/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0152\n",
      "Epoch 112/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0149\n",
      "Epoch 113/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0149\n",
      "Epoch 114/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0157\n",
      "Epoch 115/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0169\n",
      "Epoch 116/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0175\n",
      "Epoch 117/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0169\n",
      "Epoch 118/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0166\n",
      "Epoch 119/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0155\n",
      "Epoch 120/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0152\n",
      "Epoch 121/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0160\n",
      "Epoch 122/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0144\n",
      "Epoch 123/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0159\n",
      "Epoch 124/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0142\n",
      "Epoch 125/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0153\n",
      "Epoch 126/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0152\n",
      "Epoch 127/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0166\n",
      "Epoch 128/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0163\n",
      "Epoch 129/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0147\n",
      "Epoch 130/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0160\n",
      "Epoch 131/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0160\n",
      "Epoch 132/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0153\n",
      "Epoch 133/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0158\n",
      "Epoch 134/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0144\n",
      "Epoch 135/200\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0162\n",
      "Epoch 136/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0149\n",
      "Epoch 137/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0166\n",
      "Epoch 138/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0159\n",
      "Epoch 139/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0144\n",
      "Epoch 140/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0175\n",
      "Epoch 141/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0157\n",
      "Epoch 142/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0137\n",
      "Epoch 143/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0152\n",
      "Epoch 144/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0144\n",
      "Epoch 145/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0167\n",
      "Epoch 146/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0154\n",
      "Epoch 147/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0154\n",
      "Epoch 148/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0172\n",
      "Epoch 149/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0150\n",
      "Epoch 150/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0158\n",
      "Epoch 151/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0157\n",
      "Epoch 152/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0154\n",
      "Epoch 153/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0163\n",
      "Epoch 154/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0154\n",
      "Epoch 155/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0141\n",
      "Epoch 156/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0146\n",
      "Epoch 157/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0141\n",
      "Epoch 158/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0158\n",
      "Epoch 159/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0164\n",
      "Epoch 160/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0151\n",
      "Epoch 161/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0168\n",
      "Epoch 162/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0141\n",
      "Epoch 163/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0142\n",
      "Epoch 164/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0139\n",
      "Epoch 165/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0160\n",
      "Epoch 166/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0151\n",
      "Epoch 167/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0164\n",
      "Epoch 168/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0153\n",
      "Epoch 169/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0152\n",
      "Epoch 170/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0146\n",
      "Epoch 171/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0145\n",
      "Epoch 172/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0149\n",
      "Epoch 173/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0171\n",
      "Epoch 174/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0159\n",
      "Epoch 175/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0138\n",
      "Epoch 176/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0156\n",
      "Epoch 177/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0163\n",
      "Epoch 178/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0150\n",
      "Epoch 179/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0154\n",
      "Epoch 180/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0135\n",
      "Epoch 181/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0145\n",
      "Epoch 182/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0149\n",
      "Epoch 183/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0149\n",
      "Epoch 184/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0165\n",
      "Epoch 185/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0158\n",
      "Epoch 186/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0138\n",
      "Epoch 187/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0154\n",
      "Epoch 188/200\n",
      "31/31 [==============================] - 0s 3ms/step - loss: 0.0152\n",
      "Epoch 189/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0130\n",
      "Epoch 190/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0136\n",
      "Epoch 191/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0151\n",
      "Epoch 192/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0139\n",
      "Epoch 193/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0184\n",
      "Epoch 194/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0146\n",
      "Epoch 195/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0153\n",
      "Epoch 196/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0135\n",
      "Epoch 197/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0144\n",
      "Epoch 198/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0134\n",
      "Epoch 199/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0144\n",
      "Epoch 200/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0144\n",
      "16/16 [==============================] - 1s 2ms/step\n",
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_68 (LSTM)              (None, 1, 100)            47600     \n",
      "                                                                 \n",
      " dropout_68 (Dropout)        (None, 1, 100)            0         \n",
      "                                                                 \n",
      " lstm_69 (LSTM)              (None, 50)                30200     \n",
      "                                                                 \n",
      " dropout_69 (Dropout)        (None, 50)                0         \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 77,851\n",
      "Trainable params: 77,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "31/31 [==============================] - 7s 4ms/step - loss: 0.8178\n",
      "Epoch 2/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0995\n",
      "Epoch 3/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0460\n",
      "Epoch 4/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0350\n",
      "Epoch 5/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0320\n",
      "Epoch 6/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0299\n",
      "Epoch 7/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0268\n",
      "Epoch 8/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0258\n",
      "Epoch 9/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0259\n",
      "Epoch 10/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0247\n",
      "Epoch 11/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0239\n",
      "Epoch 12/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0236\n",
      "Epoch 13/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0251\n",
      "Epoch 14/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0242\n",
      "Epoch 15/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0238\n",
      "Epoch 16/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0232\n",
      "Epoch 17/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0201\n",
      "Epoch 18/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0247\n",
      "Epoch 19/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0227\n",
      "Epoch 20/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0210\n",
      "Epoch 21/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0210\n",
      "Epoch 22/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0209\n",
      "Epoch 23/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0208\n",
      "Epoch 24/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0201\n",
      "Epoch 25/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0197\n",
      "Epoch 26/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0199\n",
      "Epoch 27/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0216\n",
      "Epoch 28/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0235\n",
      "Epoch 29/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0212\n",
      "Epoch 30/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0192\n",
      "Epoch 31/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0191\n",
      "Epoch 32/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0220\n",
      "Epoch 33/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0199\n",
      "Epoch 34/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0207\n",
      "Epoch 35/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0207\n",
      "Epoch 36/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0226\n",
      "Epoch 37/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0213\n",
      "Epoch 38/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0225\n",
      "Epoch 39/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0205\n",
      "Epoch 40/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0185\n",
      "Epoch 41/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0184\n",
      "Epoch 42/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0209\n",
      "Epoch 43/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0201\n",
      "Epoch 44/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0196\n",
      "Epoch 45/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0179\n",
      "Epoch 46/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0203\n",
      "Epoch 47/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0213\n",
      "Epoch 48/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0190\n",
      "Epoch 49/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0189\n",
      "Epoch 50/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0209\n",
      "Epoch 51/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0183\n",
      "Epoch 52/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0225\n",
      "Epoch 53/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0170\n",
      "Epoch 54/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0197\n",
      "Epoch 55/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0194\n",
      "Epoch 56/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0194\n",
      "Epoch 57/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0192\n",
      "Epoch 58/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0197\n",
      "Epoch 59/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0218\n",
      "Epoch 60/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0163\n",
      "Epoch 61/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0188\n",
      "Epoch 62/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0179\n",
      "Epoch 63/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0180\n",
      "Epoch 64/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0178\n",
      "Epoch 65/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0177\n",
      "Epoch 66/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0208\n",
      "Epoch 67/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0181\n",
      "Epoch 68/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0205\n",
      "Epoch 69/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0189\n",
      "Epoch 70/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0199\n",
      "Epoch 71/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0169\n",
      "Epoch 72/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0183\n",
      "Epoch 73/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0172\n",
      "Epoch 74/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0197\n",
      "Epoch 75/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0184\n",
      "Epoch 76/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0200\n",
      "Epoch 77/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0178\n",
      "Epoch 78/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0178\n",
      "Epoch 79/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0184\n",
      "Epoch 80/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0188\n",
      "Epoch 81/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0200\n",
      "Epoch 82/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0199\n",
      "Epoch 83/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0189\n",
      "Epoch 84/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0188\n",
      "Epoch 85/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0199\n",
      "Epoch 86/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0192\n",
      "Epoch 87/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0179\n",
      "Epoch 88/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0182\n",
      "Epoch 89/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0186\n",
      "Epoch 90/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0191\n",
      "Epoch 91/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0205\n",
      "Epoch 92/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0186\n",
      "Epoch 93/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0188\n",
      "Epoch 94/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0176\n",
      "Epoch 95/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0173\n",
      "Epoch 96/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0195\n",
      "Epoch 97/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0185\n",
      "Epoch 98/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0162\n",
      "Epoch 99/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0175\n",
      "Epoch 100/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0185\n",
      "Epoch 101/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0179\n",
      "Epoch 102/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0185\n",
      "Epoch 103/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0191\n",
      "Epoch 104/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0188\n",
      "Epoch 105/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0186\n",
      "Epoch 106/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0180\n",
      "Epoch 107/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0173\n",
      "Epoch 108/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0193\n",
      "Epoch 109/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0181\n",
      "Epoch 110/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0160\n",
      "Epoch 111/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0188\n",
      "Epoch 112/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0195\n",
      "Epoch 113/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0179\n",
      "Epoch 114/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0180\n",
      "Epoch 115/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0188\n",
      "Epoch 116/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0168\n",
      "Epoch 117/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0171\n",
      "Epoch 118/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0161\n",
      "Epoch 119/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0190\n",
      "Epoch 120/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0180\n",
      "Epoch 121/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0207\n",
      "Epoch 122/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0166\n",
      "Epoch 123/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0179\n",
      "Epoch 124/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0173\n",
      "Epoch 125/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0165\n",
      "Epoch 126/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0176\n",
      "Epoch 127/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0177\n",
      "Epoch 128/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0159\n",
      "Epoch 129/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0179\n",
      "Epoch 130/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0193\n",
      "Epoch 131/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0190\n",
      "Epoch 132/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0171\n",
      "Epoch 133/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0163\n",
      "Epoch 134/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0180\n",
      "Epoch 135/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0166\n",
      "Epoch 136/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0178\n",
      "Epoch 137/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0176\n",
      "Epoch 138/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0171\n",
      "Epoch 139/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0177\n",
      "Epoch 140/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0172\n",
      "Epoch 141/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0142\n",
      "Epoch 142/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0176\n",
      "Epoch 143/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0167\n",
      "Epoch 144/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0157\n",
      "Epoch 145/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0175\n",
      "Epoch 146/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0153\n",
      "Epoch 147/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0185\n",
      "Epoch 148/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0194\n",
      "Epoch 149/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0157\n",
      "Epoch 150/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0168\n",
      "Epoch 151/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0163\n",
      "Epoch 152/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0176\n",
      "Epoch 153/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0183\n",
      "Epoch 154/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0171\n",
      "Epoch 155/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0183\n",
      "Epoch 156/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0183\n",
      "Epoch 157/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0163\n",
      "Epoch 158/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0173\n",
      "Epoch 159/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0180\n",
      "Epoch 160/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0156\n",
      "Epoch 161/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0174\n",
      "Epoch 162/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0164\n",
      "Epoch 163/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0166\n",
      "Epoch 164/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0166\n",
      "Epoch 165/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0165\n",
      "Epoch 166/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0158\n",
      "Epoch 167/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0163\n",
      "Epoch 168/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0168\n",
      "Epoch 169/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0162\n",
      "Epoch 170/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0177\n",
      "Epoch 171/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0176\n",
      "Epoch 172/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0173\n",
      "Epoch 173/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0179\n",
      "Epoch 174/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0179\n",
      "Epoch 175/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0155\n",
      "Epoch 176/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0172\n",
      "Epoch 177/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0152\n",
      "Epoch 178/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0166\n",
      "Epoch 179/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0161\n",
      "Epoch 180/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0170\n",
      "Epoch 181/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0152\n",
      "Epoch 182/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0183\n",
      "Epoch 183/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0162\n",
      "Epoch 184/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0161\n",
      "Epoch 185/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0183\n",
      "Epoch 186/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0157\n",
      "Epoch 187/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0160\n",
      "Epoch 188/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0159\n",
      "Epoch 189/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0156\n",
      "Epoch 190/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0159\n",
      "Epoch 191/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0156\n",
      "Epoch 192/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0160\n",
      "Epoch 193/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0156\n",
      "Epoch 194/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0195\n",
      "Epoch 195/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0158\n",
      "Epoch 196/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0163\n",
      "Epoch 197/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0189\n",
      "Epoch 198/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0169\n",
      "Epoch 199/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0143\n",
      "Epoch 200/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0168\n",
      "16/16 [==============================] - 1s 2ms/step\n",
      "Model: \"sequential_35\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_70 (LSTM)              (None, 1, 100)            47600     \n",
      "                                                                 \n",
      " dropout_70 (Dropout)        (None, 1, 100)            0         \n",
      "                                                                 \n",
      " lstm_71 (LSTM)              (None, 100)               80400     \n",
      "                                                                 \n",
      " dropout_71 (Dropout)        (None, 100)               0         \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 1)                 101       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 128,101\n",
      "Trainable params: 128,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "31/31 [==============================] - 3s 5ms/step - loss: 0.7998\n",
      "Epoch 2/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0747\n",
      "Epoch 3/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0413\n",
      "Epoch 4/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0259\n",
      "Epoch 5/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0234\n",
      "Epoch 6/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0211\n",
      "Epoch 7/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0232\n",
      "Epoch 8/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0212\n",
      "Epoch 9/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0202\n",
      "Epoch 10/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0223\n",
      "Epoch 11/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0201\n",
      "Epoch 12/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0212\n",
      "Epoch 13/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0215\n",
      "Epoch 14/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0174\n",
      "Epoch 15/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0193\n",
      "Epoch 16/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0193\n",
      "Epoch 17/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0183\n",
      "Epoch 18/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0221\n",
      "Epoch 19/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0197\n",
      "Epoch 20/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0196\n",
      "Epoch 21/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0186\n",
      "Epoch 22/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0181\n",
      "Epoch 23/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0203\n",
      "Epoch 24/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0178\n",
      "Epoch 25/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0194\n",
      "Epoch 26/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0188\n",
      "Epoch 27/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0181\n",
      "Epoch 28/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0200\n",
      "Epoch 29/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0166\n",
      "Epoch 30/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0190\n",
      "Epoch 31/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0164\n",
      "Epoch 32/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0178\n",
      "Epoch 33/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0156\n",
      "Epoch 34/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0154\n",
      "Epoch 35/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0159\n",
      "Epoch 36/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0183\n",
      "Epoch 37/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0184\n",
      "Epoch 38/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0191\n",
      "Epoch 39/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0169\n",
      "Epoch 40/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0181\n",
      "Epoch 41/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0178\n",
      "Epoch 42/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0154\n",
      "Epoch 43/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0162\n",
      "Epoch 44/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0168\n",
      "Epoch 45/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0171\n",
      "Epoch 46/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0164\n",
      "Epoch 47/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0178\n",
      "Epoch 48/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0165\n",
      "Epoch 49/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0159\n",
      "Epoch 50/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0181\n",
      "Epoch 51/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0178\n",
      "Epoch 52/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0158\n",
      "Epoch 53/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0144\n",
      "Epoch 54/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0157\n",
      "Epoch 55/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0161\n",
      "Epoch 56/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0154\n",
      "Epoch 57/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0153\n",
      "Epoch 58/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0149\n",
      "Epoch 59/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0155\n",
      "Epoch 60/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0181\n",
      "Epoch 61/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0158\n",
      "Epoch 62/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0143\n",
      "Epoch 63/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0169\n",
      "Epoch 64/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0167\n",
      "Epoch 65/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0172\n",
      "Epoch 66/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0150\n",
      "Epoch 67/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0163\n",
      "Epoch 68/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0136\n",
      "Epoch 69/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0163\n",
      "Epoch 70/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0167\n",
      "Epoch 71/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0158\n",
      "Epoch 72/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0165\n",
      "Epoch 73/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0151\n",
      "Epoch 74/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0155\n",
      "Epoch 75/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0149\n",
      "Epoch 76/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0151\n",
      "Epoch 77/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0149\n",
      "Epoch 78/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0151\n",
      "Epoch 79/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0162\n",
      "Epoch 80/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0168\n",
      "Epoch 81/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0167\n",
      "Epoch 82/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0153\n",
      "Epoch 83/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0172\n",
      "Epoch 84/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0152\n",
      "Epoch 85/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0151\n",
      "Epoch 86/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0155\n",
      "Epoch 87/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0158\n",
      "Epoch 88/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0151\n",
      "Epoch 89/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0163\n",
      "Epoch 90/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0157\n",
      "Epoch 91/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0142\n",
      "Epoch 92/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0143\n",
      "Epoch 93/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0163\n",
      "Epoch 94/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0145\n",
      "Epoch 95/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0162\n",
      "Epoch 96/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0147\n",
      "Epoch 97/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0144\n",
      "Epoch 98/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0149\n",
      "Epoch 99/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0152\n",
      "Epoch 100/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0144\n",
      "Epoch 101/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0151\n",
      "Epoch 102/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0138\n",
      "Epoch 103/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0141\n",
      "Epoch 104/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0151\n",
      "Epoch 105/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0143\n",
      "Epoch 106/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0149\n",
      "Epoch 107/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0137\n",
      "Epoch 108/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0146\n",
      "Epoch 109/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0151\n",
      "Epoch 110/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0150\n",
      "Epoch 111/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0172\n",
      "Epoch 112/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0143\n",
      "Epoch 113/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0136\n",
      "Epoch 114/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0154\n",
      "Epoch 115/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0152\n",
      "Epoch 116/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0159\n",
      "Epoch 117/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0149\n",
      "Epoch 118/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0149\n",
      "Epoch 119/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0147\n",
      "Epoch 120/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0165\n",
      "Epoch 121/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0144\n",
      "Epoch 122/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0135\n",
      "Epoch 123/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0151\n",
      "Epoch 124/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0156\n",
      "Epoch 125/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0151\n",
      "Epoch 126/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0153\n",
      "Epoch 127/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0151\n",
      "Epoch 128/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0144\n",
      "Epoch 129/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0158\n",
      "Epoch 130/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0140\n",
      "Epoch 131/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0164\n",
      "Epoch 132/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0139\n",
      "Epoch 133/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0132\n",
      "Epoch 134/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0145\n",
      "Epoch 135/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0147\n",
      "Epoch 136/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0133\n",
      "Epoch 137/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0157\n",
      "Epoch 138/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0154\n",
      "Epoch 139/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0166\n",
      "Epoch 140/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0135\n",
      "Epoch 141/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0149\n",
      "Epoch 142/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0165\n",
      "Epoch 143/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0156\n",
      "Epoch 144/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0140\n",
      "Epoch 145/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0139\n",
      "Epoch 146/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0140\n",
      "Epoch 147/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0120\n",
      "Epoch 148/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0141\n",
      "Epoch 149/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0142\n",
      "Epoch 150/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0143\n",
      "Epoch 151/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0158\n",
      "Epoch 152/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0143\n",
      "Epoch 153/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0173\n",
      "Epoch 154/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0150\n",
      "Epoch 155/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0160\n",
      "Epoch 156/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0151\n",
      "Epoch 157/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0141\n",
      "Epoch 158/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0140\n",
      "Epoch 159/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0143\n",
      "Epoch 160/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0133\n",
      "Epoch 161/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0143\n",
      "Epoch 162/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0134\n",
      "Epoch 163/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0130\n",
      "Epoch 164/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0142\n",
      "Epoch 165/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0154\n",
      "Epoch 166/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0152\n",
      "Epoch 167/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0144\n",
      "Epoch 168/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0147\n",
      "Epoch 169/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0149\n",
      "Epoch 170/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0139\n",
      "Epoch 171/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0142\n",
      "Epoch 172/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0135\n",
      "Epoch 173/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0137\n",
      "Epoch 174/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0139\n",
      "Epoch 175/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0137\n",
      "Epoch 176/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0151\n",
      "Epoch 177/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0142\n",
      "Epoch 178/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0146\n",
      "Epoch 179/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0124\n",
      "Epoch 180/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0134\n",
      "Epoch 181/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0142\n",
      "Epoch 182/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0141\n",
      "Epoch 183/200\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.0131\n",
      "Epoch 184/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0143\n",
      "Epoch 185/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0117\n",
      "Epoch 186/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0120\n",
      "Epoch 187/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0137\n",
      "Epoch 188/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0138\n",
      "Epoch 189/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0155\n",
      "Epoch 190/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0141\n",
      "Epoch 191/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0163\n",
      "Epoch 192/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0153\n",
      "Epoch 193/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0143\n",
      "Epoch 194/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0127\n",
      "Epoch 195/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0130\n",
      "Epoch 196/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0154\n",
      "Epoch 197/200\n",
      "31/31 [==============================] - 0s 5ms/step - loss: 0.0127\n",
      "Epoch 198/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0148\n",
      "Epoch 199/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0134\n",
      "Epoch 200/200\n",
      "31/31 [==============================] - 0s 4ms/step - loss: 0.0127\n",
      "16/16 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "modelID = 1\n",
    "for e in epochs_candidates:\n",
    "    for b in batch_size_candidates:\n",
    "        for l1 in lstm_unit1_candidates:\n",
    "            for l2 in lstm_unit2_candidates:\n",
    "                model = build_model(lstm_unit1=l1, lstm_unit2=l2, hops=1)\n",
    "                history = fit_model(model, X_train, y_train, epochs=e, batch_size=b)\n",
    "                models[f'Model-{modelID}'] = (model, history)\n",
    "                \n",
    "                predictions = predict(model, X_test)\n",
    "                predictions_dfs[f'Model-{modelID}'] = predictions\n",
    "                \n",
    "                inversed = inverse_pred_act(predictions)\n",
    "                inversed_dfs[f'Model-{modelID}'] = inversed\n",
    "                rmse_, mape_, r2 = evaluate(inversed)\n",
    "                \n",
    "                performances[f'Model-{modelID}'] = {\n",
    "                    'epochs': e,\n",
    "                    'batch size': b,\n",
    "                    'lstm unit 1': l1,\n",
    "                    'lstm unit 2': l2,\n",
    "                    'RMSE': rmse_,\n",
    "                    'MAPE': mape_,\n",
    "                    'r2': r2\n",
    "                }\n",
    "                modelID += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8c76d7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_df = pd.DataFrame(performances)\n",
    "perf_df = perf_df.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b8ddbb5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epochs</th>\n",
       "      <th>batch size</th>\n",
       "      <th>lstm unit 1</th>\n",
       "      <th>lstm unit 2</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Model-1</th>\n",
       "      <td>100.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>4.163993</td>\n",
       "      <td>3.356448</td>\n",
       "      <td>0.952732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model-24</th>\n",
       "      <td>150.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.167377</td>\n",
       "      <td>3.459918</td>\n",
       "      <td>0.952656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model-33</th>\n",
       "      <td>200.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>4.189977</td>\n",
       "      <td>3.491188</td>\n",
       "      <td>0.952141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model-34</th>\n",
       "      <td>200.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.225524</td>\n",
       "      <td>3.364953</td>\n",
       "      <td>0.951325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model-2</th>\n",
       "      <td>100.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.226553</td>\n",
       "      <td>3.621762</td>\n",
       "      <td>0.951301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model-29</th>\n",
       "      <td>200.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>4.232551</td>\n",
       "      <td>3.503749</td>\n",
       "      <td>0.951163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model-12</th>\n",
       "      <td>100.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.241465</td>\n",
       "      <td>3.438855</td>\n",
       "      <td>0.950957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model-17</th>\n",
       "      <td>150.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>4.319958</td>\n",
       "      <td>3.715872</td>\n",
       "      <td>0.949125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model-18</th>\n",
       "      <td>150.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.325381</td>\n",
       "      <td>3.612582</td>\n",
       "      <td>0.948997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model-7</th>\n",
       "      <td>100.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>4.332911</td>\n",
       "      <td>3.571496</td>\n",
       "      <td>0.948820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model-22</th>\n",
       "      <td>150.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.336104</td>\n",
       "      <td>3.526149</td>\n",
       "      <td>0.948744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model-36</th>\n",
       "      <td>200.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.336751</td>\n",
       "      <td>3.552955</td>\n",
       "      <td>0.948729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model-19</th>\n",
       "      <td>150.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>4.340086</td>\n",
       "      <td>3.568563</td>\n",
       "      <td>0.948650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model-32</th>\n",
       "      <td>200.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.363436</td>\n",
       "      <td>3.592894</td>\n",
       "      <td>0.948096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model-13</th>\n",
       "      <td>150.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>4.393797</td>\n",
       "      <td>3.690075</td>\n",
       "      <td>0.947371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model-10</th>\n",
       "      <td>100.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.404274</td>\n",
       "      <td>3.640031</td>\n",
       "      <td>0.947120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model-11</th>\n",
       "      <td>100.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>4.404479</td>\n",
       "      <td>3.730118</td>\n",
       "      <td>0.947115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model-3</th>\n",
       "      <td>100.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>4.439990</td>\n",
       "      <td>3.658144</td>\n",
       "      <td>0.946259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model-30</th>\n",
       "      <td>200.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.445297</td>\n",
       "      <td>3.825235</td>\n",
       "      <td>0.946130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model-26</th>\n",
       "      <td>200.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.468316</td>\n",
       "      <td>3.681620</td>\n",
       "      <td>0.945571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model-5</th>\n",
       "      <td>100.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>4.479131</td>\n",
       "      <td>3.684654</td>\n",
       "      <td>0.945307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model-8</th>\n",
       "      <td>100.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.480833</td>\n",
       "      <td>3.780733</td>\n",
       "      <td>0.945265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model-20</th>\n",
       "      <td>150.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.483528</td>\n",
       "      <td>3.731823</td>\n",
       "      <td>0.945200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model-23</th>\n",
       "      <td>150.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>4.497176</td>\n",
       "      <td>3.884119</td>\n",
       "      <td>0.944865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model-35</th>\n",
       "      <td>200.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>4.513049</td>\n",
       "      <td>3.687003</td>\n",
       "      <td>0.944476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model-25</th>\n",
       "      <td>200.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>4.516298</td>\n",
       "      <td>3.797343</td>\n",
       "      <td>0.944396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model-15</th>\n",
       "      <td>150.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>4.554312</td>\n",
       "      <td>3.708955</td>\n",
       "      <td>0.943456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model-21</th>\n",
       "      <td>150.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>4.586735</td>\n",
       "      <td>3.819357</td>\n",
       "      <td>0.942648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model-9</th>\n",
       "      <td>100.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>4.601350</td>\n",
       "      <td>3.741081</td>\n",
       "      <td>0.942282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model-6</th>\n",
       "      <td>100.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.623426</td>\n",
       "      <td>3.796247</td>\n",
       "      <td>0.941726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model-31</th>\n",
       "      <td>200.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>4.692316</td>\n",
       "      <td>3.943305</td>\n",
       "      <td>0.939977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model-14</th>\n",
       "      <td>150.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.742852</td>\n",
       "      <td>4.083159</td>\n",
       "      <td>0.938677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model-16</th>\n",
       "      <td>150.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.784252</td>\n",
       "      <td>3.972999</td>\n",
       "      <td>0.937602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model-4</th>\n",
       "      <td>100.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.881741</td>\n",
       "      <td>4.131465</td>\n",
       "      <td>0.935033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model-28</th>\n",
       "      <td>200.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5.255941</td>\n",
       "      <td>4.712380</td>\n",
       "      <td>0.924691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model-27</th>\n",
       "      <td>200.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>5.354789</td>\n",
       "      <td>4.631659</td>\n",
       "      <td>0.921832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          epochs  batch size  lstm unit 1  lstm unit 2      RMSE      MAPE  \\\n",
       "Model-1    100.0        16.0         50.0         50.0  4.163993  3.356448   \n",
       "Model-24   150.0        64.0        100.0        100.0  4.167377  3.459918   \n",
       "Model-33   200.0        64.0         50.0         50.0  4.189977  3.491188   \n",
       "Model-34   200.0        64.0         50.0        100.0  4.225524  3.364953   \n",
       "Model-2    100.0        16.0         50.0        100.0  4.226553  3.621762   \n",
       "Model-29   200.0        32.0         50.0         50.0  4.232551  3.503749   \n",
       "Model-12   100.0        64.0        100.0        100.0  4.241465  3.438855   \n",
       "Model-17   150.0        32.0         50.0         50.0  4.319958  3.715872   \n",
       "Model-18   150.0        32.0         50.0        100.0  4.325381  3.612582   \n",
       "Model-7    100.0        32.0        100.0         50.0  4.332911  3.571496   \n",
       "Model-22   150.0        64.0         50.0        100.0  4.336104  3.526149   \n",
       "Model-36   200.0        64.0        100.0        100.0  4.336751  3.552955   \n",
       "Model-19   150.0        32.0        100.0         50.0  4.340086  3.568563   \n",
       "Model-32   200.0        32.0        100.0        100.0  4.363436  3.592894   \n",
       "Model-13   150.0        16.0         50.0         50.0  4.393797  3.690075   \n",
       "Model-10   100.0        64.0         50.0        100.0  4.404274  3.640031   \n",
       "Model-11   100.0        64.0        100.0         50.0  4.404479  3.730118   \n",
       "Model-3    100.0        16.0        100.0         50.0  4.439990  3.658144   \n",
       "Model-30   200.0        32.0         50.0        100.0  4.445297  3.825235   \n",
       "Model-26   200.0        16.0         50.0        100.0  4.468316  3.681620   \n",
       "Model-5    100.0        32.0         50.0         50.0  4.479131  3.684654   \n",
       "Model-8    100.0        32.0        100.0        100.0  4.480833  3.780733   \n",
       "Model-20   150.0        32.0        100.0        100.0  4.483528  3.731823   \n",
       "Model-23   150.0        64.0        100.0         50.0  4.497176  3.884119   \n",
       "Model-35   200.0        64.0        100.0         50.0  4.513049  3.687003   \n",
       "Model-25   200.0        16.0         50.0         50.0  4.516298  3.797343   \n",
       "Model-15   150.0        16.0        100.0         50.0  4.554312  3.708955   \n",
       "Model-21   150.0        64.0         50.0         50.0  4.586735  3.819357   \n",
       "Model-9    100.0        64.0         50.0         50.0  4.601350  3.741081   \n",
       "Model-6    100.0        32.0         50.0        100.0  4.623426  3.796247   \n",
       "Model-31   200.0        32.0        100.0         50.0  4.692316  3.943305   \n",
       "Model-14   150.0        16.0         50.0        100.0  4.742852  4.083159   \n",
       "Model-16   150.0        16.0        100.0        100.0  4.784252  3.972999   \n",
       "Model-4    100.0        16.0        100.0        100.0  4.881741  4.131465   \n",
       "Model-28   200.0        16.0        100.0        100.0  5.255941  4.712380   \n",
       "Model-27   200.0        16.0        100.0         50.0  5.354789  4.631659   \n",
       "\n",
       "                r2  \n",
       "Model-1   0.952732  \n",
       "Model-24  0.952656  \n",
       "Model-33  0.952141  \n",
       "Model-34  0.951325  \n",
       "Model-2   0.951301  \n",
       "Model-29  0.951163  \n",
       "Model-12  0.950957  \n",
       "Model-17  0.949125  \n",
       "Model-18  0.948997  \n",
       "Model-7   0.948820  \n",
       "Model-22  0.948744  \n",
       "Model-36  0.948729  \n",
       "Model-19  0.948650  \n",
       "Model-32  0.948096  \n",
       "Model-13  0.947371  \n",
       "Model-10  0.947120  \n",
       "Model-11  0.947115  \n",
       "Model-3   0.946259  \n",
       "Model-30  0.946130  \n",
       "Model-26  0.945571  \n",
       "Model-5   0.945307  \n",
       "Model-8   0.945265  \n",
       "Model-20  0.945200  \n",
       "Model-23  0.944865  \n",
       "Model-35  0.944476  \n",
       "Model-25  0.944396  \n",
       "Model-15  0.943456  \n",
       "Model-21  0.942648  \n",
       "Model-9   0.942282  \n",
       "Model-6   0.941726  \n",
       "Model-31  0.939977  \n",
       "Model-14  0.938677  \n",
       "Model-16  0.937602  \n",
       "Model-4   0.935033  \n",
       "Model-28  0.924691  \n",
       "Model-27  0.921832  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf_df.sort_values('RMSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0f094f",
   "metadata": {},
   "source": [
    "**Best model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a9c0450e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epochs</th>\n",
       "      <th>batch size</th>\n",
       "      <th>lstm unit 1</th>\n",
       "      <th>lstm unit 2</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Model-1</th>\n",
       "      <td>100.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>4.163993</td>\n",
       "      <td>3.356448</td>\n",
       "      <td>0.952732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model-24</th>\n",
       "      <td>150.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4.167377</td>\n",
       "      <td>3.459918</td>\n",
       "      <td>0.952656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model-33</th>\n",
       "      <td>200.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>4.189977</td>\n",
       "      <td>3.491188</td>\n",
       "      <td>0.952141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          epochs  batch size  lstm unit 1  lstm unit 2      RMSE      MAPE  \\\n",
       "Model-1    100.0        16.0         50.0         50.0  4.163993  3.356448   \n",
       "Model-24   150.0        64.0        100.0        100.0  4.167377  3.459918   \n",
       "Model-33   200.0        64.0         50.0         50.0  4.189977  3.491188   \n",
       "\n",
       "                r2  \n",
       "Model-1   0.952732  \n",
       "Model-24  0.952656  \n",
       "Model-33  0.952141  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf_df.sort_values('RMSE').iloc[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "682dd013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 720x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 864x864 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "plotErrorHist(inversed_dfs['Model-1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4d80a92b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_pred_act(predictions_dfs['Model-1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7626dc8",
   "metadata": {},
   "source": [
    "## Save the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "88ae6623",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "70055e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "models['Model-1'][0].save('./models/fren.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "adb892f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "loadedModel = keras.models.load_model('./models/fren.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dc56ab0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 1, 50)             13800     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1, 50)             0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 50)                20200     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 50)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 34,051\n",
      "Trainable params: 34,051\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "loadedModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "25739884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "yhat = loadedModel.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
